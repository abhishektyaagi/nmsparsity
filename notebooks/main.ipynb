{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.multiprocessing as mp\n",
    "import torch.distributed as dist\n",
    "from torch.nn.parallel import DistributedDataParallel\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import pytorch_lightning as pl\n",
    "import random\n",
    "import dotenv\n",
    "import omegaconf\n",
    "import hydra\n",
    "import logging\n",
    "import wandb\n",
    "from datetime import date\n",
    "import dotenv\n",
    "import os\n",
    "import pathlib\n",
    "from typing import Dict, Any\n",
    "from copy import deepcopy\n",
    "\n",
    "from rigl_torch.models import ModelFactory\n",
    "from rigl_torch.rigl_scheduler import RigLScheduler\n",
    "from rigl_torch.rigl_constant_fan import RigLConstFanScheduler\n",
    "from rigl_torch.datasets import get_dataloaders\n",
    "from rigl_torch.optim import (\n",
    "    get_optimizer,\n",
    "    get_lr_scheduler,\n",
    ")\n",
    "from rigl_torch.utils.checkpoint import Checkpoint\n",
    "from rigl_torch.utils.rigl_utils import get_T_end, get_fan_in_after_ablation, get_conv_idx_from_flat_idx\n",
    "from hydra import initialize, compose\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resnet50\n"
     ]
    }
   ],
   "source": [
    "with initialize(\"../configs\", version_base=\"1.2.0\"):\n",
    "    cfg = compose(\n",
    "        \"config.yaml\",\n",
    "        overrides=[\n",
    "            \"dataset=imagenet\",\n",
    "            \"compute.distributed=False\",\n",
    "            \"model=resnet50\"\n",
    "            ])\n",
    "dotenv.load_dotenv(\"../.env\")\n",
    "os.environ[\"IMAGE_NET_PATH\"]\n",
    "print(cfg.model.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:rigl_torch.utils.checkpoint:Loading checkpoint from /home/mklasby/projects/def-yani/mklasby/condensed-sparsity/artifacts/checkpoints/20230103_vchnjrf5/checkpoint.pt.tar...\n",
      "Global seed set to 42\n",
      "INFO:/project/6066928/mklasby/condensed-sparsity/src/rigl_torch/models/model_factory.py:Loading model resnet50/imagenet using <function get_imagenet_resnet50 at 0x7feadf4f9af0> with args: () and kwargs: {}\n"
     ]
    }
   ],
   "source": [
    "run_id = \"vchnjrf5\" \n",
    "rank=0\n",
    "checkpoint = Checkpoint.load_last_checkpoint(run_id=run_id, parent_dir = cfg.paths.checkpoints)\n",
    "if checkpoint is not None:\n",
    "    run_id = checkpoint.run_id\n",
    "    optimizer_state = checkpoint.optimizer\n",
    "    scheduler_state = checkpoint.scheduler\n",
    "    pruner_state = checkpoint.pruner\n",
    "    model_state = checkpoint.model\n",
    "    cfg = checkpoint.cfg\n",
    "\n",
    "    cfg.compute.distributed=False\n",
    "    \n",
    "    pl.seed_everything(cfg.training.seed)\n",
    "    use_cuda = not cfg.compute.no_cuda and torch.cuda.is_available()\n",
    "    if not use_cuda:\n",
    "        raise SystemError(\"GPU has stopped responding...waiting to die!\")\n",
    "        logger.warning(\n",
    "            \"Using CPU! Verify cfg.compute.no_cuda and \"\n",
    "            \"torch.cuda.is_available() are properly set if this is unexpected\"\n",
    "        )\n",
    "\n",
    "    if cfg.compute.distributed:\n",
    "        device = torch.device(f\"cuda:{rank}\")\n",
    "    else:\n",
    "        device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "    # train_loader, test_loader = get_dataloaders(cfg)\n",
    "\n",
    "    model = ModelFactory.load_model(\n",
    "        model=cfg.model.name, dataset=cfg.dataset.name\n",
    "    )\n",
    "    model.to(device)\n",
    "    if cfg.compute.distributed:\n",
    "        model = DistributedDataParallel(model, device_ids=[rank])\n",
    "    if model_state is not None:\n",
    "        try:\n",
    "            model.load_state_dict(model_state)\n",
    "        except RuntimeError:\n",
    "            model_state = checkpoint.get_single_process_model_state_from_distributed_state()\n",
    "            model.load_state_dict(model_state)\n",
    "            \n",
    "    optimizer = get_optimizer(cfg, model, state_dict=optimizer_state)\n",
    "    scheduler = get_lr_scheduler(cfg, optimizer, state_dict=scheduler_state)\n",
    "    pruner = None\n",
    "    if cfg.rigl.dense_allocation is not None:\n",
    "        T_end = get_T_end(cfg, [0 for _ in range(0,1251)])\n",
    "        if cfg.rigl.const_fan_in:\n",
    "            rigl_scheduler = RigLConstFanScheduler\n",
    "        else:\n",
    "            rigl_scheduler = RigLScheduler\n",
    "        pruner = rigl_scheduler(\n",
    "            model,\n",
    "            optimizer,\n",
    "            dense_allocation=cfg.rigl.dense_allocation,\n",
    "            alpha=cfg.rigl.alpha,\n",
    "            delta=cfg.rigl.delta,\n",
    "            static_topo=cfg.rigl.static_topo,\n",
    "            T_end=T_end,\n",
    "            ignore_linear_layers=cfg.rigl.ignore_linear_layers,\n",
    "            grad_accumulation_n=cfg.rigl.grad_accumulation_n,\n",
    "            sparsity_distribution=cfg.rigl.sparsity_distribution,\n",
    "            erk_power_scale=cfg.rigl.erk_power_scale,\n",
    "            state_dict=pruner_state,\n",
    "            filter_ablation_threshold=cfg.rigl.filter_ablation_threshold,\n",
    "            static_ablation=cfg.rigl.static_ablation,\n",
    "            dynamic_ablation=cfg.rigl.dynamic_ablation,\n",
    "            min_salient_weights_per_neuron=cfg.rigl.min_salient_weights_per_neuron,  # noqa\n",
    "            use_sparse_init=cfg.rigl.use_sparse_initialization,\n",
    "            init_method_str=cfg.rigl.init_method_str,\n",
    "            use_sparse_const_fan_in_for_ablation=cfg.rigl.use_sparse_const_fan_in_for_ablation,  # noqa\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'RigLScheduler(\\nlayers=54,\\nnonzero_params=[342/9408, 605/4096, 640/36864, 1386/16384, 1561/16384, 1536/16384, 610/36864, 1380/16384, 1550/16384, 600/36864, 1512/16384, 1830/32768, 1200/147456, 3040/65536, 3555/131072, 3120/65536, 1221/147456, 3096/65536, 3120/65536, 1200/147456, 2920/65536, 3125/65536, 1265/147456, 3070/65536, 3648/131072, 2484/589824, 5753/262144, 7306/524288, 6048/262144, 2460/589824, 6171/262144, 6150/262144, 2321/589824, 6149/262144, 6100/262144, 2332/589824, 6138/262144, 6175/262144, 2400/589824, 5742/262144, 6200/262144, 2364/589824, 5796/262144, 7344/524288, 4823/2359296, 12408/1048576, 14664/2097152, 12454/1048576, 4668/2359296, 12285/1048576, 12425/1048576, 4888/2359296, 12000/1048576, 14000/2048000],\\nnonzero_percentages=[3.64%, 14.77%, 1.74%, 8.46%, 9.53%, 9.38%, 1.65%, 8.42%, 9.46%, 1.63%, 9.23%, 5.58%, 0.81%, 4.64%, 2.71%, 4.76%, 0.83%, 4.72%, 4.76%, 0.81%, 4.46%, 4.77%, 0.86%, 4.68%, 2.78%, 0.42%, 2.19%, 1.39%, 2.31%, 0.42%, 2.35%, 2.35%, 0.39%, 2.35%, 2.33%, 0.40%, 2.34%, 2.36%, 0.41%, 2.19%, 2.37%, 0.40%, 2.21%, 1.40%, 0.20%, 1.18%, 0.70%, 1.19%, 0.20%, 1.17%, 1.18%, 0.21%, 1.14%, 0.68%],\\ntotal_nonzero_params=247180/25502912 (0.97%),\\ntotal_CONV_nonzero_params=233180/23454912 (0.99%),\\nstep=66303,\\nnum_rigl_steps=165,\\nignoring_linear_layers=False,\\nsparsity_distribution=erk,\\nITOP rate=0.1675,\\nActive Neuron Count=[(57, 64), (55, 64), (64, 64), (231, 256), (223, 256), (64, 64), (61, 64), (230, 256), (62, 64), (60, 64), (216, 256), (122, 128), (120, 128), (380, 512), (395, 512), (120, 128), (111, 128), (387, 512), (120, 128), (120, 128), (365, 512), (125, 128), (115, 128), (307, 512), (228, 256), (207, 256), (523, 1024), (562, 1024), (224, 256), (205, 256), (561, 1024), (246, 256), (211, 256), (559, 1024), (244, 256), (212, 256), (558, 1024), (247, 256), (200, 256), (522, 1024), (248, 256), (197, 256), (483, 1024), (408, 512), (371, 512), (376, 2048), (376, 2048), (479, 512), (389, 512), (455, 2048), (497, 512), (376, 512), (500, 2048), (1000, 1000)],\\nconstant fan ins=[6, 11, 10, 6, 7, 24, 10, 6, 25, 10, 7, 15, 10, 8, 9, 26, 11, 8, 26, 10, 8, 25, 11, 10, 16, 12, 11, 13, 27, 12, 11, 25, 11, 11, 25, 11, 11, 25, 12, 11, 25, 12, 12, 18, 13, 33, 39, 26, 12, 27, 25, 13, 24, 14]\\nNeurons Statically Ablated per layer = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\\nNeurons Dynamically Ablated per layer = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\\n)'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pruner.__str__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:/project/6066928/mklasby/condensed-sparsity/src/rigl_torch/models/model_factory.py:Loading model resnet50/imagenet using <function get_imagenet_resnet50 at 0x7f808c85ac10> with args: () and kwargs: {}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# net = ModelFactory.load_model(\"wide_resnet22\", \"cifar10\")\n",
    "model = ModelFactory.load_model(\"resnet50\", \"imagenet\")\n",
    "device = torch.device(\"cuda:0\")\n",
    "train_loader, test_loader = get_dataloaders(cfg)\n",
    "# model = ModelFactory.load_model(\n",
    "#         model=cfg.model.name, dataset=cfg.dataset.name\n",
    "#     )\n",
    "model.to(device)\n",
    "optimizer = get_optimizer(cfg, model, state_dict=None)\n",
    "scheduler = get_lr_scheduler(cfg, optimizer, state_dict=None)\n",
    "T_end = get_T_end(cfg, train_loader)\n",
    "if cfg.rigl.const_fan_in:\n",
    "    rigl_scheduler = RigLConstFanScheduler\n",
    "else:\n",
    "    rigl_scheduler = RigLScheduler\n",
    "# pruner = rigl_scheduler(\n",
    "#     model,\n",
    "#     optimizer,\n",
    "#     dense_allocation=cfg.rigl.dense_allocation,\n",
    "#     alpha=cfg.rigl.alpha,\n",
    "#     delta=cfg.rigl.delta,\n",
    "#     static_topo=cfg.rigl.static_topo,\n",
    "#     T_end=T_end,\n",
    "#     ignore_linear_layers=False,\n",
    "#     grad_accumulation_n=cfg.rigl.grad_accumulation_n,\n",
    "#     sparsity_distribution=cfg.rigl.sparsity_distribution,\n",
    "#     erk_power_scale=cfg.rigl.erk_power_scale,\n",
    "#     state_dict=None,\n",
    "#     filter_ablation_threshold=cfg.rigl.filter_ablation_threshold,\n",
    "#     static_ablation=cfg.rigl.static_ablation,\n",
    "#     dynamic_ablation=cfg.rigl.dynamic_ablation,\n",
    "#     min_salient_weights_per_neuron=cfg.rigl.min_salient_weights_per_neuron,\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pruner(\n",
    "    \n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "832f61c19470ea428b2cef022cd1fe1aa91b00b83b99363aeeaecf593912d607"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
