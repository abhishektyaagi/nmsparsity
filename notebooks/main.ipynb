{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.multiprocessing as mp\n",
    "import torch.distributed as dist\n",
    "from torch.nn.parallel import DistributedDataParallel\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import pytorch_lightning as pl\n",
    "import random\n",
    "import dotenv\n",
    "import omegaconf\n",
    "import hydra\n",
    "import logging\n",
    "import wandb\n",
    "from datetime import date\n",
    "import dotenv\n",
    "import os\n",
    "import pathlib\n",
    "from typing import Dict, Any\n",
    "from copy import deepcopy\n",
    "\n",
    "from rigl_torch.models import ModelFactory\n",
    "from rigl_torch.rigl_scheduler import RigLScheduler\n",
    "from rigl_torch.rigl_constant_fan import RigLConstFanScheduler\n",
    "from rigl_torch.datasets import get_dataloaders\n",
    "from rigl_torch.optim import (\n",
    "    get_optimizer,\n",
    "    get_lr_scheduler,\n",
    ")\n",
    "from rigl_torch.utils.checkpoint import Checkpoint\n",
    "from rigl_torch.utils.rigl_utils import get_T_end, get_fan_in_after_ablation, get_conv_idx_from_flat_idx\n",
    "from hydra import initialize, compose\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resnet50\n"
     ]
    }
   ],
   "source": [
    "with initialize(\"../configs\", version_base=\"1.2.0\"):\n",
    "    cfg = compose(\n",
    "        \"config.yaml\",\n",
    "        overrides=[\n",
    "            \"dataset=imagenet\",\n",
    "            \"compute.distributed=False\",\n",
    "            \"model=resnet50\"\n",
    "            ])\n",
    "dotenv.load_dotenv(\"../.env\")\n",
    "os.environ[\"IMAGE_NET_PATH\"]\n",
    "print(cfg.model.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "INFO:/home/user/condensed-sparsity/src/rigl_torch/models/model_factory.py:Loading model resnet50/imagenet using <function get_imagenet_resnet50 at 0x7f0a9cbb28b0> with args: () and kwargs: {}\n"
     ]
    }
   ],
   "source": [
    "run_id = \"vchnjrf5\" \n",
    "rank=0\n",
    "# checkpoint = Checkpoint.load_last_checkpoint(run_id=run_id, parent_dir = cfg.paths.checkpoints\n",
    "checkpoint=None\n",
    "if checkpoint is not None:\n",
    "    run_id = checkpoint.run_id\n",
    "    optimizer_state = checkpoint.optimizer\n",
    "    scheduler_state = checkpoint.scheduler\n",
    "    pruner_state = checkpoint.pruner\n",
    "    model_state = checkpoint.model\n",
    "    cfg = checkpoint.cfg\n",
    "else:\n",
    "    run_id, optimizer_state, scheduler_state, pruner_state, model_state = (\n",
    "        None,\n",
    "        None,\n",
    "        None,\n",
    "        None,\n",
    "        None,\n",
    "    )\n",
    "\n",
    "\n",
    "    # cfg.compute.distributed=False\n",
    "    \n",
    "pl.seed_everything(cfg.training.seed)\n",
    "use_cuda = not cfg.compute.no_cuda and torch.cuda.is_available()\n",
    "if not use_cuda:\n",
    "    raise SystemError(\"GPU has stopped responding...waiting to die!\")\n",
    "    logger.warning(\n",
    "        \"Using CPU! Verify cfg.compute.no_cuda and \"\n",
    "        \"torch.cuda.is_available() are properly set if this is unexpected\"\n",
    "    )\n",
    "\n",
    "if cfg.compute.distributed:\n",
    "    device = torch.device(f\"cuda:{rank}\")\n",
    "else:\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "# train_loader, test_loader = get_dataloaders(cfg)\n",
    "\n",
    "model = ModelFactory.load_model(\n",
    "    model=cfg.model.name, dataset=cfg.dataset.name\n",
    ")\n",
    "model.to(device)\n",
    "if cfg.compute.distributed:\n",
    "    model = DistributedDataParallel(model, device_ids=[rank])\n",
    "if model_state is not None:\n",
    "    try:\n",
    "        model.load_state_dict(model_state)\n",
    "    except RuntimeError:\n",
    "        model_state = checkpoint.get_single_process_model_state_from_distributed_state()\n",
    "        model.load_state_dict(model_state)\n",
    "        \n",
    "optimizer = get_optimizer(cfg, model, state_dict=optimizer_state)\n",
    "scheduler = get_lr_scheduler(cfg, optimizer, state_dict=scheduler_state)\n",
    "pruner = None\n",
    "if cfg.rigl.dense_allocation is not None:\n",
    "    T_end = get_T_end(cfg, [0 for _ in range(0,1251)])\n",
    "    if cfg.rigl.const_fan_in:\n",
    "        rigl_scheduler = RigLConstFanScheduler\n",
    "    else:\n",
    "        rigl_scheduler = RigLScheduler\n",
    "    pruner = rigl_scheduler(\n",
    "        model,\n",
    "        optimizer,\n",
    "        dense_allocation=cfg.rigl.dense_allocation,\n",
    "        alpha=cfg.rigl.alpha,\n",
    "        delta=cfg.rigl.delta,\n",
    "        static_topo=cfg.rigl.static_topo,\n",
    "        T_end=T_end,\n",
    "        ignore_linear_layers=cfg.rigl.ignore_linear_layers,\n",
    "        grad_accumulation_n=cfg.rigl.grad_accumulation_n,\n",
    "        sparsity_distribution=cfg.rigl.sparsity_distribution,\n",
    "        erk_power_scale=cfg.rigl.erk_power_scale,\n",
    "        state_dict=pruner_state,\n",
    "        filter_ablation_threshold=cfg.rigl.filter_ablation_threshold,\n",
    "        static_ablation=cfg.rigl.static_ablation,\n",
    "        dynamic_ablation=cfg.rigl.dynamic_ablation,\n",
    "        min_salient_weights_per_neuron=cfg.rigl.min_salient_weights_per_neuron,  # noqa\n",
    "        use_sparse_init=cfg.rigl.use_sparse_initialization,\n",
    "        init_method_str=cfg.rigl.init_method_str,\n",
    "        use_sparse_const_fan_in_for_ablation=cfg.rigl.use_sparse_const_fan_in_for_ablation,  # noqa\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'step_size': [150, 350, 450],\n",
       " 'warm_up_steps': 25,\n",
       " 'gamma': 0.1,\n",
       " 'lr': 0.4,\n",
       " '_linear_warmup_lrs': array([1.00000000e-06, 1.66676250e-02, 3.33342500e-02, 5.00008750e-02,\n",
       "        6.66675000e-02, 8.33341250e-02, 1.00000750e-01, 1.16667375e-01,\n",
       "        1.33334000e-01, 1.50000625e-01, 1.66667250e-01, 1.83333875e-01,\n",
       "        2.00000500e-01, 2.16667125e-01, 2.33333750e-01, 2.50000375e-01,\n",
       "        2.66667000e-01, 2.83333625e-01, 3.00000250e-01, 3.16666875e-01,\n",
       "        3.33333500e-01, 3.50000125e-01, 3.66666750e-01, 3.83333375e-01,\n",
       "        4.00000000e-01]),\n",
       " '_logger': <Logger /home/user/condensed-sparsity/src/rigl_torch/optim/step_lr_with_linear_warm_up.py (INFO)>,\n",
       " 'optimizer': SGD (\n",
       " Parameter Group 0\n",
       "     dampening: 0\n",
       "     foreach: None\n",
       "     initial_lr: 0.4\n",
       "     lr: 1e-06\n",
       "     maximize: False\n",
       "     momentum: 0.9\n",
       "     nesterov: True\n",
       "     weight_decay: 0.0001\n",
       " ),\n",
       " 'base_lrs': [0.4],\n",
       " 'last_epoch': 0,\n",
       " '_step_count': 1,\n",
       " 'verbose': False,\n",
       " '_get_lr_called_within_step': False,\n",
       " '_last_lr': [1e-06]}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scheduler.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[150, 350, 450]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg.training.step_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/build/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:124: UserWarning: Seems like `optimizer.step()` has been overridden after learning rate scheduler initialization. Please, make sure to call `optimizer.step()` before `lr_scheduler.step()`. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Seems like `optimizer.step()` has been overridden after learning rate scheduler \"\n",
      "INFO:/home/user/condensed-sparsity/src/rigl_torch/optim/step_lr_with_linear_warm_up.py:Reducing LR to 0.04000000000000001 @ epoch 150\n",
      "INFO:/home/user/condensed-sparsity/src/rigl_torch/optim/step_lr_with_linear_warm_up.py:Reducing LR to 0.004000000000000001 @ epoch 350\n",
      "INFO:/home/user/condensed-sparsity/src/rigl_torch/optim/step_lr_with_linear_warm_up.py:Reducing LR to 0.00040000000000000013 @ epoch 450\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.016667625000000002], [0.03333425], [0.050000875], [0.0666675], [0.08333412500000001], [0.10000075], [0.116667375], [0.133334], [0.150000625], [0.16666725000000002], [0.183333875], [0.2000005], [0.21666712500000002], [0.23333375], [0.250000375], [0.266667], [0.283333625], [0.30000024999999997], [0.316666875], [0.3333335], [0.350000125], [0.36666675], [0.383333375], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.00040000000000000013], [0.00040000000000000013], [0.00040000000000000013], [0.00040000000000000013], [0.00040000000000000013], [0.00040000000000000013], [0.00040000000000000013], [0.00040000000000000013], [0.00040000000000000013], [0.00040000000000000013], [0.00040000000000000013], [0.00040000000000000013], [0.00040000000000000013], [0.00040000000000000013], [0.00040000000000000013], [0.00040000000000000013], [0.00040000000000000013], [0.00040000000000000013], [0.00040000000000000013], [0.00040000000000000013], [0.00040000000000000013], [0.00040000000000000013], [0.00040000000000000013], [0.00040000000000000013], [0.00040000000000000013], [0.00040000000000000013], [0.00040000000000000013], [0.00040000000000000013], [0.00040000000000000013], [0.00040000000000000013], [0.00040000000000000013], [0.00040000000000000013], [0.00040000000000000013], [0.00040000000000000013], [0.00040000000000000013], [0.00040000000000000013], [0.00040000000000000013], [0.00040000000000000013], [0.00040000000000000013], [0.00040000000000000013], [0.00040000000000000013], [0.00040000000000000013], [0.00040000000000000013], [0.00040000000000000013], [0.00040000000000000013], [0.00040000000000000013], [0.00040000000000000013], [0.00040000000000000013], [0.00040000000000000013], [0.00040000000000000013]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f0a4fce6550>]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "lrs = []\n",
    "for epoch in list(range(1,500)):\n",
    "    scheduler.step()\n",
    "    lrs.append(scheduler.get_last_lr())\n",
    "print(lrs)\n",
    "plt.plot(lrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'RigLScheduler(\\nlayers=54,\\nnonzero_params=[384/9408, 576/4096, 640/36864, 1536/16384, 1536/16384, 1536/16384, 640/36864, 1536/16384, 1536/16384, 640/36864, 1536/16384, 1792/32768, 1152/147456, 3072/65536, 3584/131072, 3072/65536, 1152/147456, 3072/65536, 3072/65536, 1152/147456, 3072/65536, 3072/65536, 1152/147456, 3072/65536, 3584/131072, 2304/589824, 6144/262144, 7168/524288, 6144/262144, 2304/589824, 6144/262144, 6144/262144, 2304/589824, 6144/262144, 6144/262144, 2304/589824, 6144/262144, 6144/262144, 2304/589824, 6144/262144, 6144/262144, 2304/589824, 6144/262144, 7168/524288, 4608/2359296, 12288/1048576, 14336/2097152, 12288/1048576, 4608/2359296, 12288/1048576, 12288/1048576, 4608/2359296, 12288/1048576, 14000/2048000],\\nnonzero_percentages=[4.08%, 14.06%, 1.74%, 9.38%, 9.38%, 9.38%, 1.74%, 9.38%, 9.38%, 1.74%, 9.38%, 5.47%, 0.78%, 4.69%, 2.73%, 4.69%, 0.78%, 4.69%, 4.69%, 0.78%, 4.69%, 4.69%, 0.78%, 4.69%, 2.73%, 0.39%, 2.34%, 1.37%, 2.34%, 0.39%, 2.34%, 2.34%, 0.39%, 2.34%, 2.34%, 0.39%, 2.34%, 2.34%, 0.39%, 2.34%, 2.34%, 0.39%, 2.34%, 1.37%, 0.20%, 1.17%, 0.68%, 1.17%, 0.20%, 1.17%, 1.17%, 0.20%, 1.17%, 0.68%],\\ntotal_nonzero_params=246512/25502912 (0.97%),\\ntotal_CONV_nonzero_params=232512/23454912 (0.99%),\\nstep=0,\\nnum_rigl_steps=0,\\nignoring_linear_layers=False,\\nsparsity_distribution=erk,\\nITOP rate=0.0097,\\nActive Neuron Count=[(64, 64), (64, 64), (64, 64), (256, 256), (256, 256), (64, 64), (64, 64), (256, 256), (64, 64), (64, 64), (256, 256), (128, 128), (128, 128), (512, 512), (512, 512), (128, 128), (128, 128), (512, 512), (128, 128), (128, 128), (512, 512), (128, 128), (128, 128), (512, 512), (256, 256), (256, 256), (1024, 1024), (1024, 1024), (256, 256), (256, 256), (1024, 1024), (256, 256), (256, 256), (1024, 1024), (256, 256), (256, 256), (1024, 1024), (256, 256), (256, 256), (1024, 1024), (256, 256), (256, 256), (1024, 1024), (512, 512), (512, 512), (2048, 2048), (2048, 2048), (512, 512), (512, 512), (2048, 2048), (512, 512), (512, 512), (2048, 2048), (1000, 1000)],\\nconstant fan ins=[6, 9, 10, 6, 6, 24, 10, 6, 24, 10, 6, 14, 9, 6, 7, 24, 9, 6, 24, 9, 6, 24, 9, 6, 14, 9, 6, 7, 24, 9, 6, 24, 9, 6, 24, 9, 6, 24, 9, 6, 24, 9, 6, 14, 9, 6, 7, 24, 9, 6, 24, 9, 6, 14]\\nNeurons Statically Ablated per layer = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\\nNeurons Dynamically Ablated per layer = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\\n)'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pruner.__str__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:/project/6066928/mklasby/condensed-sparsity/src/rigl_torch/models/model_factory.py:Loading model resnet50/imagenet using <function get_imagenet_resnet50 at 0x7f808c85ac10> with args: () and kwargs: {}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# net = ModelFactory.load_model(\"wide_resnet22\", \"cifar10\")\n",
    "model = ModelFactory.load_model(\"resnet50\", \"imagenet\")\n",
    "device = torch.device(\"cuda:0\")\n",
    "train_loader, test_loader = get_dataloaders(cfg)\n",
    "# model = ModelFactory.load_model(\n",
    "#         model=cfg.model.name, dataset=cfg.dataset.name\n",
    "#     )\n",
    "model.to(device)\n",
    "optimizer = get_optimizer(cfg, model, state_dict=None)\n",
    "scheduler = get_lr_scheduler(cfg, optimizer, state_dict=None)\n",
    "T_end = get_T_end(cfg, train_loader)\n",
    "if cfg.rigl.const_fan_in:\n",
    "    rigl_scheduler = RigLConstFanScheduler\n",
    "else:\n",
    "    rigl_scheduler = RigLScheduler\n",
    "# pruner = rigl_scheduler(\n",
    "#     model,\n",
    "#     optimizer,\n",
    "#     dense_allocation=cfg.rigl.dense_allocation,\n",
    "#     alpha=cfg.rigl.alpha,\n",
    "#     delta=cfg.rigl.delta,\n",
    "#     static_topo=cfg.rigl.static_topo,\n",
    "#     T_end=T_end,\n",
    "#     ignore_linear_layers=False,\n",
    "#     grad_accumulation_n=cfg.rigl.grad_accumulation_n,\n",
    "#     sparsity_distribution=cfg.rigl.sparsity_distribution,\n",
    "#     erk_power_scale=cfg.rigl.erk_power_scale,\n",
    "#     state_dict=None,\n",
    "#     filter_ablation_threshold=cfg.rigl.filter_ablation_threshold,\n",
    "#     static_ablation=cfg.rigl.static_ablation,\n",
    "#     dynamic_ablation=cfg.rigl.dynamic_ablation,\n",
    "#     min_salient_weights_per_neuron=cfg.rigl.min_salient_weights_per_neuron,\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pruner(\n",
    "    \n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "816b48dc46e0e4033a4b7ddacb526e2f216437e7413cf9fdf092ed7be3b64e38"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
