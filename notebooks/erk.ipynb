{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from rigl_torch.models import ModelFactory\n",
    "from rigl_torch.optim.cosine_annealing_with_linear_warm_up import CosineAnnealingWithLinearWarmUp\n",
    "from rigl_torch.rigl_constant_fan import RigLConstFanScheduler\n",
    "from rigl_torch.rigl_scheduler import RigLScheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_270864/856747501.py:5: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  with hydra.initialize(config_path=\"../configs\"):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'dataset': {'name': 'cifar10', 'normalize': False, 'num_classes': 10, 'classes': ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']}, 'model': {'name': 'wide_resnet22'}, 'experiment': {'comment': 'erk_testing', 'name': '${model.name}_${dataset.name}_${experiment.comment}'}, 'paths': {'data_folder': '/home/condensed-sparsity/data', 'artifacts': '/home/condensed-sparsity/artifacts', 'logs': '/home/condensed-sparsity/logs'}, 'rigl': {'dense_allocation': 0.1, 'delta': 100, 'grad_accumulation_n': 1, 'alpha': 0.3, 'static_topo': 0, 'const_fan_in': False, 'sparsity_distribution': 'erk', 'erk_power_scale': 1.0}, 'training': {'batch_size': 64, 'test_batch_size': 10, 'epochs': 50, 'lr': 0.1, 'init_lr': 1e-06, 'warm_up_steps': 5, 'gamma': 0.7, 'dry_run': False, 'seed': 1, 'log_interval': 10, 'save_model': True, 'weight_decay': 0, 'momentum': 0.9, 'optimizer': 'adadelta'}, 'compute': {'no_cuda': False, 'cuda_kwargs': {'num_workers': 1, 'pin_memory': True, 'shuffle': True}}, 'wandb': {'project': 'condensed-rigl', 'entity': 'condensed-sparsity', 'start_method': 'thread'}}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from rigl_torch.datasets import get_dataloaders\n",
    "from omegaconf import DictConfig\n",
    "import hydra\n",
    "\n",
    "with hydra.initialize(config_path=\"../configs\"):\n",
    "    cfg = hydra.compose(config_name=\"config.yaml\", overrides=[])\n",
    "cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.rigl.sparsity_distribution = \"erk\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# model = ModelFactory.load_model(model=\"mnist\", dataset='mnist').to(device)\n",
    "use_cuda = not cfg.compute.no_cuda and torch.cuda.is_available()\n",
    "torch.manual_seed(cfg.training.seed)\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "train_loader, test_loader = get_dataloaders(cfg)\n",
    "\n",
    "model = ModelFactory.load_model(model=cfg.model.name, dataset=cfg.dataset.name).to(device)\n",
    "# model = get_model(cfg).to(device)\n",
    "optimizer = torch.optim.Adadelta(model.parameters(), lr=cfg.training.lr)\n",
    "scheduler = CosineAnnealingWithLinearWarmUp(\n",
    "    optimizer,\n",
    "    T_max=cfg.training.epochs,\n",
    "    eta_min=0,\n",
    "    lr=cfg.training.lr,\n",
    "    warm_up_steps=cfg.training.warm_up_steps,\n",
    ")\n",
    "\n",
    "pruner = lambda: True  # noqa: E731\n",
    "if cfg.rigl.dense_allocation is not None:\n",
    "    T_end = int(0.75 * cfg.training.epochs * len(train_loader))\n",
    "    if cfg.rigl.const_fan_in:\n",
    "        rigl_scheduler = RigLConstFanScheduler\n",
    "    else:\n",
    "        rigl_scheduler = RigLScheduler\n",
    "    pruner = rigl_scheduler(\n",
    "        model,\n",
    "        optimizer,\n",
    "        dense_allocation=cfg.rigl.dense_allocation,\n",
    "        alpha=cfg.rigl.alpha,\n",
    "        delta=cfg.rigl.delta,\n",
    "        static_topo=cfg.rigl.static_topo,\n",
    "        T_end=T_end,\n",
    "        ignore_linear_layers=False,\n",
    "        grad_accumulation_n=cfg.rigl.grad_accumulation_n,\n",
    "        sparsity_distribution=cfg.rigl.sparsity_distribution,\n",
    "        erk_power_scale=cfg.rigl.erk_power_scale,\n",
    "    )\n",
    "else:\n",
    "    print(\n",
    "        \"cfg.rigl.dense_allocation is `null`, training with dense \"\n",
    "        \"network...\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RigLScheduler(\n",
      "layers=23,\n",
      "nonzero_params=[432/432, 4608/4608, 9216/9216, 512/512, 9216/9216, 9216/9216, 9216/9216, 9216/9216, 18432/18432, 36864/36864, 2048/2048, 36864/36864, 36864/36864, 36864/36864, 36864/36864, 73728/73728, 21537/147456, 8192/8192, 21537/147456, 21537/147456, 21537/147456, 21537/147456, 1280/1280],\n",
      "nonzero_percentages=[100.00%, 100.00%, 100.00%, 100.00%, 100.00%, 100.00%, 100.00%, 100.00%, 100.00%, 100.00%, 100.00%, 100.00%, 100.00%, 100.00%, 100.00%, 100.00%, 14.61%, 100.00%, 14.61%, 14.61%, 14.61%, 14.61%, 100.00%],\n",
      "total_nonzero_params=447317/1076912 (41.54%),\n",
      "total_CONV_nonzero_params=446037/1075632 (41.47%),\n",
      "step=0,\n",
      "num_rigl_steps=0,\n",
      "ignoring_linear_layers=False,\n",
      "sparsity_distribution=erk,\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(pruner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 3, 3, 3])\n",
      "432\n",
      "torch.Size([32, 16, 3, 3])\n",
      "4608\n",
      "torch.Size([32, 32, 3, 3])\n",
      "9216\n",
      "torch.Size([32, 16, 1, 1])\n",
      "512\n",
      "torch.Size([32, 32, 3, 3])\n",
      "9216\n",
      "torch.Size([32, 32, 3, 3])\n",
      "9216\n",
      "torch.Size([32, 32, 3, 3])\n",
      "9216\n",
      "torch.Size([32, 32, 3, 3])\n",
      "9216\n",
      "torch.Size([64, 32, 3, 3])\n",
      "18432\n",
      "torch.Size([64, 64, 3, 3])\n",
      "36864\n",
      "torch.Size([64, 32, 1, 1])\n",
      "2048\n",
      "torch.Size([64, 64, 3, 3])\n",
      "36864\n",
      "torch.Size([64, 64, 3, 3])\n",
      "36864\n",
      "torch.Size([64, 64, 3, 3])\n",
      "36864\n",
      "torch.Size([64, 64, 3, 3])\n",
      "36864\n",
      "torch.Size([128, 64, 3, 3])\n",
      "73728\n",
      "torch.Size([128, 128, 3, 3])\n",
      "147456\n",
      "torch.Size([128, 64, 1, 1])\n",
      "8192\n",
      "torch.Size([128, 128, 3, 3])\n",
      "147456\n",
      "torch.Size([128, 128, 3, 3])\n",
      "147456\n",
      "torch.Size([128, 128, 3, 3])\n",
      "147456\n",
      "torch.Size([128, 128, 3, 3])\n",
      "147456\n",
      "torch.Size([10, 128])\n",
      "1280\n"
     ]
    }
   ],
   "source": [
    "from rigl_torch.util import get_W\n",
    "W = get_W(model, return_linear_layers_mask=False)\n",
    "for w in W:\n",
    "    print(w.shape)\n",
    "    print(w.numel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_el = 0\n",
    "non_zero_el = 0\n",
    "for mask, weights in list(zip(pruner.backward_masks, pruner.W)):\n",
    "    if mask is None:\n",
    "        total_el += weights.numel()\n",
    "        non_zero_el += weights.numel()\n",
    "    else:\n",
    "        total_el +=weights.numel()\n",
    "        non_zero_el+=mask.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1199648"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_el"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(121534, device='cuda:0')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_zero_el"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1014, device='cuda:0')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_zero_el / total_el"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RigLScheduler(\n",
      "layers=4,\n",
      "nonzero_params=[288/288, 6848/18432, 113280/1179648, 1280/1280],\n",
      "nonzero_percentages=[100.00%, 37.15%, 9.60%, 100.00%],\n",
      "total_nonzero_params=121696/1199648 (10.14%),\n",
      "total_CONV_nonzero_params=7136/18720 (38.12%),\n",
      "step=0,\n",
      "num_rigl_steps=0,\n",
      "ignoring_linear_layers=False,\n",
      "sparsity_distribution=erk,\n",
      "constant fan ins=[9, 107, 885, 128]\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(pruner)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None,\n",
       " tensor([[[[ True,  True,  True],\n",
       "           [False, False, False],\n",
       "           [ True,  True, False]],\n",
       " \n",
       "          [[ True, False,  True],\n",
       "           [False, False, False],\n",
       "           [False, False, False]],\n",
       " \n",
       "          [[False, False, False],\n",
       "           [False,  True,  True],\n",
       "           [False, False,  True]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[False, False, False],\n",
       "           [ True, False, False],\n",
       "           [False, False,  True]],\n",
       " \n",
       "          [[ True,  True, False],\n",
       "           [ True,  True, False],\n",
       "           [ True, False, False]],\n",
       " \n",
       "          [[False, False, False],\n",
       "           [False,  True, False],\n",
       "           [False,  True,  True]]],\n",
       " \n",
       " \n",
       "         [[[ True, False, False],\n",
       "           [False, False,  True],\n",
       "           [False, False, False]],\n",
       " \n",
       "          [[False,  True, False],\n",
       "           [ True,  True, False],\n",
       "           [False, False, False]],\n",
       " \n",
       "          [[ True, False, False],\n",
       "           [False,  True, False],\n",
       "           [False, False,  True]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ True,  True, False],\n",
       "           [False, False, False],\n",
       "           [ True, False, False]],\n",
       " \n",
       "          [[ True, False, False],\n",
       "           [False,  True, False],\n",
       "           [ True,  True, False]],\n",
       " \n",
       "          [[False,  True, False],\n",
       "           [False, False, False],\n",
       "           [False,  True,  True]]],\n",
       " \n",
       " \n",
       "         [[[ True, False, False],\n",
       "           [ True,  True, False],\n",
       "           [False, False, False]],\n",
       " \n",
       "          [[False,  True,  True],\n",
       "           [False, False,  True],\n",
       "           [False, False, False]],\n",
       " \n",
       "          [[ True,  True, False],\n",
       "           [False,  True, False],\n",
       "           [False,  True, False]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[False, False, False],\n",
       "           [ True, False, False],\n",
       "           [ True,  True,  True]],\n",
       " \n",
       "          [[False,  True, False],\n",
       "           [False, False, False],\n",
       "           [False, False, False]],\n",
       " \n",
       "          [[False,  True, False],\n",
       "           [False,  True, False],\n",
       "           [False, False,  True]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[False,  True, False],\n",
       "           [False, False, False],\n",
       "           [False, False, False]],\n",
       " \n",
       "          [[False, False,  True],\n",
       "           [False, False,  True],\n",
       "           [False, False, False]],\n",
       " \n",
       "          [[False,  True,  True],\n",
       "           [False, False, False],\n",
       "           [ True,  True, False]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ True,  True, False],\n",
       "           [ True, False, False],\n",
       "           [False, False, False]],\n",
       " \n",
       "          [[False, False,  True],\n",
       "           [ True, False, False],\n",
       "           [False, False,  True]],\n",
       " \n",
       "          [[ True, False, False],\n",
       "           [False, False, False],\n",
       "           [False, False, False]]],\n",
       " \n",
       " \n",
       "         [[[ True,  True, False],\n",
       "           [False, False, False],\n",
       "           [False,  True,  True]],\n",
       " \n",
       "          [[False, False,  True],\n",
       "           [False, False, False],\n",
       "           [False, False, False]],\n",
       " \n",
       "          [[False, False, False],\n",
       "           [False,  True, False],\n",
       "           [False,  True, False]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ True,  True,  True],\n",
       "           [False,  True,  True],\n",
       "           [ True, False,  True]],\n",
       " \n",
       "          [[False, False, False],\n",
       "           [False,  True,  True],\n",
       "           [False, False,  True]],\n",
       " \n",
       "          [[False, False, False],\n",
       "           [ True, False,  True],\n",
       "           [False, False, False]]],\n",
       " \n",
       " \n",
       "         [[[ True, False,  True],\n",
       "           [False,  True,  True],\n",
       "           [ True, False,  True]],\n",
       " \n",
       "          [[ True,  True, False],\n",
       "           [ True,  True, False],\n",
       "           [False, False,  True]],\n",
       " \n",
       "          [[False,  True, False],\n",
       "           [False, False, False],\n",
       "           [False, False, False]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[False, False,  True],\n",
       "           [ True, False, False],\n",
       "           [False, False, False]],\n",
       " \n",
       "          [[False,  True,  True],\n",
       "           [ True,  True, False],\n",
       "           [ True, False, False]],\n",
       " \n",
       "          [[False,  True, False],\n",
       "           [False, False,  True],\n",
       "           [ True, False, False]]]], device='cuda:0'),\n",
       " tensor([[False, False, False,  ..., False, False,  True],\n",
       "         [False, False, False,  ..., False, False, False],\n",
       "         [False, False, False,  ..., False, False, False],\n",
       "         ...,\n",
       "         [False, False, False,  ..., False,  True, False],\n",
       "         [False, False, False,  ..., False, False, False],\n",
       "         [ True, False,  True,  ..., False, False, False]], device='cuda:0'),\n",
       " None]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pruner.backward_masks"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
