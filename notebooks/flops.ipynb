{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.multiprocessing as mp\n",
    "import torch.distributed as dist\n",
    "from torch.nn.parallel import DistributedDataParallel\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import pytorch_lightning as pl\n",
    "import random\n",
    "import dotenv\n",
    "import omegaconf\n",
    "import hydra\n",
    "import logging\n",
    "from typing import List\n",
    "\n",
    "import wandb\n",
    "from datetime import date\n",
    "import dotenv\n",
    "import os\n",
    "import pathlib\n",
    "from typing import Dict, Any\n",
    "from copy import deepcopy\n",
    "\n",
    "from rigl_torch.models import ModelFactory\n",
    "from rigl_torch.rigl_scheduler import RigLScheduler\n",
    "from rigl_torch.rigl_constant_fan import RigLConstFanScheduler\n",
    "from rigl_torch.datasets import get_dataloaders\n",
    "from rigl_torch.optim import (\n",
    "    get_optimizer,\n",
    "    get_lr_scheduler,\n",
    ")\n",
    "from rigl_torch.utils.rigl_utils import get_names_and_W\n",
    "from rigl_torch.utils.checkpoint import Checkpoint\n",
    "from rigl_torch.utils.rigl_utils import get_T_end, get_fan_in_after_ablation, get_conv_idx_from_flat_idx\n",
    "from hydra import initialize, compose\n",
    "\n",
    "from fvcore.nn import FlopCountAnalysis\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pruner_model_loader(dense_alloc, model, dataset):\n",
    "    with initialize(\"../configs\", version_base=\"1.2.0\"):\n",
    "        cfg = compose(\n",
    "            \"config.yaml\",\n",
    "            overrides=[\n",
    "                f\"dataset={dataset}\",\n",
    "                \"compute.distributed=False\",\n",
    "                f\"model={model}\",\n",
    "                f\"rigl.dense_allocation={dense_alloc}\",\n",
    "                ])\n",
    "    dotenv.load_dotenv(\"../.env\")\n",
    "    os.environ[\"IMAGE_NET_PATH\"]\n",
    "\n",
    "\n",
    "    rank=0\n",
    "    checkpoint=None\n",
    "    if checkpoint is not None:\n",
    "        run_id = checkpoint.run_id\n",
    "        optimizer_state = checkpoint.optimizer\n",
    "        scheduler_state = checkpoint.scheduler\n",
    "        pruner_state = checkpoint.pruner\n",
    "        model_state = checkpoint.model\n",
    "        cfg = checkpoint.cfg\n",
    "    else:\n",
    "        run_id, optimizer_state, scheduler_state, pruner_state, model_state = (\n",
    "            None,\n",
    "            None,\n",
    "            None,\n",
    "            None,\n",
    "            None,\n",
    "        )\n",
    "\n",
    "    print(cfg.compute)\n",
    "    cfg.compute.distributed=False\n",
    "        \n",
    "    pl.seed_everything(cfg.training.seed)\n",
    "    use_cuda = not cfg.compute.no_cuda and torch.cuda.is_available()\n",
    "    if not use_cuda:\n",
    "        raise SystemError(\"GPU has stopped responding...waiting to die!\")\n",
    "        logger.warning(\n",
    "            \"Using CPU! Verify cfg.compute.no_cuda and \"\n",
    "            \"torch.cuda.is_available() are properly set if this is unexpected\"\n",
    "        )\n",
    "\n",
    "    if cfg.compute.distributed and use_cuda:\n",
    "        device = torch.device(f\"cuda:{rank}\")\n",
    "    else:\n",
    "        print(f\"loading to device rank: {rank}\")\n",
    "        device = torch.device(f\"cuda:{rank}\")\n",
    "    if not use_cuda:\n",
    "        device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "    train_loader, test_loader = get_dataloaders(cfg)\n",
    "\n",
    "    model = ModelFactory.load_model(\n",
    "        model=cfg.model.name, dataset=cfg.dataset.name\n",
    "    )\n",
    "    model.to(device)\n",
    "    if cfg.compute.distributed:\n",
    "        model = DistributedDataParallel(model, device_ids=[rank])\n",
    "    if model_state is not None:\n",
    "        try:\n",
    "            model.load_state_dict(model_state)\n",
    "        except RuntimeError:\n",
    "            model_state = checkpoint.get_single_process_model_state_from_distributed_state()\n",
    "            model.load_state_dict(model_state)\n",
    "            \n",
    "    optimizer = get_optimizer(cfg, model, state_dict=optimizer_state)\n",
    "    scheduler = get_lr_scheduler(cfg, optimizer, state_dict=scheduler_state)\n",
    "    pruner = None\n",
    "    if cfg.rigl.dense_allocation is not None:\n",
    "        T_end = get_T_end(cfg, [0 for _ in range(0,1251)])\n",
    "        if cfg.rigl.const_fan_in:\n",
    "            rigl_scheduler = RigLConstFanScheduler\n",
    "        else:\n",
    "            rigl_scheduler = RigLScheduler\n",
    "        pruner = rigl_scheduler(\n",
    "            model,\n",
    "            optimizer,\n",
    "            dense_allocation=cfg.rigl.dense_allocation,\n",
    "            alpha=cfg.rigl.alpha,\n",
    "            delta=cfg.rigl.delta,\n",
    "            static_topo=cfg.rigl.static_topo,\n",
    "            T_end=T_end,\n",
    "            ignore_linear_layers=cfg.rigl.ignore_linear_layers,\n",
    "            grad_accumulation_n=cfg.rigl.grad_accumulation_n,\n",
    "            sparsity_distribution=cfg.rigl.sparsity_distribution,\n",
    "            erk_power_scale=cfg.rigl.erk_power_scale,\n",
    "            state_dict=pruner_state,\n",
    "            filter_ablation_threshold=cfg.rigl.filter_ablation_threshold,\n",
    "            static_ablation=cfg.rigl.static_ablation,\n",
    "            dynamic_ablation=cfg.rigl.dynamic_ablation,\n",
    "            min_salient_weights_per_neuron=cfg.rigl.min_salient_weights_per_neuron,  # noqa\n",
    "            use_sparse_init=cfg.rigl.use_sparse_initialization,\n",
    "            init_method_str=cfg.rigl.init_method_str,\n",
    "            use_sparse_const_fan_in_for_ablation=cfg.rigl.use_sparse_const_fan_in_for_ablation,  # noqa\n",
    "        )\n",
    "        \n",
    "        step=0\n",
    "        return pruner, model, train_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_flops_df(model_name, dataset):\n",
    "    df = {k:[] for k in [\"rigl.dense_allocation\", \"flops\", \"model\",]}\n",
    "    for da in [0.01, 0.05, 0.0625, 0.1, 0.2, 0.25,]:\n",
    "        print(f\"Calculating with dense_alloc == {da}\")\n",
    "        pruner, model, train_loader = get_pruner_model_loader(da, model_name, dataset)\n",
    "        model.eval()\n",
    "        for data, _ in train_loader:\n",
    "            data = data[0].to(\"cpu\").reshape(1, *data[0].shape)\n",
    "            break\n",
    "        flops = FlopCountAnalysis(model.to(\"cpu\"),data)\n",
    "        total_flops = 0\n",
    "        S = pruner.S\n",
    "        names, W = get_names_and_W(model)\n",
    "        for name, counter in flops.by_module_and_operator().items():\n",
    "            if name in names:\n",
    "                if len(counter) != 1:\n",
    "                    raise ValueError(f\"Too many items found in {name}. Goodbye\")\n",
    "                f = list(counter.values())[0]\n",
    "                s = S[names.index(name)]\n",
    "                if s is None:\n",
    "                    s=1\n",
    "                total_flops += f*(1-s)\n",
    "        del model\n",
    "        del pruner\n",
    "        del train_loader\n",
    "        df[\"rigl.dense_allocation\"].append(da)\n",
    "        df[\"flops\"].append(total_flops)\n",
    "        df[\"model\"].append(model_name)\n",
    "    return pd.DataFrame(df)\n",
    "\n",
    "# df = get_flops_df(\"resnet50\", \"imagenet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'no_cuda': False, 'cuda_kwargs': {'num_workers': '${ oc.decode:${oc.env:NUM_WORKERS} }', 'pin_memory': True}, 'distributed': False, 'world_size': 4, 'dist_backend': 'nccl'}\n",
      "loading to device rank: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:/home/mike/condensed-sparsity/src/rigl_torch/models/model_factory.py:Loading model resnet50/imagenet using <function get_imagenet_resnet50 at 0x7f9881d5a200> with args: () and kwargs: {}\n"
     ]
    }
   ],
   "source": [
    "p, m, l = get_pruner_model_loader(0.01, \"resnet50\", \"imagenet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('input_size', 'kernel_shape', 'strides', 'padding', 'use_bias', 'activation')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from micronet_challenge.counting import *\n",
    "import torch.nn as nn\n",
    "Conv2D._fields\n",
    " \n",
    "def get_conv_op(conv: nn.Conv2d, input):\n",
    "    return Conv2D(\n",
    "        input_size=input.shape[1],\n",
    "        kernel_shape=\n",
    "    )\n",
    "    \n",
    "\n",
    "# def get_op()\n",
    "\n",
    "\n",
    "# for name, child in model.named_children():\n",
    "#     print(type(child))\n",
    "#     break\n",
    "# # names, _ = get_names_and_W(model)\n",
    "# type(w[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['training', '_parameters', '_buffers', '_non_persistent_buffers_set', '_backward_hooks', '_is_full_backward_hook', '_forward_hooks', '_forward_pre_hooks', '_state_dict_hooks', '_load_state_dict_pre_hooks', '_load_state_dict_post_hooks', '_modules', 'in_channels', 'out_channels', 'kernel_size', 'stride', 'padding', 'dilation', 'transposed', 'output_padding', 'groups', 'padding_mode', '_reversed_padding_repeated_twice'])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import List, Optional\n",
    "\n",
    "def get_names_and_children(\n",
    "    module,\n",
    "    parents: Optional[List] = None,\n",
    "    name_append:Optional[str] = None\n",
    "):\n",
    "    if parents is None:\n",
    "        parents =[]\n",
    "    \n",
    "    for name, child in module.named_children():\n",
    "    \n",
    "        return child\n",
    "        # if len(child._mod)\n",
    "        print(child._modules)\n",
    "\n",
    "child = get_names_and_children(m)\n",
    "child.__dict__.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.nn.modules.conv.Conv2d"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(child)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict()"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "child.__dict__[\"_modules\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_types = [torch.nn.Conv2d, torch.nn.Linear]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.nn.modules.linear.Linear"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modules.Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.nn.modules.conv.Conv2d"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modules.conv.Conv2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9940712038332824"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.by_operator()[\"conv\"]/df.total()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:fvcore.nn.jit_analysis:Unsupported operator aten::max_pool2d encountered 1 time(s)\n",
      "WARNING:fvcore.nn.jit_analysis:Unsupported operator aten::add_ encountered 16 time(s)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'': Counter({'conv': 4087136256,\n",
       "          'batch_norm': 22227968,\n",
       "          'adaptive_avg_pool2d': 100352,\n",
       "          'linear': 2048000}),\n",
       " 'conv1': Counter({'conv': 118013952}),\n",
       " 'bn1': Counter({'batch_norm': 1605632}),\n",
       " 'relu': Counter(),\n",
       " 'maxpool': Counter(),\n",
       " 'layer1': Counter({'conv': 667942912, 'batch_norm': 8830976}),\n",
       " 'layer1.0': Counter({'conv': 231211008, 'batch_norm': 4014080}),\n",
       " 'layer1.0.conv1': Counter({'conv': 12845056}),\n",
       " 'layer1.0.bn1': Counter({'batch_norm': 401408}),\n",
       " 'layer1.0.conv2': Counter({'conv': 115605504}),\n",
       " 'layer1.0.bn2': Counter({'batch_norm': 401408}),\n",
       " 'layer1.0.conv3': Counter({'conv': 51380224}),\n",
       " 'layer1.0.bn3': Counter({'batch_norm': 1605632}),\n",
       " 'layer1.0.relu': Counter(),\n",
       " 'layer1.0.downsample': Counter({'conv': 51380224, 'batch_norm': 1605632}),\n",
       " 'layer1.0.downsample.0': Counter({'conv': 51380224}),\n",
       " 'layer1.0.downsample.1': Counter({'batch_norm': 1605632}),\n",
       " 'layer1.1': Counter({'conv': 218365952, 'batch_norm': 2408448}),\n",
       " 'layer1.1.conv1': Counter({'conv': 51380224}),\n",
       " 'layer1.1.bn1': Counter({'batch_norm': 401408}),\n",
       " 'layer1.1.conv2': Counter({'conv': 115605504}),\n",
       " 'layer1.1.bn2': Counter({'batch_norm': 401408}),\n",
       " 'layer1.1.conv3': Counter({'conv': 51380224}),\n",
       " 'layer1.1.bn3': Counter({'batch_norm': 1605632}),\n",
       " 'layer1.1.relu': Counter(),\n",
       " 'layer1.2': Counter({'conv': 218365952, 'batch_norm': 2408448}),\n",
       " 'layer1.2.conv1': Counter({'conv': 51380224}),\n",
       " 'layer1.2.bn1': Counter({'batch_norm': 401408}),\n",
       " 'layer1.2.conv2': Counter({'conv': 115605504}),\n",
       " 'layer1.2.bn2': Counter({'batch_norm': 401408}),\n",
       " 'layer1.2.conv3': Counter({'conv': 51380224}),\n",
       " 'layer1.2.bn3': Counter({'batch_norm': 1605632}),\n",
       " 'layer1.2.relu': Counter(),\n",
       " 'layer2': Counter({'conv': 1027604480, 'batch_norm': 6221824}),\n",
       " 'layer2.0': Counter({'conv': 372506624, 'batch_norm': 2609152}),\n",
       " 'layer2.0.conv1': Counter({'conv': 102760448}),\n",
       " 'layer2.0.bn1': Counter({'batch_norm': 802816}),\n",
       " 'layer2.0.conv2': Counter({'conv': 115605504}),\n",
       " 'layer2.0.bn2': Counter({'batch_norm': 200704}),\n",
       " 'layer2.0.conv3': Counter({'conv': 51380224}),\n",
       " 'layer2.0.bn3': Counter({'batch_norm': 802816}),\n",
       " 'layer2.0.relu': Counter(),\n",
       " 'layer2.0.downsample': Counter({'conv': 102760448, 'batch_norm': 802816}),\n",
       " 'layer2.0.downsample.0': Counter({'conv': 102760448}),\n",
       " 'layer2.0.downsample.1': Counter({'batch_norm': 802816}),\n",
       " 'layer2.1': Counter({'conv': 218365952, 'batch_norm': 1204224}),\n",
       " 'layer2.1.conv1': Counter({'conv': 51380224}),\n",
       " 'layer2.1.bn1': Counter({'batch_norm': 200704}),\n",
       " 'layer2.1.conv2': Counter({'conv': 115605504}),\n",
       " 'layer2.1.bn2': Counter({'batch_norm': 200704}),\n",
       " 'layer2.1.conv3': Counter({'conv': 51380224}),\n",
       " 'layer2.1.bn3': Counter({'batch_norm': 802816}),\n",
       " 'layer2.1.relu': Counter(),\n",
       " 'layer2.2': Counter({'conv': 218365952, 'batch_norm': 1204224}),\n",
       " 'layer2.2.conv1': Counter({'conv': 51380224}),\n",
       " 'layer2.2.bn1': Counter({'batch_norm': 200704}),\n",
       " 'layer2.2.conv2': Counter({'conv': 115605504}),\n",
       " 'layer2.2.bn2': Counter({'batch_norm': 200704}),\n",
       " 'layer2.2.conv3': Counter({'conv': 51380224}),\n",
       " 'layer2.2.bn3': Counter({'batch_norm': 802816}),\n",
       " 'layer2.2.relu': Counter(),\n",
       " 'layer2.3': Counter({'conv': 218365952, 'batch_norm': 1204224}),\n",
       " 'layer2.3.conv1': Counter({'conv': 51380224}),\n",
       " 'layer2.3.bn1': Counter({'batch_norm': 200704}),\n",
       " 'layer2.3.conv2': Counter({'conv': 115605504}),\n",
       " 'layer2.3.bn2': Counter({'batch_norm': 200704}),\n",
       " 'layer2.3.conv3': Counter({'conv': 51380224}),\n",
       " 'layer2.3.bn3': Counter({'batch_norm': 802816}),\n",
       " 'layer2.3.relu': Counter(),\n",
       " 'layer3': Counter({'conv': 1464336384, 'batch_norm': 4315136}),\n",
       " 'layer3.0': Counter({'conv': 372506624, 'batch_norm': 1304576}),\n",
       " 'layer3.0.conv1': Counter({'conv': 102760448}),\n",
       " 'layer3.0.bn1': Counter({'batch_norm': 401408}),\n",
       " 'layer3.0.conv2': Counter({'conv': 115605504}),\n",
       " 'layer3.0.bn2': Counter({'batch_norm': 100352}),\n",
       " 'layer3.0.conv3': Counter({'conv': 51380224}),\n",
       " 'layer3.0.bn3': Counter({'batch_norm': 401408}),\n",
       " 'layer3.0.relu': Counter(),\n",
       " 'layer3.0.downsample': Counter({'conv': 102760448, 'batch_norm': 401408}),\n",
       " 'layer3.0.downsample.0': Counter({'conv': 102760448}),\n",
       " 'layer3.0.downsample.1': Counter({'batch_norm': 401408}),\n",
       " 'layer3.1': Counter({'conv': 218365952, 'batch_norm': 602112}),\n",
       " 'layer3.1.conv1': Counter({'conv': 51380224}),\n",
       " 'layer3.1.bn1': Counter({'batch_norm': 100352}),\n",
       " 'layer3.1.conv2': Counter({'conv': 115605504}),\n",
       " 'layer3.1.bn2': Counter({'batch_norm': 100352}),\n",
       " 'layer3.1.conv3': Counter({'conv': 51380224}),\n",
       " 'layer3.1.bn3': Counter({'batch_norm': 401408}),\n",
       " 'layer3.1.relu': Counter(),\n",
       " 'layer3.2': Counter({'conv': 218365952, 'batch_norm': 602112}),\n",
       " 'layer3.2.conv1': Counter({'conv': 51380224}),\n",
       " 'layer3.2.bn1': Counter({'batch_norm': 100352}),\n",
       " 'layer3.2.conv2': Counter({'conv': 115605504}),\n",
       " 'layer3.2.bn2': Counter({'batch_norm': 100352}),\n",
       " 'layer3.2.conv3': Counter({'conv': 51380224}),\n",
       " 'layer3.2.bn3': Counter({'batch_norm': 401408}),\n",
       " 'layer3.2.relu': Counter(),\n",
       " 'layer3.3': Counter({'conv': 218365952, 'batch_norm': 602112}),\n",
       " 'layer3.3.conv1': Counter({'conv': 51380224}),\n",
       " 'layer3.3.bn1': Counter({'batch_norm': 100352}),\n",
       " 'layer3.3.conv2': Counter({'conv': 115605504}),\n",
       " 'layer3.3.bn2': Counter({'batch_norm': 100352}),\n",
       " 'layer3.3.conv3': Counter({'conv': 51380224}),\n",
       " 'layer3.3.bn3': Counter({'batch_norm': 401408}),\n",
       " 'layer3.3.relu': Counter(),\n",
       " 'layer3.4': Counter({'conv': 218365952, 'batch_norm': 602112}),\n",
       " 'layer3.4.conv1': Counter({'conv': 51380224}),\n",
       " 'layer3.4.bn1': Counter({'batch_norm': 100352}),\n",
       " 'layer3.4.conv2': Counter({'conv': 115605504}),\n",
       " 'layer3.4.bn2': Counter({'batch_norm': 100352}),\n",
       " 'layer3.4.conv3': Counter({'conv': 51380224}),\n",
       " 'layer3.4.bn3': Counter({'batch_norm': 401408}),\n",
       " 'layer3.4.relu': Counter(),\n",
       " 'layer3.5': Counter({'conv': 218365952, 'batch_norm': 602112}),\n",
       " 'layer3.5.conv1': Counter({'conv': 51380224}),\n",
       " 'layer3.5.bn1': Counter({'batch_norm': 100352}),\n",
       " 'layer3.5.conv2': Counter({'conv': 115605504}),\n",
       " 'layer3.5.bn2': Counter({'batch_norm': 100352}),\n",
       " 'layer3.5.conv3': Counter({'conv': 51380224}),\n",
       " 'layer3.5.bn3': Counter({'batch_norm': 401408}),\n",
       " 'layer3.5.relu': Counter(),\n",
       " 'layer4': Counter({'conv': 809238528, 'batch_norm': 1254400}),\n",
       " 'layer4.0': Counter({'conv': 372506624, 'batch_norm': 652288}),\n",
       " 'layer4.0.conv1': Counter({'conv': 102760448}),\n",
       " 'layer4.0.bn1': Counter({'batch_norm': 200704}),\n",
       " 'layer4.0.conv2': Counter({'conv': 115605504}),\n",
       " 'layer4.0.bn2': Counter({'batch_norm': 50176}),\n",
       " 'layer4.0.conv3': Counter({'conv': 51380224}),\n",
       " 'layer4.0.bn3': Counter({'batch_norm': 200704}),\n",
       " 'layer4.0.relu': Counter(),\n",
       " 'layer4.0.downsample': Counter({'conv': 102760448, 'batch_norm': 200704}),\n",
       " 'layer4.0.downsample.0': Counter({'conv': 102760448}),\n",
       " 'layer4.0.downsample.1': Counter({'batch_norm': 200704}),\n",
       " 'layer4.1': Counter({'conv': 218365952, 'batch_norm': 301056}),\n",
       " 'layer4.1.conv1': Counter({'conv': 51380224}),\n",
       " 'layer4.1.bn1': Counter({'batch_norm': 50176}),\n",
       " 'layer4.1.conv2': Counter({'conv': 115605504}),\n",
       " 'layer4.1.bn2': Counter({'batch_norm': 50176}),\n",
       " 'layer4.1.conv3': Counter({'conv': 51380224}),\n",
       " 'layer4.1.bn3': Counter({'batch_norm': 200704}),\n",
       " 'layer4.1.relu': Counter(),\n",
       " 'layer4.2': Counter({'conv': 218365952, 'batch_norm': 301056}),\n",
       " 'layer4.2.conv1': Counter({'conv': 51380224}),\n",
       " 'layer4.2.bn1': Counter({'batch_norm': 50176}),\n",
       " 'layer4.2.conv2': Counter({'conv': 115605504}),\n",
       " 'layer4.2.bn2': Counter({'batch_norm': 50176}),\n",
       " 'layer4.2.conv3': Counter({'conv': 51380224}),\n",
       " 'layer4.2.bn3': Counter({'batch_norm': 200704}),\n",
       " 'layer4.2.relu': Counter(),\n",
       " 'avgpool': Counter({'adaptive_avg_pool2d': 100352}),\n",
       " 'fc': Counter({'linear': 2048000})}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.by_module_and_operator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99517038.63962848"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_idx = 0\n",
    "total_flops = 0\n",
    "modules_to_ignore = []\n",
    "S = pruner.S\n",
    "names, W = get_names_and_W(model)\n",
    "for name, counter in flops.by_module_and_operator().items():\n",
    "    if name in names:\n",
    "        if len(counter) != 1:\n",
    "            raise ValueError(\"?\")\n",
    "        f = list(counter.values())[0]\n",
    "        s = S[names.index(name)]\n",
    "        if s is None:\n",
    "            s=1\n",
    "        total_flops += f*(1-s)\n",
    "\n",
    "total_flops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.4336050967188756"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(99517038.63962848 / 4089284608)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.989667217"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "3989667217/1e9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.089284608"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "4089284608/1e9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99617390.63962793"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "4089284608-3989667217.360372"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4089284608"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total - flops.by_operator()['batch_norm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4089284608"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total - flops.by_operator()['batch_norm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.089284608"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "4089284608/1e9"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4089284608/1e9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.111512576"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "4111512576/1e9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "311512576.0"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "4111512576 - 3.8e9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| module                 | #parameters or shape   | #flops     |\n",
      "|:-----------------------|:-----------------------|:-----------|\n",
      "| model                  | 25.557M                | 0.531T     |\n",
      "|  conv1                 |  9.408K                |  15.106G   |\n",
      "|   conv1.weight         |   (64, 3, 7, 7)        |            |\n",
      "|  bn1                   |  0.128K                |  0.514G    |\n",
      "|   bn1.weight           |   (64,)                |            |\n",
      "|   bn1.bias             |   (64,)                |            |\n",
      "|  layer1                |  0.216M                |  88.323G   |\n",
      "|   layer1.0             |   75.008K              |   30.88G   |\n",
      "|    layer1.0.conv1      |    4.096K              |    1.644G  |\n",
      "|    layer1.0.bn1        |    0.128K              |    0.128G  |\n",
      "|    layer1.0.conv2      |    36.864K             |    14.798G |\n",
      "|    layer1.0.bn2        |    0.128K              |    0.128G  |\n",
      "|    layer1.0.conv3      |    16.384K             |    6.577G  |\n",
      "|    layer1.0.bn3        |    0.512K              |    0.514G  |\n",
      "|    layer1.0.downsample |    16.896K             |    7.09G   |\n",
      "|   layer1.1             |   70.4K                |   28.722G  |\n",
      "|    layer1.1.conv1      |    16.384K             |    6.577G  |\n",
      "|    layer1.1.bn1        |    0.128K              |    0.128G  |\n",
      "|    layer1.1.conv2      |    36.864K             |    14.798G |\n",
      "|    layer1.1.bn2        |    0.128K              |    0.128G  |\n",
      "|    layer1.1.conv3      |    16.384K             |    6.577G  |\n",
      "|    layer1.1.bn3        |    0.512K              |    0.514G  |\n",
      "|   layer1.2             |   70.4K                |   28.722G  |\n",
      "|    layer1.2.conv1      |    16.384K             |    6.577G  |\n",
      "|    layer1.2.bn1        |    0.128K              |    0.128G  |\n",
      "|    layer1.2.conv2      |    36.864K             |    14.798G |\n",
      "|    layer1.2.bn2        |    0.128K              |    0.128G  |\n",
      "|    layer1.2.conv3      |    16.384K             |    6.577G  |\n",
      "|    layer1.2.bn3        |    0.512K              |    0.514G  |\n",
      "|  layer2                |  1.22M                 |  0.134T    |\n",
      "|   layer2.0             |   0.379M               |   48.516G  |\n",
      "|    layer2.0.conv1      |    32.768K             |    13.153G |\n",
      "|    layer2.0.bn1        |    0.256K              |    0.257G  |\n",
      "|    layer2.0.conv2      |    0.147M              |    14.798G |\n",
      "|    layer2.0.bn2        |    0.256K              |    64.225M |\n",
      "|    layer2.0.conv3      |    65.536K             |    6.577G  |\n",
      "|    layer2.0.bn3        |    1.024K              |    0.257G  |\n",
      "|    layer2.0.downsample |    0.132M              |    13.41G  |\n",
      "|   layer2.1             |   0.28M                |   28.336G  |\n",
      "|    layer2.1.conv1      |    65.536K             |    6.577G  |\n",
      "|    layer2.1.bn1        |    0.256K              |    64.225M |\n",
      "|    layer2.1.conv2      |    0.147M              |    14.798G |\n",
      "|    layer2.1.bn2        |    0.256K              |    64.225M |\n",
      "|    layer2.1.conv3      |    65.536K             |    6.577G  |\n",
      "|    layer2.1.bn3        |    1.024K              |    0.257G  |\n",
      "|   layer2.2             |   0.28M                |   28.336G  |\n",
      "|    layer2.2.conv1      |    65.536K             |    6.577G  |\n",
      "|    layer2.2.bn1        |    0.256K              |    64.225M |\n",
      "|    layer2.2.conv2      |    0.147M              |    14.798G |\n",
      "|    layer2.2.bn2        |    0.256K              |    64.225M |\n",
      "|    layer2.2.conv3      |    65.536K             |    6.577G  |\n",
      "|    layer2.2.bn3        |    1.024K              |    0.257G  |\n",
      "|   layer2.3             |   0.28M                |   28.336G  |\n",
      "|    layer2.3.conv1      |    65.536K             |    6.577G  |\n",
      "|    layer2.3.bn1        |    0.256K              |    64.225M |\n",
      "|    layer2.3.conv2      |    0.147M              |    14.798G |\n",
      "|    layer2.3.bn2        |    0.256K              |    64.225M |\n",
      "|    layer2.3.conv3      |    65.536K             |    6.577G  |\n",
      "|    layer2.3.bn3        |    1.024K              |    0.257G  |\n",
      "|  layer3                |  7.098M                |  0.189T    |\n",
      "|   layer3.0             |   1.512M               |   48.098G  |\n",
      "|    layer3.0.conv1      |    0.131M              |    13.153G |\n",
      "|    layer3.0.bn1        |    0.512K              |    0.128G  |\n",
      "|    layer3.0.conv2      |    0.59M               |    14.798G |\n",
      "|    layer3.0.bn2        |    0.512K              |    32.113M |\n",
      "|    layer3.0.conv3      |    0.262M              |    6.577G  |\n",
      "|    layer3.0.bn3        |    2.048K              |    0.128G  |\n",
      "|    layer3.0.downsample |    0.526M              |    13.282G |\n",
      "|   layer3.1             |   1.117M               |   28.144G  |\n",
      "|    layer3.1.conv1      |    0.262M              |    6.577G  |\n",
      "|    layer3.1.bn1        |    0.512K              |    32.113M |\n",
      "|    layer3.1.conv2      |    0.59M               |    14.798G |\n",
      "|    layer3.1.bn2        |    0.512K              |    32.113M |\n",
      "|    layer3.1.conv3      |    0.262M              |    6.577G  |\n",
      "|    layer3.1.bn3        |    2.048K              |    0.128G  |\n",
      "|   layer3.2             |   1.117M               |   28.144G  |\n",
      "|    layer3.2.conv1      |    0.262M              |    6.577G  |\n",
      "|    layer3.2.bn1        |    0.512K              |    32.113M |\n",
      "|    layer3.2.conv2      |    0.59M               |    14.798G |\n",
      "|    layer3.2.bn2        |    0.512K              |    32.113M |\n",
      "|    layer3.2.conv3      |    0.262M              |    6.577G  |\n",
      "|    layer3.2.bn3        |    2.048K              |    0.128G  |\n",
      "|   layer3.3             |   1.117M               |   28.144G  |\n",
      "|    layer3.3.conv1      |    0.262M              |    6.577G  |\n",
      "|    layer3.3.bn1        |    0.512K              |    32.113M |\n",
      "|    layer3.3.conv2      |    0.59M               |    14.798G |\n",
      "|    layer3.3.bn2        |    0.512K              |    32.113M |\n",
      "|    layer3.3.conv3      |    0.262M              |    6.577G  |\n",
      "|    layer3.3.bn3        |    2.048K              |    0.128G  |\n",
      "|   layer3.4             |   1.117M               |   28.144G  |\n",
      "|    layer3.4.conv1      |    0.262M              |    6.577G  |\n",
      "|    layer3.4.bn1        |    0.512K              |    32.113M |\n",
      "|    layer3.4.conv2      |    0.59M               |    14.798G |\n",
      "|    layer3.4.bn2        |    0.512K              |    32.113M |\n",
      "|    layer3.4.conv3      |    0.262M              |    6.577G  |\n",
      "|    layer3.4.bn3        |    2.048K              |    0.128G  |\n",
      "|   layer3.5             |   1.117M               |   28.144G  |\n",
      "|    layer3.5.conv1      |    0.262M              |    6.577G  |\n",
      "|    layer3.5.bn1        |    0.512K              |    32.113M |\n",
      "|    layer3.5.conv2      |    0.59M               |    14.798G |\n",
      "|    layer3.5.bn2        |    0.512K              |    32.113M |\n",
      "|    layer3.5.conv3      |    0.262M              |    6.577G  |\n",
      "|    layer3.5.bn3        |    2.048K              |    0.128G  |\n",
      "|  layer4                |  14.965M               |  0.104T    |\n",
      "|   layer4.0             |   6.04M                |   47.89G   |\n",
      "|    layer4.0.conv1      |    0.524M              |    13.153G |\n",
      "|    layer4.0.bn1        |    1.024K              |    64.225M |\n",
      "|    layer4.0.conv2      |    2.359M              |    14.798G |\n",
      "|    layer4.0.bn2        |    1.024K              |    16.056M |\n",
      "|    layer4.0.conv3      |    1.049M              |    6.577G  |\n",
      "|    layer4.0.bn3        |    4.096K              |    64.225M |\n",
      "|    layer4.0.downsample |    2.101M              |    13.218G |\n",
      "|   layer4.1             |   4.463M               |   28.047G  |\n",
      "|    layer4.1.conv1      |    1.049M              |    6.577G  |\n",
      "|    layer4.1.bn1        |    1.024K              |    16.056M |\n",
      "|    layer4.1.conv2      |    2.359M              |    14.798G |\n",
      "|    layer4.1.bn2        |    1.024K              |    16.056M |\n",
      "|    layer4.1.conv3      |    1.049M              |    6.577G  |\n",
      "|    layer4.1.bn3        |    4.096K              |    64.225M |\n",
      "|   layer4.2             |   4.463M               |   28.047G  |\n",
      "|    layer4.2.conv1      |    1.049M              |    6.577G  |\n",
      "|    layer4.2.bn1        |    1.024K              |    16.056M |\n",
      "|    layer4.2.conv2      |    2.359M              |    14.798G |\n",
      "|    layer4.2.bn2        |    1.024K              |    16.056M |\n",
      "|    layer4.2.conv3      |    1.049M              |    6.577G  |\n",
      "|    layer4.2.bn3        |    4.096K              |    64.225M |\n",
      "|  fc                    |  2.049M                |  0.262G    |\n",
      "|   fc.weight            |   (1000, 2048)         |            |\n",
      "|   fc.bias              |   (1000,)              |            |\n",
      "|  avgpool               |                        |  12.845M   |\n"
     ]
    }
   ],
   "source": [
    "from fvcore.nn import flop_count_table\n",
    "\n",
    "print(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: module Bottleneck is treated as a zero-op.\n",
      "Warning: module ResNet is treated as a zero-op.\n",
      "ResNet(\n",
      "  25.56 M, 100.000% Params, 4.12 GMac, 100.000% MACs, \n",
      "  (conv1): Conv2d(9.41 k, 0.037% Params, 118.01 MMac, 2.863% MACs, 3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(128, 0.001% Params, 1.61 MMac, 0.039% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(0, 0.000% Params, 802.82 KMac, 0.019% MACs, inplace=True)\n",
      "  (maxpool): MaxPool2d(0, 0.000% Params, 802.82 KMac, 0.019% MACs, kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    215.81 k, 0.844% Params, 680.39 MMac, 16.507% MACs, \n",
      "    (0): Bottleneck(\n",
      "      75.01 k, 0.293% Params, 236.43 MMac, 5.736% MACs, \n",
      "      (conv1): Conv2d(4.1 k, 0.016% Params, 12.85 MMac, 0.312% MACs, 64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, 0.001% Params, 401.41 KMac, 0.010% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(36.86 k, 0.144% Params, 115.61 MMac, 2.805% MACs, 64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, 0.001% Params, 401.41 KMac, 0.010% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(16.38 k, 0.064% Params, 51.38 MMac, 1.247% MACs, 64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, 0.002% Params, 1.61 MMac, 0.039% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(0, 0.000% Params, 1.2 MMac, 0.029% MACs, inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        16.9 k, 0.066% Params, 52.99 MMac, 1.285% MACs, \n",
      "        (0): Conv2d(16.38 k, 0.064% Params, 51.38 MMac, 1.247% MACs, 64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(512, 0.002% Params, 1.61 MMac, 0.039% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      70.4 k, 0.275% Params, 221.98 MMac, 5.385% MACs, \n",
      "      (conv1): Conv2d(16.38 k, 0.064% Params, 51.38 MMac, 1.247% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, 0.001% Params, 401.41 KMac, 0.010% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(36.86 k, 0.144% Params, 115.61 MMac, 2.805% MACs, 64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, 0.001% Params, 401.41 KMac, 0.010% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(16.38 k, 0.064% Params, 51.38 MMac, 1.247% MACs, 64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, 0.002% Params, 1.61 MMac, 0.039% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(0, 0.000% Params, 1.2 MMac, 0.029% MACs, inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      70.4 k, 0.275% Params, 221.98 MMac, 5.385% MACs, \n",
      "      (conv1): Conv2d(16.38 k, 0.064% Params, 51.38 MMac, 1.247% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, 0.001% Params, 401.41 KMac, 0.010% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(36.86 k, 0.144% Params, 115.61 MMac, 2.805% MACs, 64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, 0.001% Params, 401.41 KMac, 0.010% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(16.38 k, 0.064% Params, 51.38 MMac, 1.247% MACs, 64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, 0.002% Params, 1.61 MMac, 0.039% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(0, 0.000% Params, 1.2 MMac, 0.029% MACs, inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    1.22 M, 4.772% Params, 1.04 GMac, 25.147% MACs, \n",
      "    (0): Bottleneck(\n",
      "      379.39 k, 1.484% Params, 376.02 MMac, 9.122% MACs, \n",
      "      (conv1): Conv2d(32.77 k, 0.128% Params, 102.76 MMac, 2.493% MACs, 256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, 0.001% Params, 802.82 KMac, 0.019% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(147.46 k, 0.577% Params, 115.61 MMac, 2.805% MACs, 128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, 0.001% Params, 200.7 KMac, 0.005% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(65.54 k, 0.256% Params, 51.38 MMac, 1.247% MACs, 128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1.02 k, 0.004% Params, 802.82 KMac, 0.019% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(0, 0.000% Params, 903.17 KMac, 0.022% MACs, inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        132.1 k, 0.517% Params, 103.56 MMac, 2.512% MACs, \n",
      "        (0): Conv2d(131.07 k, 0.513% Params, 102.76 MMac, 2.493% MACs, 256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(1.02 k, 0.004% Params, 802.82 KMac, 0.019% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      280.06 k, 1.096% Params, 220.17 MMac, 5.341% MACs, \n",
      "      (conv1): Conv2d(65.54 k, 0.256% Params, 51.38 MMac, 1.247% MACs, 512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, 0.001% Params, 200.7 KMac, 0.005% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(147.46 k, 0.577% Params, 115.61 MMac, 2.805% MACs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, 0.001% Params, 200.7 KMac, 0.005% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(65.54 k, 0.256% Params, 51.38 MMac, 1.247% MACs, 128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1.02 k, 0.004% Params, 802.82 KMac, 0.019% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(0, 0.000% Params, 602.11 KMac, 0.015% MACs, inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      280.06 k, 1.096% Params, 220.17 MMac, 5.341% MACs, \n",
      "      (conv1): Conv2d(65.54 k, 0.256% Params, 51.38 MMac, 1.247% MACs, 512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, 0.001% Params, 200.7 KMac, 0.005% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(147.46 k, 0.577% Params, 115.61 MMac, 2.805% MACs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, 0.001% Params, 200.7 KMac, 0.005% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(65.54 k, 0.256% Params, 51.38 MMac, 1.247% MACs, 128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1.02 k, 0.004% Params, 802.82 KMac, 0.019% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(0, 0.000% Params, 602.11 KMac, 0.015% MACs, inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      280.06 k, 1.096% Params, 220.17 MMac, 5.341% MACs, \n",
      "      (conv1): Conv2d(65.54 k, 0.256% Params, 51.38 MMac, 1.247% MACs, 512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, 0.001% Params, 200.7 KMac, 0.005% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(147.46 k, 0.577% Params, 115.61 MMac, 2.805% MACs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, 0.001% Params, 200.7 KMac, 0.005% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(65.54 k, 0.256% Params, 51.38 MMac, 1.247% MACs, 128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1.02 k, 0.004% Params, 802.82 KMac, 0.019% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(0, 0.000% Params, 602.11 KMac, 0.015% MACs, inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    7.1 M, 27.775% Params, 1.47 GMac, 35.678% MACs, \n",
      "    (0): Bottleneck(\n",
      "      1.51 M, 5.918% Params, 374.26 MMac, 9.080% MACs, \n",
      "      (conv1): Conv2d(131.07 k, 0.513% Params, 102.76 MMac, 2.493% MACs, 512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, 0.002% Params, 401.41 KMac, 0.010% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(589.82 k, 2.308% Params, 115.61 MMac, 2.805% MACs, 256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, 0.002% Params, 100.35 KMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(262.14 k, 1.026% Params, 51.38 MMac, 1.247% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2.05 k, 0.008% Params, 401.41 KMac, 0.010% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(0, 0.000% Params, 451.58 KMac, 0.011% MACs, inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        526.34 k, 2.059% Params, 103.16 MMac, 2.503% MACs, \n",
      "        (0): Conv2d(524.29 k, 2.051% Params, 102.76 MMac, 2.493% MACs, 512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(2.05 k, 0.008% Params, 401.41 KMac, 0.010% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      1.12 M, 4.371% Params, 219.27 MMac, 5.320% MACs, \n",
      "      (conv1): Conv2d(262.14 k, 1.026% Params, 51.38 MMac, 1.247% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, 0.002% Params, 100.35 KMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(589.82 k, 2.308% Params, 115.61 MMac, 2.805% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, 0.002% Params, 100.35 KMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(262.14 k, 1.026% Params, 51.38 MMac, 1.247% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2.05 k, 0.008% Params, 401.41 KMac, 0.010% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.007% MACs, inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      1.12 M, 4.371% Params, 219.27 MMac, 5.320% MACs, \n",
      "      (conv1): Conv2d(262.14 k, 1.026% Params, 51.38 MMac, 1.247% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, 0.002% Params, 100.35 KMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(589.82 k, 2.308% Params, 115.61 MMac, 2.805% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, 0.002% Params, 100.35 KMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(262.14 k, 1.026% Params, 51.38 MMac, 1.247% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2.05 k, 0.008% Params, 401.41 KMac, 0.010% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.007% MACs, inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      1.12 M, 4.371% Params, 219.27 MMac, 5.320% MACs, \n",
      "      (conv1): Conv2d(262.14 k, 1.026% Params, 51.38 MMac, 1.247% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, 0.002% Params, 100.35 KMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(589.82 k, 2.308% Params, 115.61 MMac, 2.805% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, 0.002% Params, 100.35 KMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(262.14 k, 1.026% Params, 51.38 MMac, 1.247% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2.05 k, 0.008% Params, 401.41 KMac, 0.010% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.007% MACs, inplace=True)\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      1.12 M, 4.371% Params, 219.27 MMac, 5.320% MACs, \n",
      "      (conv1): Conv2d(262.14 k, 1.026% Params, 51.38 MMac, 1.247% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, 0.002% Params, 100.35 KMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(589.82 k, 2.308% Params, 115.61 MMac, 2.805% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, 0.002% Params, 100.35 KMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(262.14 k, 1.026% Params, 51.38 MMac, 1.247% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2.05 k, 0.008% Params, 401.41 KMac, 0.010% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.007% MACs, inplace=True)\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      1.12 M, 4.371% Params, 219.27 MMac, 5.320% MACs, \n",
      "      (conv1): Conv2d(262.14 k, 1.026% Params, 51.38 MMac, 1.247% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, 0.002% Params, 100.35 KMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(589.82 k, 2.308% Params, 115.61 MMac, 2.805% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, 0.002% Params, 100.35 KMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(262.14 k, 1.026% Params, 51.38 MMac, 1.247% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2.05 k, 0.008% Params, 401.41 KMac, 0.010% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.007% MACs, inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    14.96 M, 58.554% Params, 811.02 MMac, 19.676% MACs, \n",
      "    (0): Bottleneck(\n",
      "      6.04 M, 23.632% Params, 373.38 MMac, 9.059% MACs, \n",
      "      (conv1): Conv2d(524.29 k, 2.051% Params, 102.76 MMac, 2.493% MACs, 1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(1.02 k, 0.004% Params, 200.7 KMac, 0.005% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(2.36 M, 9.231% Params, 115.61 MMac, 2.805% MACs, 512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(1.02 k, 0.004% Params, 50.18 KMac, 0.001% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(1.05 M, 4.103% Params, 51.38 MMac, 1.247% MACs, 512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(4.1 k, 0.016% Params, 200.7 KMac, 0.005% MACs, 2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(0, 0.000% Params, 225.79 KMac, 0.005% MACs, inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        2.1 M, 8.222% Params, 102.96 MMac, 2.498% MACs, \n",
      "        (0): Conv2d(2.1 M, 8.206% Params, 102.76 MMac, 2.493% MACs, 1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(4.1 k, 0.016% Params, 200.7 KMac, 0.005% MACs, 2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      4.46 M, 17.461% Params, 218.82 MMac, 5.309% MACs, \n",
      "      (conv1): Conv2d(1.05 M, 4.103% Params, 51.38 MMac, 1.247% MACs, 2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(1.02 k, 0.004% Params, 50.18 KMac, 0.001% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(2.36 M, 9.231% Params, 115.61 MMac, 2.805% MACs, 512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(1.02 k, 0.004% Params, 50.18 KMac, 0.001% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(1.05 M, 4.103% Params, 51.38 MMac, 1.247% MACs, 512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(4.1 k, 0.016% Params, 200.7 KMac, 0.005% MACs, 2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(0, 0.000% Params, 150.53 KMac, 0.004% MACs, inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      4.46 M, 17.461% Params, 218.82 MMac, 5.309% MACs, \n",
      "      (conv1): Conv2d(1.05 M, 4.103% Params, 51.38 MMac, 1.247% MACs, 2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(1.02 k, 0.004% Params, 50.18 KMac, 0.001% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(2.36 M, 9.231% Params, 115.61 MMac, 2.805% MACs, 512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(1.02 k, 0.004% Params, 50.18 KMac, 0.001% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(1.05 M, 4.103% Params, 51.38 MMac, 1.247% MACs, 512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(4.1 k, 0.016% Params, 200.7 KMac, 0.005% MACs, 2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(0, 0.000% Params, 150.53 KMac, 0.004% MACs, inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 100.35 KMac, 0.002% MACs, output_size=(1, 1))\n",
      "  (fc): Linear(2.05 M, 8.017% Params, 2.05 MMac, 0.050% MACs, in_features=2048, out_features=1000, bias=True)\n",
      ")\n",
      "4.12 GMac\n"
     ]
    }
   ],
   "source": [
    "from ptflops import get_model_complexity_info\n",
    "macs, params = get_model_complexity_info(model, (3, 224, 224), as_strings=True,\n",
    "                                           print_per_layer_stat=True, verbose=True)\n",
    "print(macs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " checkpoint=None\n",
    "    rank=1\n",
    "\n",
    "    if checkpoint is not None:\n",
    "        run_id = checkpoint.run_id\n",
    "        optimizer_state = checkpoint.optimizer\n",
    "        scheduler_state = checkpoint.scheduler\n",
    "        pruner_state = checkpoint.pruner\n",
    "        model_state = checkpoint.model\n",
    "        cfg = checkpoint.cfg\n",
    "    else:\n",
    "        run_id, optimizer_state, scheduler_state, pruner_state, model_state = (\n",
    "            None,\n",
    "            None,\n",
    "            None,\n",
    "            None,\n",
    "            None,\n",
    "        )\n",
    "\n",
    "    print(cfg.compute)\n",
    "    cfg.compute.distributed=False\n",
    "        \n",
    "    pl.seed_everything(cfg.training.seed)\n",
    "    use_cuda = not cfg.compute.no_cuda and torch.cuda.is_available()\n",
    "    if not use_cuda:\n",
    "        raise SystemError(\"GPU has stopped responding...waiting to die!\")\n",
    "        logger.warning(\n",
    "            \"Using CPU! Verify cfg.compute.no_cuda and \"\n",
    "            \"torch.cuda.is_available() are properly set if this is unexpected\"\n",
    "        )\n",
    "\n",
    "    if cfg.compute.distributed and use_cuda:\n",
    "        device = torch.device(f\"cuda:{rank}\")\n",
    "    else:\n",
    "        print(f\"loading to device rank: {rank}\")\n",
    "        device = torch.device(f\"cuda:{rank}\")\n",
    "    if not use_cuda:\n",
    "        device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "    # train_loader, test_loader = get_dataloaders(cfg)\n",
    "\n",
    "    model = ModelFactory.load_model(\n",
    "        model=cfg.model.name, dataset=cfg.dataset.name, diet=cfg.rigl.diet\n",
    "    )\n",
    "    model.to(device)\n",
    "    if cfg.compute.distributed:\n",
    "        model = DistributedDataParallel(model, device_ids=[rank])\n",
    "    if model_state is not None:\n",
    "        try:\n",
    "            model.load_state_dict(model_state)\n",
    "        except RuntimeError:\n",
    "            model_state = checkpoint.get_single_process_model_state_from_distributed_state()\n",
    "            model.load_state_dict(model_state)\n",
    "            \n",
    "    optimizer = get_optimizer(cfg, model, state_dict=optimizer_state)\n",
    "    scheduler = get_lr_scheduler(cfg, optimizer, state_dict=scheduler_state)\n",
    "    pruner = None\n",
    "    if cfg.rigl.dense_allocation is not None:\n",
    "        if cfg.rigl.dense_allocation is not None:\n",
    "            if cfg.model.name == \"skinny_resnet18\":\n",
    "                dense_allocation = (\n",
    "                    cfg.rigl.dense_allocation * cfg.model.sparsity_scale_factor\n",
    "                )\n",
    "                print(\n",
    "                    f\"Scaling {cfg.rigl.dense_allocation} by \"\n",
    "                    f\"{cfg.model.sparsity_scale_factor:.2f} for SkinnyResNet18 \"\n",
    "                    f\"New Dense Alloc == {dense_allocation:.6f}\"\n",
    "                )\n",
    "            else:\n",
    "                dense_allocation = cfg.rigl.dense_allocation\n",
    "            T_end = get_T_end(cfg, [0 for _ in range(0,1251)])\n",
    "            if cfg.rigl.const_fan_in:\n",
    "                rigl_scheduler = RigLConstFanScheduler\n",
    "            else:\n",
    "                rigl_scheduler = RigLScheduler\n",
    "            pruner = rigl_scheduler(\n",
    "                model,\n",
    "                optimizer,\n",
    "                dense_allocation=da,\n",
    "                alpha=cfg.rigl.alpha,\n",
    "                delta=cfg.rigl.delta,\n",
    "                static_topo=cfg.rigl.static_topo,\n",
    "                T_end=T_end,\n",
    "                ignore_linear_layers=cfg.rigl.ignore_linear_layers,\n",
    "                grad_accumulation_n=cfg.rigl.grad_accumulation_n,\n",
    "                sparsity_distribution=cfg.rigl.sparsity_distribution,\n",
    "                erk_power_scale=cfg.rigl.erk_power_scale,\n",
    "                state_dict=pruner_state,\n",
    "                filter_ablation_threshold=cfg.rigl.filter_ablation_threshold,\n",
    "                static_ablation=cfg.rigl.static_ablation,\n",
    "                dynamic_ablation=cfg.rigl.dynamic_ablation,\n",
    "                min_salient_weights_per_neuron=cfg.rigl.min_salient_weights_per_neuron,  # noqa\n",
    "                use_sparse_init=cfg.rigl.use_sparse_initialization,\n",
    "                init_method_str=cfg.rigl.init_method_str,\n",
    "                use_sparse_const_fan_in_for_ablation=cfg.rigl.use_sparse_const_fan_in_for_ablation,  # noqa\n",
    "            )\n",
    "            step=0\n",
    "    print(f\"Results for {1-da} sparsity...\")\n",
    "    els = []\n",
    "    non_zero=[]\n",
    "    for p in model.parameters():\n",
    "        els.append(p.numel())\n",
    "        non_zero.append(torch.count_nonzero(p))\n",
    "    s=torch.tensor(non_zero).sum().item()\n",
    "    n=torch.tensor(els).sum().item()\n",
    "    w_total = torch.tensor([torch.count_nonzero(w) for w in pruner.W]).sum()\n",
    "    params[\"dense_allocation\"].append(da)\n",
    "    params[\"parameters\"].append(s)\n",
    "    params[\"dense_params\"].append(n)\n",
    "    # print(f\"total el: {n}\")\n",
    "    # print(f\"non zero el: {s}\")\n",
    "    # print(f\"non zero weights only: {w_total}\")\n",
    "    # print(s/n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "INFO:/home/user/condensed-sparsity/src/rigl_torch/models/model_factory.py:Loading model resnet50/imagenet using <function get_imagenet_resnet50 at 0x7f5a9bebf910> with args: () and kwargs: {'diet': [17, 16, 17, 14, 16, 33, 31, 31, 32, 30, 65, 63, 63, 65, 63, 122, 124, 124, 114, 125, 0]}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'no_cuda': False, 'cuda_kwargs': {'num_workers': '${ oc.decode:${oc.env:NUM_WORKERS} }', 'pin_memory': True}, 'distributed': False, 'world_size': 4, 'dist_backend': 'nccl'}\n",
      "loading to device rank: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "INFO:/home/user/condensed-sparsity/src/rigl_torch/models/model_factory.py:Loading model resnet50/imagenet using <function get_imagenet_resnet50 at 0x7f5a9bebf910> with args: () and kwargs: {'diet': [17, 16, 17, 14, 16, 33, 31, 31, 32, 30, 65, 63, 63, 65, 63, 122, 124, 124, 114, 125, 0]}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for 0.99 sparsity...\n",
      "{'no_cuda': False, 'cuda_kwargs': {'num_workers': '${ oc.decode:${oc.env:NUM_WORKERS} }', 'pin_memory': True}, 'distributed': False, 'world_size': 4, 'dist_backend': 'nccl'}\n",
      "loading to device rank: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "INFO:/home/user/condensed-sparsity/src/rigl_torch/models/model_factory.py:Loading model resnet50/imagenet using <function get_imagenet_resnet50 at 0x7f5a9bebf910> with args: () and kwargs: {'diet': [17, 16, 17, 14, 16, 33, 31, 31, 32, 30, 65, 63, 63, 65, 63, 122, 124, 124, 114, 125, 0]}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for 0.95 sparsity...\n",
      "{'no_cuda': False, 'cuda_kwargs': {'num_workers': '${ oc.decode:${oc.env:NUM_WORKERS} }', 'pin_memory': True}, 'distributed': False, 'world_size': 4, 'dist_backend': 'nccl'}\n",
      "loading to device rank: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "INFO:/home/user/condensed-sparsity/src/rigl_torch/models/model_factory.py:Loading model resnet50/imagenet using <function get_imagenet_resnet50 at 0x7f5a9bebf910> with args: () and kwargs: {'diet': [17, 16, 17, 14, 16, 33, 31, 31, 32, 30, 65, 63, 63, 65, 63, 122, 124, 124, 114, 125, 0]}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for 0.9375 sparsity...\n",
      "{'no_cuda': False, 'cuda_kwargs': {'num_workers': '${ oc.decode:${oc.env:NUM_WORKERS} }', 'pin_memory': True}, 'distributed': False, 'world_size': 4, 'dist_backend': 'nccl'}\n",
      "loading to device rank: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:/home/user/condensed-sparsity/src/rigl_torch/rigl_scheduler.py:Sparsity of layer at index 1 set to 0.0\n",
      "Global seed set to 42\n",
      "INFO:/home/user/condensed-sparsity/src/rigl_torch/models/model_factory.py:Loading model resnet50/imagenet using <function get_imagenet_resnet50 at 0x7f5a9bebf910> with args: () and kwargs: {'diet': [17, 16, 17, 14, 16, 33, 31, 31, 32, 30, 65, 63, 63, 65, 63, 122, 124, 124, 114, 125, 0]}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for 0.9 sparsity...\n",
      "{'no_cuda': False, 'cuda_kwargs': {'num_workers': '${ oc.decode:${oc.env:NUM_WORKERS} }', 'pin_memory': True}, 'distributed': False, 'world_size': 4, 'dist_backend': 'nccl'}\n",
      "loading to device rank: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:/home/user/condensed-sparsity/src/rigl_torch/rigl_scheduler.py:Sparsity of layer at index 1 set to 0.0\n",
      "INFO:/home/user/condensed-sparsity/src/rigl_torch/rigl_scheduler.py:Sparsity of layer at index 3 set to 0.0\n",
      "INFO:/home/user/condensed-sparsity/src/rigl_torch/rigl_scheduler.py:Sparsity of layer at index 4 set to 0.0\n",
      "INFO:/home/user/condensed-sparsity/src/rigl_torch/rigl_scheduler.py:Sparsity of layer at index 5 set to 0.0\n",
      "INFO:/home/user/condensed-sparsity/src/rigl_torch/rigl_scheduler.py:Sparsity of layer at index 7 set to 0.0\n",
      "INFO:/home/user/condensed-sparsity/src/rigl_torch/rigl_scheduler.py:Sparsity of layer at index 8 set to 0.0\n",
      "INFO:/home/user/condensed-sparsity/src/rigl_torch/rigl_scheduler.py:Sparsity of layer at index 10 set to 0.0\n",
      "INFO:/home/user/condensed-sparsity/src/rigl_torch/rigl_scheduler.py:Sparsity of layer at index 11 set to 0.0\n",
      "Global seed set to 42\n",
      "INFO:/home/user/condensed-sparsity/src/rigl_torch/models/model_factory.py:Loading model resnet50/imagenet using <function get_imagenet_resnet50 at 0x7f5a9bebf910> with args: () and kwargs: {'diet': [17, 16, 17, 14, 16, 33, 31, 31, 32, 30, 65, 63, 63, 65, 63, 122, 124, 124, 114, 125, 0]}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for 0.8 sparsity...\n",
      "{'no_cuda': False, 'cuda_kwargs': {'num_workers': '${ oc.decode:${oc.env:NUM_WORKERS} }', 'pin_memory': True}, 'distributed': False, 'world_size': 4, 'dist_backend': 'nccl'}\n",
      "loading to device rank: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:/home/user/condensed-sparsity/src/rigl_torch/rigl_scheduler.py:Sparsity of layer at index 1 set to 0.0\n",
      "INFO:/home/user/condensed-sparsity/src/rigl_torch/rigl_scheduler.py:Sparsity of layer at index 3 set to 0.0\n",
      "INFO:/home/user/condensed-sparsity/src/rigl_torch/rigl_scheduler.py:Sparsity of layer at index 4 set to 0.0\n",
      "INFO:/home/user/condensed-sparsity/src/rigl_torch/rigl_scheduler.py:Sparsity of layer at index 5 set to 0.0\n",
      "INFO:/home/user/condensed-sparsity/src/rigl_torch/rigl_scheduler.py:Sparsity of layer at index 7 set to 0.0\n",
      "INFO:/home/user/condensed-sparsity/src/rigl_torch/rigl_scheduler.py:Sparsity of layer at index 8 set to 0.0\n",
      "INFO:/home/user/condensed-sparsity/src/rigl_torch/rigl_scheduler.py:Sparsity of layer at index 10 set to 0.0\n",
      "INFO:/home/user/condensed-sparsity/src/rigl_torch/rigl_scheduler.py:Sparsity of layer at index 11 set to 0.0\n",
      "INFO:/home/user/condensed-sparsity/src/rigl_torch/rigl_scheduler.py:Sparsity of layer at index 13 set to 0.0\n",
      "INFO:/home/user/condensed-sparsity/src/rigl_torch/rigl_scheduler.py:Sparsity of layer at index 15 set to 0.0\n",
      "INFO:/home/user/condensed-sparsity/src/rigl_torch/rigl_scheduler.py:Sparsity of layer at index 17 set to 0.0\n",
      "INFO:/home/user/condensed-sparsity/src/rigl_torch/rigl_scheduler.py:Sparsity of layer at index 18 set to 0.0\n",
      "INFO:/home/user/condensed-sparsity/src/rigl_torch/rigl_scheduler.py:Sparsity of layer at index 20 set to 0.0\n",
      "INFO:/home/user/condensed-sparsity/src/rigl_torch/rigl_scheduler.py:Sparsity of layer at index 21 set to 0.0\n",
      "INFO:/home/user/condensed-sparsity/src/rigl_torch/rigl_scheduler.py:Sparsity of layer at index 23 set to 0.0\n",
      "INFO:/home/user/condensed-sparsity/src/rigl_torch/rigl_scheduler.py:Sparsity of layer at index 0 set to 0.0\n",
      "Global seed set to 42\n",
      "INFO:/home/user/condensed-sparsity/src/rigl_torch/models/model_factory.py:Loading model resnet50/imagenet using <function get_imagenet_resnet50 at 0x7f5a9bebf910> with args: () and kwargs: {'diet': [17, 16, 17, 14, 16, 33, 31, 31, 32, 30, 65, 63, 63, 65, 63, 122, 124, 124, 114, 125, 0]}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for 0.75 sparsity...\n",
      "{'no_cuda': False, 'cuda_kwargs': {'num_workers': '${ oc.decode:${oc.env:NUM_WORKERS} }', 'pin_memory': True}, 'distributed': False, 'world_size': 4, 'dist_backend': 'nccl'}\n",
      "loading to device rank: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:/home/user/condensed-sparsity/src/rigl_torch/rigl_scheduler.py:Sparsity of layer at index 1 set to 0.0\n",
      "INFO:/home/user/condensed-sparsity/src/rigl_torch/rigl_scheduler.py:Sparsity of layer at index 3 set to 0.0\n",
      "INFO:/home/user/condensed-sparsity/src/rigl_torch/rigl_scheduler.py:Sparsity of layer at index 4 set to 0.0\n",
      "INFO:/home/user/condensed-sparsity/src/rigl_torch/rigl_scheduler.py:Sparsity of layer at index 5 set to 0.0\n",
      "INFO:/home/user/condensed-sparsity/src/rigl_torch/rigl_scheduler.py:Sparsity of layer at index 7 set to 0.0\n",
      "INFO:/home/user/condensed-sparsity/src/rigl_torch/rigl_scheduler.py:Sparsity of layer at index 8 set to 0.0\n",
      "INFO:/home/user/condensed-sparsity/src/rigl_torch/rigl_scheduler.py:Sparsity of layer at index 10 set to 0.0\n",
      "INFO:/home/user/condensed-sparsity/src/rigl_torch/rigl_scheduler.py:Sparsity of layer at index 11 set to 0.0\n",
      "INFO:/home/user/condensed-sparsity/src/rigl_torch/rigl_scheduler.py:Sparsity of layer at index 13 set to 0.0\n",
      "INFO:/home/user/condensed-sparsity/src/rigl_torch/rigl_scheduler.py:Sparsity of layer at index 15 set to 0.0\n",
      "INFO:/home/user/condensed-sparsity/src/rigl_torch/rigl_scheduler.py:Sparsity of layer at index 17 set to 0.0\n",
      "INFO:/home/user/condensed-sparsity/src/rigl_torch/rigl_scheduler.py:Sparsity of layer at index 18 set to 0.0\n",
      "INFO:/home/user/condensed-sparsity/src/rigl_torch/rigl_scheduler.py:Sparsity of layer at index 20 set to 0.0\n",
      "INFO:/home/user/condensed-sparsity/src/rigl_torch/rigl_scheduler.py:Sparsity of layer at index 21 set to 0.0\n",
      "INFO:/home/user/condensed-sparsity/src/rigl_torch/rigl_scheduler.py:Sparsity of layer at index 23 set to 0.0\n",
      "INFO:/home/user/condensed-sparsity/src/rigl_torch/rigl_scheduler.py:Sparsity of layer at index 0 set to 0.0\n",
      "Global seed set to 42\n",
      "INFO:/home/user/condensed-sparsity/src/rigl_torch/models/model_factory.py:Loading model resnet50/imagenet using <function get_imagenet_resnet50 at 0x7f5a9bebf910> with args: () and kwargs: {'diet': [17, 16, 17, 14, 16, 33, 31, 31, 32, 30, 65, 63, 63, 65, 63, 122, 124, 124, 114, 125, 0]}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for 0.7 sparsity...\n",
      "{'no_cuda': False, 'cuda_kwargs': {'num_workers': '${ oc.decode:${oc.env:NUM_WORKERS} }', 'pin_memory': True}, 'distributed': False, 'world_size': 4, 'dist_backend': 'nccl'}\n",
      "loading to device rank: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:/home/user/condensed-sparsity/src/rigl_torch/rigl_scheduler.py:Sparsity of layer at index 1 set to 0.0\n",
      "INFO:/home/user/condensed-sparsity/src/rigl_torch/rigl_scheduler.py:Sparsity of layer at index 3 set to 0.0\n",
      "INFO:/home/user/condensed-sparsity/src/rigl_torch/rigl_scheduler.py:Sparsity of layer at index 4 set to 0.0\n",
      "INFO:/home/user/condensed-sparsity/src/rigl_torch/rigl_scheduler.py:Sparsity of layer at index 5 set to 0.0\n",
      "INFO:/home/user/condensed-sparsity/src/rigl_torch/rigl_scheduler.py:Sparsity of layer at index 7 set to 0.0\n",
      "INFO:/home/user/condensed-sparsity/src/rigl_torch/rigl_scheduler.py:Sparsity of layer at index 8 set to 0.0\n",
      "INFO:/home/user/condensed-sparsity/src/rigl_torch/rigl_scheduler.py:Sparsity of layer at index 10 set to 0.0\n",
      "INFO:/home/user/condensed-sparsity/src/rigl_torch/rigl_scheduler.py:Sparsity of layer at index 11 set to 0.0\n",
      "INFO:/home/user/condensed-sparsity/src/rigl_torch/rigl_scheduler.py:Sparsity of layer at index 13 set to 0.0\n",
      "INFO:/home/user/condensed-sparsity/src/rigl_torch/rigl_scheduler.py:Sparsity of layer at index 15 set to 0.0\n",
      "INFO:/home/user/condensed-sparsity/src/rigl_torch/rigl_scheduler.py:Sparsity of layer at index 17 set to 0.0\n",
      "INFO:/home/user/condensed-sparsity/src/rigl_torch/rigl_scheduler.py:Sparsity of layer at index 18 set to 0.0\n",
      "INFO:/home/user/condensed-sparsity/src/rigl_torch/rigl_scheduler.py:Sparsity of layer at index 20 set to 0.0\n",
      "INFO:/home/user/condensed-sparsity/src/rigl_torch/rigl_scheduler.py:Sparsity of layer at index 21 set to 0.0\n",
      "INFO:/home/user/condensed-sparsity/src/rigl_torch/rigl_scheduler.py:Sparsity of layer at index 23 set to 0.0\n",
      "INFO:/home/user/condensed-sparsity/src/rigl_torch/rigl_scheduler.py:Sparsity of layer at index 0 set to 0.0\n",
      "INFO:/home/user/condensed-sparsity/src/rigl_torch/rigl_scheduler.py:Sparsity of layer at index 14 set to 0.0\n",
      "INFO:/home/user/condensed-sparsity/src/rigl_torch/rigl_scheduler.py:Sparsity of layer at index 24 set to 0.0\n",
      "INFO:/home/user/condensed-sparsity/src/rigl_torch/rigl_scheduler.py:Sparsity of layer at index 26 set to 0.0\n",
      "INFO:/home/user/condensed-sparsity/src/rigl_torch/rigl_scheduler.py:Sparsity of layer at index 28 set to 0.0\n",
      "INFO:/home/user/condensed-sparsity/src/rigl_torch/rigl_scheduler.py:Sparsity of layer at index 30 set to 0.0\n",
      "INFO:/home/user/condensed-sparsity/src/rigl_torch/rigl_scheduler.py:Sparsity of layer at index 31 set to 0.0\n",
      "INFO:/home/user/condensed-sparsity/src/rigl_torch/rigl_scheduler.py:Sparsity of layer at index 33 set to 0.0\n",
      "INFO:/home/user/condensed-sparsity/src/rigl_torch/rigl_scheduler.py:Sparsity of layer at index 34 set to 0.0\n",
      "INFO:/home/user/condensed-sparsity/src/rigl_torch/rigl_scheduler.py:Sparsity of layer at index 36 set to 0.0\n",
      "INFO:/home/user/condensed-sparsity/src/rigl_torch/rigl_scheduler.py:Sparsity of layer at index 37 set to 0.0\n",
      "INFO:/home/user/condensed-sparsity/src/rigl_torch/rigl_scheduler.py:Sparsity of layer at index 39 set to 0.0\n",
      "INFO:/home/user/condensed-sparsity/src/rigl_torch/rigl_scheduler.py:Sparsity of layer at index 40 set to 0.0\n",
      "INFO:/home/user/condensed-sparsity/src/rigl_torch/rigl_scheduler.py:Sparsity of layer at index 42 set to 0.0\n",
      "Global seed set to 42\n",
      "INFO:/home/user/condensed-sparsity/src/rigl_torch/models/model_factory.py:Loading model resnet50/imagenet using <function get_imagenet_resnet50 at 0x7f5a9bebf910> with args: () and kwargs: {'diet': [17, 16, 17, 14, 16, 33, 31, 31, 32, 30, 65, 63, 63, 65, 63, 122, 124, 124, 114, 125, 0]}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for 0.6 sparsity...\n",
      "{'no_cuda': False, 'cuda_kwargs': {'num_workers': '${ oc.decode:${oc.env:NUM_WORKERS} }', 'pin_memory': True}, 'distributed': False, 'world_size': 4, 'dist_backend': 'nccl'}\n",
      "loading to device rank: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:/home/user/condensed-sparsity/src/rigl_torch/rigl_scheduler.py:Sparsity of layer at index 1 set to 0.0\n",
      "INFO:/home/user/condensed-sparsity/src/rigl_torch/rigl_scheduler.py:Sparsity of layer at index 3 set to 0.0\n",
      "INFO:/home/user/condensed-sparsity/src/rigl_torch/rigl_scheduler.py:Sparsity of layer at index 4 set to 0.0\n",
      "INFO:/home/user/condensed-sparsity/src/rigl_torch/rigl_scheduler.py:Sparsity of layer at index 5 set to 0.0\n",
      "INFO:/home/user/condensed-sparsity/src/rigl_torch/rigl_scheduler.py:Sparsity of layer at index 7 set to 0.0\n",
      "INFO:/home/user/condensed-sparsity/src/rigl_torch/rigl_scheduler.py:Sparsity of layer at index 8 set to 0.0\n",
      "INFO:/home/user/condensed-sparsity/src/rigl_torch/rigl_scheduler.py:Sparsity of layer at index 10 set to 0.0\n",
      "INFO:/home/user/condensed-sparsity/src/rigl_torch/rigl_scheduler.py:Sparsity of layer at index 11 set to 0.0\n",
      "INFO:/home/user/condensed-sparsity/src/rigl_torch/rigl_scheduler.py:Sparsity of layer at index 13 set to 0.0\n",
      "INFO:/home/user/condensed-sparsity/src/rigl_torch/rigl_scheduler.py:Sparsity of layer at index 15 set to 0.0\n",
      "INFO:/home/user/condensed-sparsity/src/rigl_torch/rigl_scheduler.py:Sparsity of layer at index 17 set to 0.0\n",
      "INFO:/home/user/condensed-sparsity/src/rigl_torch/rigl_scheduler.py:Sparsity of layer at index 18 set to 0.0\n",
      "INFO:/home/user/condensed-sparsity/src/rigl_torch/rigl_scheduler.py:Sparsity of layer at index 20 set to 0.0\n",
      "INFO:/home/user/condensed-sparsity/src/rigl_torch/rigl_scheduler.py:Sparsity of layer at index 21 set to 0.0\n",
      "INFO:/home/user/condensed-sparsity/src/rigl_torch/rigl_scheduler.py:Sparsity of layer at index 23 set to 0.0\n",
      "INFO:/home/user/condensed-sparsity/src/rigl_torch/rigl_scheduler.py:Sparsity of layer at index 0 set to 0.0\n",
      "INFO:/home/user/condensed-sparsity/src/rigl_torch/rigl_scheduler.py:Sparsity of layer at index 14 set to 0.0\n",
      "INFO:/home/user/condensed-sparsity/src/rigl_torch/rigl_scheduler.py:Sparsity of layer at index 24 set to 0.0\n",
      "INFO:/home/user/condensed-sparsity/src/rigl_torch/rigl_scheduler.py:Sparsity of layer at index 26 set to 0.0\n",
      "INFO:/home/user/condensed-sparsity/src/rigl_torch/rigl_scheduler.py:Sparsity of layer at index 28 set to 0.0\n",
      "INFO:/home/user/condensed-sparsity/src/rigl_torch/rigl_scheduler.py:Sparsity of layer at index 30 set to 0.0\n",
      "INFO:/home/user/condensed-sparsity/src/rigl_torch/rigl_scheduler.py:Sparsity of layer at index 31 set to 0.0\n",
      "INFO:/home/user/condensed-sparsity/src/rigl_torch/rigl_scheduler.py:Sparsity of layer at index 33 set to 0.0\n",
      "INFO:/home/user/condensed-sparsity/src/rigl_torch/rigl_scheduler.py:Sparsity of layer at index 34 set to 0.0\n",
      "INFO:/home/user/condensed-sparsity/src/rigl_torch/rigl_scheduler.py:Sparsity of layer at index 36 set to 0.0\n",
      "INFO:/home/user/condensed-sparsity/src/rigl_torch/rigl_scheduler.py:Sparsity of layer at index 37 set to 0.0\n",
      "INFO:/home/user/condensed-sparsity/src/rigl_torch/rigl_scheduler.py:Sparsity of layer at index 39 set to 0.0\n",
      "INFO:/home/user/condensed-sparsity/src/rigl_torch/rigl_scheduler.py:Sparsity of layer at index 40 set to 0.0\n",
      "INFO:/home/user/condensed-sparsity/src/rigl_torch/rigl_scheduler.py:Sparsity of layer at index 42 set to 0.0\n",
      "INFO:/home/user/condensed-sparsity/src/rigl_torch/rigl_scheduler.py:Sparsity of layer at index 2 set to 0.0\n",
      "INFO:/home/user/condensed-sparsity/src/rigl_torch/rigl_scheduler.py:Sparsity of layer at index 6 set to 0.0\n",
      "INFO:/home/user/condensed-sparsity/src/rigl_torch/rigl_scheduler.py:Sparsity of layer at index 9 set to 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for 0.5 sparsity...\n"
     ]
    }
   ],
   "source": [
    "params = {k:[] for k in [\"dense_allocation\", \"parameters\", \"dense_params\"]}\n",
    "for da in [0.01, 0.05, 0.0625, 0.1, 0.2, 0.25, 0.3, 0.4, 0.5,]:\n",
    "    checkpoint=None\n",
    "    rank=1\n",
    "\n",
    "    if checkpoint is not None:\n",
    "        run_id = checkpoint.run_id\n",
    "        optimizer_state = checkpoint.optimizer\n",
    "        scheduler_state = checkpoint.scheduler\n",
    "        pruner_state = checkpoint.pruner\n",
    "        model_state = checkpoint.model\n",
    "        cfg = checkpoint.cfg\n",
    "    else:\n",
    "        run_id, optimizer_state, scheduler_state, pruner_state, model_state = (\n",
    "            None,\n",
    "            None,\n",
    "            None,\n",
    "            None,\n",
    "            None,\n",
    "        )\n",
    "\n",
    "    print(cfg.compute)\n",
    "    cfg.compute.distributed=False\n",
    "        \n",
    "    pl.seed_everything(cfg.training.seed)\n",
    "    use_cuda = not cfg.compute.no_cuda and torch.cuda.is_available()\n",
    "    if not use_cuda:\n",
    "        raise SystemError(\"GPU has stopped responding...waiting to die!\")\n",
    "        logger.warning(\n",
    "            \"Using CPU! Verify cfg.compute.no_cuda and \"\n",
    "            \"torch.cuda.is_available() are properly set if this is unexpected\"\n",
    "        )\n",
    "\n",
    "    if cfg.compute.distributed and use_cuda:\n",
    "        device = torch.device(f\"cuda:{rank}\")\n",
    "    else:\n",
    "        print(f\"loading to device rank: {rank}\")\n",
    "        device = torch.device(f\"cuda:{rank}\")\n",
    "    if not use_cuda:\n",
    "        device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "    # train_loader, test_loader = get_dataloaders(cfg)\n",
    "\n",
    "    model = ModelFactory.load_model(\n",
    "        model=cfg.model.name, dataset=cfg.dataset.name, diet=cfg.rigl.diet\n",
    "    )\n",
    "    model.to(device)\n",
    "    if cfg.compute.distributed:\n",
    "        model = DistributedDataParallel(model, device_ids=[rank])\n",
    "    if model_state is not None:\n",
    "        try:\n",
    "            model.load_state_dict(model_state)\n",
    "        except RuntimeError:\n",
    "            model_state = checkpoint.get_single_process_model_state_from_distributed_state()\n",
    "            model.load_state_dict(model_state)\n",
    "            \n",
    "    optimizer = get_optimizer(cfg, model, state_dict=optimizer_state)\n",
    "    scheduler = get_lr_scheduler(cfg, optimizer, state_dict=scheduler_state)\n",
    "    pruner = None\n",
    "    if cfg.rigl.dense_allocation is not None:\n",
    "        if cfg.rigl.dense_allocation is not None:\n",
    "            if cfg.model.name == \"skinny_resnet18\":\n",
    "                dense_allocation = (\n",
    "                    cfg.rigl.dense_allocation * cfg.model.sparsity_scale_factor\n",
    "                )\n",
    "                print(\n",
    "                    f\"Scaling {cfg.rigl.dense_allocation} by \"\n",
    "                    f\"{cfg.model.sparsity_scale_factor:.2f} for SkinnyResNet18 \"\n",
    "                    f\"New Dense Alloc == {dense_allocation:.6f}\"\n",
    "                )\n",
    "            else:\n",
    "                dense_allocation = cfg.rigl.dense_allocation\n",
    "            T_end = get_T_end(cfg, [0 for _ in range(0,1251)])\n",
    "            if cfg.rigl.const_fan_in:\n",
    "                rigl_scheduler = RigLConstFanScheduler\n",
    "            else:\n",
    "                rigl_scheduler = RigLScheduler\n",
    "            pruner = rigl_scheduler(\n",
    "                model,\n",
    "                optimizer,\n",
    "                dense_allocation=da,\n",
    "                alpha=cfg.rigl.alpha,\n",
    "                delta=cfg.rigl.delta,\n",
    "                static_topo=cfg.rigl.static_topo,\n",
    "                T_end=T_end,\n",
    "                ignore_linear_layers=cfg.rigl.ignore_linear_layers,\n",
    "                grad_accumulation_n=cfg.rigl.grad_accumulation_n,\n",
    "                sparsity_distribution=cfg.rigl.sparsity_distribution,\n",
    "                erk_power_scale=cfg.rigl.erk_power_scale,\n",
    "                state_dict=pruner_state,\n",
    "                filter_ablation_threshold=cfg.rigl.filter_ablation_threshold,\n",
    "                static_ablation=cfg.rigl.static_ablation,\n",
    "                dynamic_ablation=cfg.rigl.dynamic_ablation,\n",
    "                min_salient_weights_per_neuron=cfg.rigl.min_salient_weights_per_neuron,  # noqa\n",
    "                use_sparse_init=cfg.rigl.use_sparse_initialization,\n",
    "                init_method_str=cfg.rigl.init_method_str,\n",
    "                use_sparse_const_fan_in_for_ablation=cfg.rigl.use_sparse_const_fan_in_for_ablation,  # noqa\n",
    "            )\n",
    "            step=0\n",
    "    print(f\"Results for {1-da} sparsity...\")\n",
    "    els = []\n",
    "    non_zero=[]\n",
    "    for p in model.parameters():\n",
    "        els.append(p.numel())\n",
    "        non_zero.append(torch.count_nonzero(p))\n",
    "    s=torch.tensor(non_zero).sum().item()\n",
    "    n=torch.tensor(els).sum().item()\n",
    "    w_total = torch.tensor([torch.count_nonzero(w) for w in pruner.W]).sum()\n",
    "    params[\"dense_allocation\"].append(da)\n",
    "    params[\"parameters\"].append(s)\n",
    "    params[\"dense_params\"].append(n)\n",
    "    # print(f\"total el: {n}\")\n",
    "    # print(f\"non zero el: {s}\")\n",
    "    # print(f\"non zero weights only: {w_total}\")\n",
    "    # print(s/n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dense_allocation': {0: 0.01,\n",
       "  1: 0.05,\n",
       "  2: 0.0625,\n",
       "  3: 0.1,\n",
       "  4: 0.2,\n",
       "  5: 0.25,\n",
       "  6: 0.3,\n",
       "  7: 0.4,\n",
       "  8: 0.5},\n",
       " 'parameters': {0: 274072,\n",
       "  1: 1289784,\n",
       "  2: 1611784,\n",
       "  3: 2571656,\n",
       "  4: 5113920,\n",
       "  5: 6391944,\n",
       "  6: 7663032,\n",
       "  7: 10222975,\n",
       "  8: 12774296},\n",
       " 'dense_params': {0: 25557032,\n",
       "  1: 25557032,\n",
       "  2: 25557032,\n",
       "  3: 25557032,\n",
       "  4: 25557032,\n",
       "  5: 25557032,\n",
       "  6: 25557032,\n",
       "  7: 25557032,\n",
       "  8: 25557032}}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(params).to_dict()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f8e7aa388760f1ed0054a801e8f4bc0d2f712d90d0781f57f52c8b826e4e7fab"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
