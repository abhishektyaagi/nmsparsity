{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.multiprocessing as mp\n",
    "import torch.distributed as dist\n",
    "from torch.nn.parallel import DistributedDataParallel\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import pytorch_lightning as pl\n",
    "import random\n",
    "import dotenv\n",
    "import omegaconf\n",
    "import hydra\n",
    "import logging\n",
    "from typing import List\n",
    "\n",
    "import wandb\n",
    "from datetime import date\n",
    "import dotenv\n",
    "import os\n",
    "import pathlib\n",
    "from typing import Dict, Any\n",
    "from copy import deepcopy\n",
    "\n",
    "from rigl_torch.models import ModelFactory\n",
    "from rigl_torch.rigl_scheduler import RigLScheduler\n",
    "from rigl_torch.rigl_constant_fan import RigLConstFanScheduler\n",
    "from rigl_torch.datasets import get_dataloaders\n",
    "from rigl_torch.optim import (\n",
    "    get_optimizer,\n",
    "    get_lr_scheduler,\n",
    ")\n",
    "from rigl_torch.utils.rigl_utils import get_names_and_W\n",
    "from rigl_torch.utils.checkpoint import Checkpoint\n",
    "from rigl_torch.utils.rigl_utils import get_T_end, get_fan_in_after_ablation, get_conv_idx_from_flat_idx\n",
    "from hydra import initialize, compose\n",
    "\n",
    "from fvcore.nn import FlopCountAnalysis\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pruner_model_loader(dense_alloc, model, dataset):\n",
    "    with initialize(\"../configs\", version_base=\"1.2.0\"):\n",
    "        cfg = compose(\n",
    "            \"config.yaml\",\n",
    "            overrides=[\n",
    "                f\"dataset={dataset}\",\n",
    "                \"compute.distributed=False\",\n",
    "                f\"model={model}\",\n",
    "                # f\"rigl.dense_allocation={dense_alloc}\",\n",
    "                f\"rigl.dense_allocation={dense_alloc}\",\n",
    "                ])\n",
    "    dotenv.load_dotenv(\"../.env\")\n",
    "    os.environ[\"IMAGE_NET_PATH\"]\n",
    "\n",
    "\n",
    "    rank=0\n",
    "    checkpoint=None\n",
    "    if checkpoint is not None:\n",
    "        run_id = checkpoint.run_id\n",
    "        optimizer_state = checkpoint.optimizer\n",
    "        scheduler_state = checkpoint.scheduler\n",
    "        pruner_state = checkpoint.pruner\n",
    "        model_state = checkpoint.model\n",
    "        cfg = checkpoint.cfg\n",
    "    else:\n",
    "        run_id, optimizer_state, scheduler_state, pruner_state, model_state = (\n",
    "            None,\n",
    "            None,\n",
    "            None,\n",
    "            None,\n",
    "            None,\n",
    "        )\n",
    "\n",
    "    print(cfg.compute)\n",
    "    cfg.compute.distributed=False\n",
    "        \n",
    "    pl.seed_everything(cfg.training.seed)\n",
    "    use_cuda = not cfg.compute.no_cuda and torch.cuda.is_available()\n",
    "    if not use_cuda:\n",
    "        raise SystemError(\"GPU has stopped responding...waiting to die!\")\n",
    "        logger.warning(\n",
    "            \"Using CPU! Verify cfg.compute.no_cuda and \"\n",
    "            \"torch.cuda.is_available() are properly set if this is unexpected\"\n",
    "        )\n",
    "\n",
    "    if cfg.compute.distributed and use_cuda:\n",
    "        device = torch.device(f\"cuda:{rank}\")\n",
    "    else:\n",
    "        print(f\"loading to device rank: {rank}\")\n",
    "        device = torch.device(f\"cuda:{rank}\")\n",
    "    if not use_cuda:\n",
    "        device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "    train_loader, test_loader = get_dataloaders(cfg)\n",
    "\n",
    "    model = ModelFactory.load_model(\n",
    "        model=cfg.model.name, dataset=cfg.dataset.name\n",
    "    )\n",
    "    model.to(device)\n",
    "    if cfg.compute.distributed:\n",
    "        model = DistributedDataParallel(model, device_ids=[rank])\n",
    "    if model_state is not None:\n",
    "        try:\n",
    "            model.load_state_dict(model_state)\n",
    "        except RuntimeError:\n",
    "            model_state = checkpoint.get_single_process_model_state_from_distributed_state()\n",
    "            model.load_state_dict(model_state)\n",
    "            \n",
    "    optimizer = get_optimizer(cfg, model, state_dict=optimizer_state)\n",
    "    scheduler = get_lr_scheduler(cfg, optimizer, state_dict=scheduler_state)\n",
    "    pruner = None\n",
    "    if cfg.rigl.dense_allocation is not None:\n",
    "        T_end = get_T_end(cfg, [0 for _ in range(0,1251)])\n",
    "        if cfg.rigl.const_fan_in:\n",
    "            rigl_scheduler = RigLConstFanScheduler\n",
    "        else:\n",
    "            rigl_scheduler = RigLScheduler\n",
    "        pruner = rigl_scheduler(\n",
    "            model,\n",
    "            optimizer,\n",
    "            dense_allocation=cfg.rigl.dense_allocation,\n",
    "            alpha=cfg.rigl.alpha,\n",
    "            delta=cfg.rigl.delta,\n",
    "            static_topo=cfg.rigl.static_topo,\n",
    "            T_end=T_end,\n",
    "            ignore_linear_layers=cfg.rigl.ignore_linear_layers,\n",
    "            grad_accumulation_n=cfg.rigl.grad_accumulation_n,\n",
    "            sparsity_distribution=cfg.rigl.sparsity_distribution,\n",
    "            erk_power_scale=cfg.rigl.erk_power_scale,\n",
    "            state_dict=pruner_state,\n",
    "            filter_ablation_threshold=cfg.rigl.filter_ablation_threshold,\n",
    "            static_ablation=cfg.rigl.static_ablation,\n",
    "            dynamic_ablation=cfg.rigl.dynamic_ablation,\n",
    "            min_salient_weights_per_neuron=cfg.rigl.min_salient_weights_per_neuron,  # noqa\n",
    "            use_sparse_init=cfg.rigl.use_sparse_initialization,\n",
    "            init_method_str=cfg.rigl.init_method_str,\n",
    "            use_sparse_const_fan_in_for_ablation=cfg.rigl.use_sparse_const_fan_in_for_ablation,  # noqa\n",
    "        )\n",
    "        \n",
    "        step=0\n",
    "    return pruner, model, train_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating with dense_alloc == null\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'no_cuda': False, 'cuda_kwargs': {'num_workers': '${ oc.decode:${oc.env:NUM_WORKERS} }', 'pin_memory': True}, 'distributed': False, 'world_size': 4, 'dist_backend': 'nccl'}\n",
      "loading to device rank: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:/home/mike/condensed-sparsity/src/rigl_torch/models/model_factory.py:Loading model resnet50/imagenet using <function get_imagenet_resnet50 at 0x7fc9ce06e170> with args: () and kwargs: {}\n",
      "WARNING:fvcore.nn.jit_analysis:Unsupported operator aten::add_ encountered 69 time(s)\n",
      "WARNING:fvcore.nn.jit_analysis:Unsupported operator aten::max_pool2d encountered 1 time(s)\n",
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating with dense_alloc == 0.01\n",
      "{'no_cuda': False, 'cuda_kwargs': {'num_workers': '${ oc.decode:${oc.env:NUM_WORKERS} }', 'pin_memory': True}, 'distributed': False, 'world_size': 4, 'dist_backend': 'nccl'}\n",
      "loading to device rank: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:/home/mike/condensed-sparsity/src/rigl_torch/models/model_factory.py:Loading model resnet50/imagenet using <function get_imagenet_resnet50 at 0x7fc9ce06e170> with args: () and kwargs: {}\n",
      "WARNING:fvcore.nn.jit_analysis:Unsupported operator aten::add_ encountered 69 time(s)\n",
      "WARNING:fvcore.nn.jit_analysis:Unsupported operator aten::max_pool2d encountered 1 time(s)\n",
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating with dense_alloc == 0.05\n",
      "{'no_cuda': False, 'cuda_kwargs': {'num_workers': '${ oc.decode:${oc.env:NUM_WORKERS} }', 'pin_memory': True}, 'distributed': False, 'world_size': 4, 'dist_backend': 'nccl'}\n",
      "loading to device rank: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:/home/mike/condensed-sparsity/src/rigl_torch/models/model_factory.py:Loading model resnet50/imagenet using <function get_imagenet_resnet50 at 0x7fc9ce06e170> with args: () and kwargs: {}\n",
      "WARNING:fvcore.nn.jit_analysis:Unsupported operator aten::add_ encountered 69 time(s)\n",
      "WARNING:fvcore.nn.jit_analysis:Unsupported operator aten::max_pool2d encountered 1 time(s)\n",
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating with dense_alloc == 0.0625\n",
      "{'no_cuda': False, 'cuda_kwargs': {'num_workers': '${ oc.decode:${oc.env:NUM_WORKERS} }', 'pin_memory': True}, 'distributed': False, 'world_size': 4, 'dist_backend': 'nccl'}\n",
      "loading to device rank: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:/home/mike/condensed-sparsity/src/rigl_torch/models/model_factory.py:Loading model resnet50/imagenet using <function get_imagenet_resnet50 at 0x7fc9ce06e170> with args: () and kwargs: {}\n",
      "WARNING:fvcore.nn.jit_analysis:Unsupported operator aten::add_ encountered 69 time(s)\n",
      "WARNING:fvcore.nn.jit_analysis:Unsupported operator aten::max_pool2d encountered 1 time(s)\n",
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating with dense_alloc == 0.1\n",
      "{'no_cuda': False, 'cuda_kwargs': {'num_workers': '${ oc.decode:${oc.env:NUM_WORKERS} }', 'pin_memory': True}, 'distributed': False, 'world_size': 4, 'dist_backend': 'nccl'}\n",
      "loading to device rank: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:/home/mike/condensed-sparsity/src/rigl_torch/models/model_factory.py:Loading model resnet50/imagenet using <function get_imagenet_resnet50 at 0x7fc9ce06e170> with args: () and kwargs: {}\n",
      "INFO:/home/mike/condensed-sparsity/src/rigl_torch/rigl_scheduler.py:Sparsity of layer at index 1 set to 0.0\n",
      "WARNING:fvcore.nn.jit_analysis:Unsupported operator aten::add_ encountered 69 time(s)\n",
      "WARNING:fvcore.nn.jit_analysis:Unsupported operator aten::max_pool2d encountered 1 time(s)\n",
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating with dense_alloc == 0.2\n",
      "{'no_cuda': False, 'cuda_kwargs': {'num_workers': '${ oc.decode:${oc.env:NUM_WORKERS} }', 'pin_memory': True}, 'distributed': False, 'world_size': 4, 'dist_backend': 'nccl'}\n",
      "loading to device rank: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:/home/mike/condensed-sparsity/src/rigl_torch/models/model_factory.py:Loading model resnet50/imagenet using <function get_imagenet_resnet50 at 0x7fc9ce06e170> with args: () and kwargs: {}\n",
      "INFO:/home/mike/condensed-sparsity/src/rigl_torch/rigl_scheduler.py:Sparsity of layer at index 1 set to 0.0\n",
      "INFO:/home/mike/condensed-sparsity/src/rigl_torch/rigl_scheduler.py:Sparsity of layer at index 3 set to 0.0\n",
      "INFO:/home/mike/condensed-sparsity/src/rigl_torch/rigl_scheduler.py:Sparsity of layer at index 4 set to 0.0\n",
      "INFO:/home/mike/condensed-sparsity/src/rigl_torch/rigl_scheduler.py:Sparsity of layer at index 5 set to 0.0\n",
      "INFO:/home/mike/condensed-sparsity/src/rigl_torch/rigl_scheduler.py:Sparsity of layer at index 7 set to 0.0\n",
      "INFO:/home/mike/condensed-sparsity/src/rigl_torch/rigl_scheduler.py:Sparsity of layer at index 8 set to 0.0\n",
      "INFO:/home/mike/condensed-sparsity/src/rigl_torch/rigl_scheduler.py:Sparsity of layer at index 10 set to 0.0\n",
      "INFO:/home/mike/condensed-sparsity/src/rigl_torch/rigl_scheduler.py:Sparsity of layer at index 11 set to 0.0\n",
      "WARNING:fvcore.nn.jit_analysis:Unsupported operator aten::add_ encountered 69 time(s)\n",
      "WARNING:fvcore.nn.jit_analysis:Unsupported operator aten::max_pool2d encountered 1 time(s)\n",
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating with dense_alloc == 0.25\n",
      "{'no_cuda': False, 'cuda_kwargs': {'num_workers': '${ oc.decode:${oc.env:NUM_WORKERS} }', 'pin_memory': True}, 'distributed': False, 'world_size': 4, 'dist_backend': 'nccl'}\n",
      "loading to device rank: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:/home/mike/condensed-sparsity/src/rigl_torch/models/model_factory.py:Loading model resnet50/imagenet using <function get_imagenet_resnet50 at 0x7fc9ce06e170> with args: () and kwargs: {}\n",
      "INFO:/home/mike/condensed-sparsity/src/rigl_torch/rigl_scheduler.py:Sparsity of layer at index 1 set to 0.0\n",
      "INFO:/home/mike/condensed-sparsity/src/rigl_torch/rigl_scheduler.py:Sparsity of layer at index 3 set to 0.0\n",
      "INFO:/home/mike/condensed-sparsity/src/rigl_torch/rigl_scheduler.py:Sparsity of layer at index 4 set to 0.0\n",
      "INFO:/home/mike/condensed-sparsity/src/rigl_torch/rigl_scheduler.py:Sparsity of layer at index 5 set to 0.0\n",
      "INFO:/home/mike/condensed-sparsity/src/rigl_torch/rigl_scheduler.py:Sparsity of layer at index 7 set to 0.0\n",
      "INFO:/home/mike/condensed-sparsity/src/rigl_torch/rigl_scheduler.py:Sparsity of layer at index 8 set to 0.0\n",
      "INFO:/home/mike/condensed-sparsity/src/rigl_torch/rigl_scheduler.py:Sparsity of layer at index 10 set to 0.0\n",
      "INFO:/home/mike/condensed-sparsity/src/rigl_torch/rigl_scheduler.py:Sparsity of layer at index 11 set to 0.0\n",
      "INFO:/home/mike/condensed-sparsity/src/rigl_torch/rigl_scheduler.py:Sparsity of layer at index 13 set to 0.0\n",
      "INFO:/home/mike/condensed-sparsity/src/rigl_torch/rigl_scheduler.py:Sparsity of layer at index 15 set to 0.0\n",
      "INFO:/home/mike/condensed-sparsity/src/rigl_torch/rigl_scheduler.py:Sparsity of layer at index 17 set to 0.0\n",
      "INFO:/home/mike/condensed-sparsity/src/rigl_torch/rigl_scheduler.py:Sparsity of layer at index 18 set to 0.0\n",
      "INFO:/home/mike/condensed-sparsity/src/rigl_torch/rigl_scheduler.py:Sparsity of layer at index 20 set to 0.0\n",
      "INFO:/home/mike/condensed-sparsity/src/rigl_torch/rigl_scheduler.py:Sparsity of layer at index 21 set to 0.0\n",
      "INFO:/home/mike/condensed-sparsity/src/rigl_torch/rigl_scheduler.py:Sparsity of layer at index 23 set to 0.0\n",
      "INFO:/home/mike/condensed-sparsity/src/rigl_torch/rigl_scheduler.py:Sparsity of layer at index 0 set to 0.0\n",
      "WARNING:fvcore.nn.jit_analysis:Unsupported operator aten::add_ encountered 69 time(s)\n",
      "WARNING:fvcore.nn.jit_analysis:Unsupported operator aten::max_pool2d encountered 1 time(s)\n"
     ]
    }
   ],
   "source": [
    "def get_flops_df(model_name, dataset):\n",
    "    df = {k:[] for k in [\"rigl.dense_allocation\", \"flops\", \"model\",]}\n",
    "    for da in [\"null\", 0.01, 0.05, 0.0625, 0.1, 0.2, 0.25,]:\n",
    "        print(f\"Calculating with dense_alloc == {da}\")\n",
    "        pruner, model, train_loader = get_pruner_model_loader(da, model_name, dataset)\n",
    "        model.train()\n",
    "        for data, _ in train_loader:\n",
    "            data = data[0].to(\"cpu\").reshape(1, *data[0].shape)\n",
    "            break\n",
    "        \n",
    "        flops = FlopCountAnalysis(model.to(\"cpu\"),data)\n",
    "        total_flops = 0\n",
    "\n",
    "        names, W = get_names_and_W(model)\n",
    "        if pruner is not None:\n",
    "            S = pruner.S\n",
    "        else:\n",
    "            S = [0. for _ in range(len(names))]\n",
    "        for name, counter in flops.by_module_and_operator().items():\n",
    "            if name in names:\n",
    "                if len(counter) != 1:\n",
    "                    raise ValueError(f\"Too many items found in {name}. Goodbye\")\n",
    "                f = list(counter.values())[0]\n",
    "                s = S[names.index(name)]\n",
    "                if s is None:\n",
    "                    s=0\n",
    "                total_flops += f*(1-s)\n",
    "        del model\n",
    "        del pruner\n",
    "        del train_loader\n",
    "        df[\"rigl.dense_allocation\"].append(da)\n",
    "        df[\"flops\"].append(total_flops)\n",
    "        df[\"model\"].append(model_name)\n",
    "    \n",
    "    df=pd.DataFrame(df)\n",
    "    df[\"normalized_flops\"] = df[\"flops\"]/ df.loc[df[\"rigl.dense_allocation\"]==\"null\"][\"flops\"].item()\n",
    "\n",
    "    return pd.DataFrame(df)\n",
    "\n",
    "df = get_flops_df(\"resnet50\", \"imagenet\")\n",
    "df.to_csv(\"../train_flops_fvcore.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rigl.dense_allocation</th>\n",
       "      <th>flops</th>\n",
       "      <th>model</th>\n",
       "      <th>normalized_flops</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>null</td>\n",
       "      <td>4.089184e+09</td>\n",
       "      <td>resnet50</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.01</td>\n",
       "      <td>9.951704e+07</td>\n",
       "      <td>resnet50</td>\n",
       "      <td>0.024337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.05</td>\n",
       "      <td>4.975516e+08</td>\n",
       "      <td>resnet50</td>\n",
       "      <td>0.121675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0625</td>\n",
       "      <td>6.219257e+08</td>\n",
       "      <td>resnet50</td>\n",
       "      <td>0.152090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.1</td>\n",
       "      <td>9.889238e+08</td>\n",
       "      <td>resnet50</td>\n",
       "      <td>0.241839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.2</td>\n",
       "      <td>1.692089e+09</td>\n",
       "      <td>resnet50</td>\n",
       "      <td>0.413796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.25</td>\n",
       "      <td>1.946310e+09</td>\n",
       "      <td>resnet50</td>\n",
       "      <td>0.475965</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  rigl.dense_allocation         flops     model  normalized_flops\n",
       "0                  null  4.089184e+09  resnet50          1.000000\n",
       "1                  0.01  9.951704e+07  resnet50          0.024337\n",
       "2                  0.05  4.975516e+08  resnet50          0.121675\n",
       "3                0.0625  6.219257e+08  resnet50          0.152090\n",
       "4                   0.1  9.889238e+08  resnet50          0.241839\n",
       "5                   0.2  1.692089e+09  resnet50          0.413796\n",
       "6                  0.25  1.946310e+09  resnet50          0.475965"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'no_cuda': False, 'cuda_kwargs': {'num_workers': '${ oc.decode:${oc.env:NUM_WORKERS} }', 'pin_memory': True}, 'distributed': False, 'world_size': 4, 'dist_backend': 'nccl'}\n",
      "loading to device rank: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:/home/mike/condensed-sparsity/src/rigl_torch/models/model_factory.py:Loading model resnet50/imagenet using <function get_imagenet_resnet50 at 0x7fc9ce06e170> with args: () and kwargs: {}\n"
     ]
    }
   ],
   "source": [
    "p, m, l = get_pruner_model_loader(\"null\", \"resnet50\", \"imagenet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from micronet_challenge import counting\n",
    "import torch.nn as nn\n",
    "\n",
    "from functools import partial\n",
    "def register_forward_hook(model, masked_layers):\n",
    "    def hook_input_shape(x, *args, n, mod,_unwrapped_forward, **kwargs):\n",
    "        # print(f\"{n}: Input Shape: {x.shape}\")\n",
    "        if not hasattr(mod, \"_input_shape\"):\n",
    "            mod._input_shape=x.shape\n",
    "        return _unwrapped_forward(x, *args, **kwargs)\n",
    "    for n,mod in model.named_modules():\n",
    "        if n in masked_layers:\n",
    "            _unwrapped_forward = mod.forward\n",
    "            mod.forward = partial(hook_input_shape, n=n, mod=mod, _unwrapped_forward=_unwrapped_forward)\n",
    "\n",
    "def get_conv_op(conv: nn.Conv2d):\n",
    "    # use_bias = True if conv.bias is not None else False\n",
    "    use_bias=True\n",
    "    c_out, c_in, k_x, k_y = conv.weight.shape\n",
    "    input_size = conv._input_shape[-1]\n",
    "    return counting.Conv2D(\n",
    "        input_size=input_size,\n",
    "        kernel_shape=(k_x, k_y, c_in, c_out),\n",
    "        strides=conv.stride,\n",
    "        use_bias=use_bias,\n",
    "        padding=\"same\",\n",
    "        activation=\"relu\",\n",
    "    )\n",
    "\n",
    "def get_add_op(conv_downsample: nn.Conv2d):\n",
    "    return counting.Add(\n",
    "        input_size=conv_downsample._input_shape[-1],\n",
    "        n_channels=conv_downsample.out_channels\n",
    "    )\n",
    "\n",
    "def get_linear_op(linear: nn.Linear, use_relu_activation: bool = True):\n",
    "    c_out, c_in = linear.weight.shape\n",
    "    input_size = linear._input_shape[-1]\n",
    "    return counting.FullyConnected(\n",
    "        kernel_shape=(c_in, c_out),\n",
    "        # use_bias = True if linear.bias is not None else False,\n",
    "        use_bias=True,\n",
    "        activation=\"relu\" if use_relu_activation else None,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Optional, NamedTuple\n",
    "import numpy as np\n",
    "\n",
    "def get_op_from_module(m):\n",
    "    if isinstance(m, nn.Conv2d):\n",
    "        return get_conv_op(m)\n",
    "    if isinstance(m, nn.Linear):\n",
    "        return get_linear_op(m, use_relu_activation=False)  # Only 1 layer\n",
    "\n",
    "def get_names_and_ops(\n",
    "    module,\n",
    "    target_names: Optional[List[str]]=None,\n",
    ") -> Dict[str, nn.Module]:\n",
    "    if target_names is None:\n",
    "        target_names, _ = get_names_and_W(module)\n",
    "    names_ops = {k: None for k in target_names}\n",
    "    add_counter = 0\n",
    "    for n,m in module.named_modules():\n",
    "        if n in target_names:\n",
    "            op = get_op_from_module(m)\n",
    "            names_ops[n]=op\n",
    "            # if \"downsample\" in n:\n",
    "            #     names_ops[f\"add.{add_counter}\"] = get_add_op(m)\n",
    "            #     add_counter+=1\n",
    "    return names_ops\n",
    "\n",
    "\n",
    "def get_model_info(m, p):\n",
    "    names = get_names_and_ops(m)\n",
    "    # names\n",
    "\n",
    "    total_flops = 0\n",
    "    flops_dict = {n:0 for n in names}\n",
    "    if p is not None:\n",
    "        S = p.S\n",
    "    else:\n",
    "        S = [0. for _ in range(len(names))]\n",
    "    total_flops = 0\n",
    "    total_param_bits = 0\n",
    "    total_params = 0.\n",
    "    n_zeros = 0.\n",
    "    for s, (n, o) in list(zip(S, names.items())):\n",
    "        param_count, n_mults, n_adds = counting.count_ops(o, s, param_bits=32)\n",
    "        # print(f\"{n}: FLOPS: {(n_mults+n_adds)/1e9}\")\n",
    "        total_flops += n_mults + n_adds\n",
    "        if isinstance(o, counting.Add):\n",
    "            continue\n",
    "        k_shape = o.kernel_shape\n",
    "        total_param_bits += param_count\n",
    "        n_param = np.prod(k_shape)\n",
    "        total_params += n_param\n",
    "        n_zeros += int(n_param * s)\n",
    "    return total_flops, total_param_bits, n_zeros / total_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'total_flops' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m total_flops\u001b[39m/\u001b[39m\u001b[39m1e9\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'total_flops' is not defined"
     ]
    }
   ],
   "source": [
    "total_flops/1e9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_input_shape(m):\n",
    "    m.to(\"cpu\")\n",
    "    masked_layers, _ = get_names_and_W(m)\n",
    "    register_forward_hook(m, masked_layers)\n",
    "    input = torch.ones(size=(1,3,224,224))\n",
    "    out = m(input)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating with dense_alloc == null\n",
      "{'no_cuda': False, 'cuda_kwargs': {'num_workers': '${ oc.decode:${oc.env:NUM_WORKERS} }', 'pin_memory': True}, 'distributed': False, 'world_size': 4, 'dist_backend': 'nccl'}\n",
      "loading to device rank: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:/home/mike/condensed-sparsity/src/rigl_torch/models/model_factory.py:Loading model resnet50/imagenet using <function get_imagenet_resnet50 at 0x7f93be862170> with args: () and kwargs: {}\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'init_input_shape' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [9], line 22\u001b[0m\n\u001b[1;32m     19\u001b[0m     df[\u001b[39m\"\u001b[39m\u001b[39mnormalized_training_flops\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m df[\u001b[39m\"\u001b[39m\u001b[39mtraining_flops\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m/\u001b[39m df\u001b[39m.\u001b[39mloc[df[\u001b[39m\"\u001b[39m\u001b[39mrigl.dense_allocation\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m==\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mnull\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mtraining_flops\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mitem()\n\u001b[1;32m     20\u001b[0m     \u001b[39mreturn\u001b[39;00m df\n\u001b[0;32m---> 22\u001b[0m df \u001b[39m=\u001b[39m get_flops_df(\u001b[39m\"\u001b[39;49m\u001b[39mresnet50\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mimagenet\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m     23\u001b[0m df\n",
      "Cell \u001b[0;32mIn [9], line 8\u001b[0m, in \u001b[0;36mget_flops_df\u001b[0;34m(model_name, dataset)\u001b[0m\n\u001b[1;32m      6\u001b[0m model\u001b[39m.\u001b[39meval()\n\u001b[1;32m      7\u001b[0m model\u001b[39m.\u001b[39mto(\u001b[39m\"\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m----> 8\u001b[0m init_input_shape(model)\n\u001b[1;32m      9\u001b[0m total_flops, params, global_sparsity \u001b[39m=\u001b[39m get_model_info(model, pruner)\n\u001b[1;32m     10\u001b[0m \u001b[39mdel\u001b[39;00m model\n",
      "\u001b[0;31mNameError\u001b[0m: name 'init_input_shape' is not defined"
     ]
    }
   ],
   "source": [
    "def get_flops_df(model_name, dataset):\n",
    "    df = {k:[] for k in [\"rigl.dense_allocation\", \"flops\", \"model\",]}\n",
    "    for da in [\"null\", 0.01, 0.05, 0.0625, 0.1, 0.2, 0.25,]:\n",
    "        print(f\"Calculating with dense_alloc == {da}\")\n",
    "        pruner, model, _ = get_pruner_model_loader(da, model_name, dataset)\n",
    "        model.eval()\n",
    "        model.to(\"cpu\")\n",
    "        init_input_shape(model)\n",
    "        total_flops, params, global_sparsity = get_model_info(model, pruner)\n",
    "        del model\n",
    "        del pruner\n",
    "        df[\"rigl.dense_allocation\"].append(da)\n",
    "        df[\"flops\"].append(total_flops)\n",
    "        df[\"model\"].append(model_name)\n",
    "    df = pd.DataFrame(df)\n",
    "    df[\"normalized_flops\"] = df[\"flops\"]/ df.loc[df[\"rigl.dense_allocation\"]==\"null\"][\"flops\"].item()\n",
    "    df[\"training_flops\"] = df[\"flops\"]* 3\n",
    "    df.loc[df[\"rigl.dense_allocation\"]==\"null\"]['training_flops'] = df.loc[df[\"rigl.dense_allocation\"]==\"null\"][\"flops\"].item()*3\n",
    "    df[\"normalized_training_flops\"] = df[\"training_flops\"]/ df.loc[df[\"rigl.dense_allocation\"]==\"null\"][\"training_flops\"].item()\n",
    "    return df\n",
    "    \n",
    "df = get_flops_df(\"resnet50\", \"imagenet\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rigl.dense_allocation</th>\n",
       "      <th>flops</th>\n",
       "      <th>model</th>\n",
       "      <th>normalized_flops</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>null</td>\n",
       "      <td>4.089184e+09</td>\n",
       "      <td>resnet50</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.01</td>\n",
       "      <td>9.951704e+07</td>\n",
       "      <td>resnet50</td>\n",
       "      <td>0.024337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.05</td>\n",
       "      <td>4.975516e+08</td>\n",
       "      <td>resnet50</td>\n",
       "      <td>0.121675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0625</td>\n",
       "      <td>6.219257e+08</td>\n",
       "      <td>resnet50</td>\n",
       "      <td>0.152090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.1</td>\n",
       "      <td>9.889238e+08</td>\n",
       "      <td>resnet50</td>\n",
       "      <td>0.241839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.2</td>\n",
       "      <td>1.692089e+09</td>\n",
       "      <td>resnet50</td>\n",
       "      <td>0.413796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.25</td>\n",
       "      <td>1.946310e+09</td>\n",
       "      <td>resnet50</td>\n",
       "      <td>0.475965</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  rigl.dense_allocation         flops     model  normalized_flops\n",
       "0                  null  4.089184e+09  resnet50          1.000000\n",
       "1                  0.01  9.951704e+07  resnet50          0.024337\n",
       "2                  0.05  4.975516e+08  resnet50          0.121675\n",
       "3                0.0625  6.219257e+08  resnet50          0.152090\n",
       "4                   0.1  9.889238e+08  resnet50          0.241839\n",
       "5                   0.2  1.692089e+09  resnet50          0.413796\n",
       "6                  0.25  1.946310e+09  resnet50          0.475965"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4.089184\n",
       "1    0.099517\n",
       "2    0.497552\n",
       "3    0.621926\n",
       "4    0.988924\n",
       "5    1.692089\n",
       "6    1.946310\n",
       "Name: flops, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"flops\"]/1e9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rigl.dense_allocation</th>\n",
       "      <th>flops</th>\n",
       "      <th>model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0100</td>\n",
       "      <td>9.951704e+07</td>\n",
       "      <td>resnet50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0500</td>\n",
       "      <td>4.975516e+08</td>\n",
       "      <td>resnet50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0625</td>\n",
       "      <td>6.219257e+08</td>\n",
       "      <td>resnet50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.1000</td>\n",
       "      <td>9.889238e+08</td>\n",
       "      <td>resnet50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.2000</td>\n",
       "      <td>1.692089e+09</td>\n",
       "      <td>resnet50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.2500</td>\n",
       "      <td>1.946310e+09</td>\n",
       "      <td>resnet50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rigl.dense_allocation         flops     model\n",
       "0                 0.0100  9.951704e+07  resnet50\n",
       "1                 0.0500  4.975516e+08  resnet50\n",
       "2                 0.0625  6.219257e+08  resnet50\n",
       "3                 0.1000  9.889238e+08  resnet50\n",
       "4                 0.2000  1.692089e+09  resnet50\n",
       "5                 0.2500  1.946310e+09  resnet50"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pytorch_profiler_flops = pd.read_csv(\"../flops_fvcore.csv\", index_col=\"Unnamed: 0\")\n",
    "pytorch_profiler_flops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pytorch_profiler_flops = pd.read_csv(\"../training_flops_fvcore.csv\", index_col=\"Unnamed: 0\")\n",
    "pytorch_profiler_flops"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f8e7aa388760f1ed0054a801e8f4bc0d2f712d90d0781f57f52c8b826e4e7fab"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
