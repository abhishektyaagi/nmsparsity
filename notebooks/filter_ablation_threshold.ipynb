{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.multiprocessing as mp\n",
    "import torch.distributed as dist\n",
    "from torch.nn.parallel import DistributedDataParallel\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import pytorch_lightning as pl\n",
    "import random\n",
    "import dotenv\n",
    "import omegaconf\n",
    "import hydra\n",
    "import logging\n",
    "import wandb\n",
    "from datetime import date\n",
    "import pathlib\n",
    "from typing import Dict, Any\n",
    "from copy import deepcopy\n",
    "\n",
    "from rigl_torch.models.model_factory import ModelFactory\n",
    "from rigl_torch.rigl_scheduler import RigLScheduler\n",
    "from rigl_torch.rigl_constant_fan import RigLConstFanScheduler\n",
    "from rigl_torch.datasets import get_dataloaders\n",
    "from rigl_torch.optim import (\n",
    "    get_optimizer,\n",
    "    get_lr_scheduler,\n",
    ")\n",
    "from rigl_torch.utils.checkpoint import Checkpoint\n",
    "from rigl_torch.utils.rigl_utils import get_T_end, get_fan_in_after_ablation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_94728/1191591776.py:1: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  with hydra.initialize(config_path=\"../configs\"):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'dataset': {'name': 'cifar10', 'normalize': False, 'num_classes': 10, 'classes': ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck'], 'train_len': 50000}, 'model': {'name': 'wide_resnet22'}, 'experiment': {'comment': 'dense_alloc${rigl.dense_allocation}_const_fan${rigl.const_fan_in}_docker_bind_test', 'name': '${model.name}_${dataset.name}_${experiment.comment}', 'resume_from_checkpoint': False, 'run_id': None}, 'paths': {'base': '${oc.env:BASE_PATH}', 'data_folder': '${paths.base}/data', 'artifacts': '${paths.base}/artifacts', 'logs': '${paths.base}/logs', 'checkpoints': '${paths.artifacts}/checkpoints'}, 'rigl': {'dense_allocation': 0.01, 'delta': 4000, 'grad_accumulation_n': 8, 'alpha': 0.5, 'static_topo': 0, 'const_fan_in': True, 'sparsity_distribution': 'erk', 'erk_power_scale': 1.0, 'use_t_end': False, 'filter_ablation_threshold': 0.01}, 'training': {'dry_run': False, 'batch_size': 64, 'simulated_batch_size': None, 'test_batch_size': 1000, 'epochs': 100, 'seed': 42, 'log_interval': 1000, 'save_model': True, 'max_steps': None, 'optimizer': 'sgd', 'weight_decay': 0.0001, 'momentum': 0.9, 'label_smoothing': 0.1, 'scheduler': 'step_lr_with_warm_up', 'lr': 0.1, 'init_lr': 1e-06, 'warm_up_steps': 5, 'gamma': 0.1, 'step_size': [30, 60, 90]}, 'compute': {'no_cuda': False, 'cuda_kwargs': {'num_workers': '${ oc.decode:${oc.env:NUM_WORKERS} }', 'pin_memory': True}, 'distributed': False, 'world_size': 4, 'dist_backend': 'nccl'}, 'wandb': {'project': 'condensed-rigl', 'entity': 'condensed-sparsity', 'start_method': 'thread', 'log_images': False}}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with hydra.initialize(config_path=\"../configs\"):\n",
    "    cfg = hydra.compose(\n",
    "        config_name=\"config.yaml\", \n",
    "        overrides=[\n",
    "            \"dataset=cifar10\",\n",
    "            \"model=wide_resnet22\",\n",
    "            \"compute.distributed=False\",\n",
    "            \"rigl.dense_allocation=0.01\",\n",
    "            \"rigl.const_fan_in=True\",\n",
    "            \"rigl.filter_ablation_threshold=0.01\",\n",
    "        ]\n",
    "    )\n",
    "cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg.rigl.filter_ablation_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:/home/user/condensed-sparsity/src/rigl_torch/models/model_factory.py:Loading model wide_resnet22/cifar10 using <function get_wide_resnet_22 at 0x7f2d117511f0> with args: () and kwargs: {}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:/home/user/condensed-sparsity/src/rigl_torch/models/model_factory.py:Loading model wide_resnet22/cifar10 using <function get_wide_resnet_22 at 0x7f2d117511f0> with args: () and kwargs: {}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filter Ablation not implemented for vanilla rigl yet!!!\n"
     ]
    }
   ],
   "source": [
    "net = ModelFactory.load_model(\"wide_resnet22\", \"cifar10\")\n",
    "device = torch.device(\"cuda\")\n",
    "train_loader, test_loader = get_dataloaders(cfg)\n",
    "model = ModelFactory.load_model(\n",
    "        model=cfg.model.name, dataset=cfg.dataset.name\n",
    "    )\n",
    "model.to(device)\n",
    "optimizer = get_optimizer(cfg, model, state_dict=None)\n",
    "scheduler = get_lr_scheduler(cfg, optimizer, state_dict=None)\n",
    "T_end = get_T_end(cfg, train_loader)\n",
    "if cfg.rigl.const_fan_in:\n",
    "    rigl_scheduler = RigLConstFanScheduler\n",
    "else:\n",
    "    rigl_scheduler = RigLScheduler\n",
    "pruner = rigl_scheduler(\n",
    "    model,\n",
    "    optimizer,\n",
    "    dense_allocation=cfg.rigl.dense_allocation,\n",
    "    alpha=cfg.rigl.alpha,\n",
    "    delta=cfg.rigl.delta,\n",
    "    static_topo=cfg.rigl.static_topo,\n",
    "    T_end=T_end,\n",
    "    ignore_linear_layers=False,\n",
    "    grad_accumulation_n=cfg.rigl.grad_accumulation_n,\n",
    "    sparsity_distribution=cfg.rigl.sparsity_distribution,\n",
    "    erk_power_scale=cfg.rigl.erk_power_scale,\n",
    "    state_dict=None,\n",
    "    filter_ablation_threshold=cfg.rigl.filter_ablation_threshold\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 62, 0, 62, 62, 62, 62, 0]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pruner.inital_ablated_filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(80, device='cuda:0')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pruner.backward_masks[0].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1152, 1152)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from rigl_torch.utils.rigl_utils import calculate_fan_in_and_fan_out\n",
    "\n",
    "\n",
    "calculate_fan_in_and_fan_out(pruner.W[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pruner.inital_ablated_filters[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 128, 3, 3])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pruner.W[idx].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = -2\n",
    "get_fan_in_after_ablation(pruner.W[idx], num_neurons_to_ablate=pruner.inital_ablated_filters[idx], sparsity=pruner.S[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 62, 0, 62, 62, 62, 62, 0]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pruner.inital_ablated_filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1664, device='cuda:0')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pruner.backward_masks[idx].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(True, device='cuda:0')"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pruner.backward_masks[idx][1].any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "858"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "13 * (128-62)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.005818684895833333"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "13 * (128-62) / pruner.W[idx].numel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9904, device='cuda:0')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_global_sparsity_from_masks(pruner) -> float:\n",
    "    total_els = 0\n",
    "    total_non_zero_els = 0\n",
    "    for w, m in list(zip(pruner.W, pruner.backward_masks)):\n",
    "        if m is None:\n",
    "            total_non_zero_els += w.numel()\n",
    "            total_els += w.numel()\n",
    "        else:\n",
    "            total_non_zero_els += m.sum()\n",
    "            total_els += w.numel()\n",
    "    return 1 - (total_non_zero_els / total_els)\n",
    "\n",
    "get_global_sparsity_from_masks(pruner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9904, device='cuda:0')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_el = 0\n",
    "non_zero_els = 0\n",
    "for w, m,s in list(zip(pruner.W, pruner.backward_masks, pruner.S)):\n",
    "    total_el += m.numel()\n",
    "    non_zero_els += m.sum()\n",
    "1-(non_zero_els / total_el)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9904, device='cuda:0')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pruner.get_global_sparsity_from_masks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 62, 0, 62, 62, 62, 62, 0]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pruner.inital_ablated_filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected Tensor as element 0 in argument 0, but got list",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m torch\u001b[39m.\u001b[39;49mconcat([pruner\u001b[39m.\u001b[39;49mbackward_masks])\n",
      "\u001b[0;31mTypeError\u001b[0m: expected Tensor as element 0 in argument 0, but got list"
     ]
    }
   ],
   "source": [
    "total_el = 0 \n",
    "non_zero_el = 0\n",
    "for m in pruner.backward_masks:\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0151, device='cuda:0')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pruner.get_global_sparsity_from_masks()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'RigLScheduler(\\nlayers=23,\\nnonzero_params=[85/432, 183/4608, 237/9216, 170/512, 237/9216, 237/9216, 237/9216, 237/9216, 345/18432, 454/36864, 332/2048, 454/36864, 454/36864, 454/36864, 454/36864, 670/73728, 886/147456, 656/8192, 886/147456, 886/147456, 886/147456, 886/147456, 467/1280],\\nnonzero_percentages=[19.68%, 3.97%, 2.57%, 33.20%, 2.57%, 2.57%, 2.57%, 2.57%, 1.87%, 1.23%, 16.21%, 1.23%, 1.23%, 1.23%, 1.23%, 0.91%, 0.60%, 8.01%, 0.60%, 0.60%, 0.60%, 0.60%, 36.48%],\\ntotal_nonzero_params=10793/1076912 (1.00%),\\ntotal_CONV_nonzero_params=10326/1075632 (0.96%),\\nstep=0,\\nnum_rigl_steps=0,\\nignoring_linear_layers=False,\\nsparsity_distribution=erk,\\nITOP rate=0.0100,\\n)'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pruner.__str__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[432, 4608, 9216, 512, 9216, 9216, 9216, 9216, 18432, 36864, 2048, 36864, 36864, 36864, 36864, 73728, 147456, 8192, 147456, 147456, 147456, 147456, 1280]\n",
      "[85, 183, 237, 170, 237, 237, 237, 237, 345, 454, 332, 454, 454, 454, 454, 670, 886, 656, 886, 886, 886, 886, 467]\n",
      "10793\n",
      "1076912\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.010022174513795"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_global_sparsity_from_masks(pruner) -> float:\n",
    "    total_els = [m.numel() for m in pruner.backward_masks]\n",
    "    print(total_els)\n",
    "    non_zero_els = [m.sum().item() for m in pruner.backward_masks]\n",
    "    print(non_zero_els)\n",
    "    print(sum(non_zero_els))\n",
    "    print(sum(total_els))\n",
    "    return sum(non_zero_els) / sum(total_els)\n",
    "\n",
    "get_global_sparsity_from_masks(pruner)\n",
    "\n",
    "#todo what?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from rigl_torch.utils.rigl_utils import calculate_fan_in_and_fan_out\n",
    "# @torch.no_grad()\n",
    "# def random_sparsify(pruner) -> None:\n",
    "#     \"\"\"Randomly sparsifies model to desired sparsity distribution with\n",
    "#     constant fan in.\n",
    "#     \"\"\"\n",
    "#     is_dist: bool = dist.is_initialized()\n",
    "#     pruner.backward_masks = []\n",
    "#     for idx, (w, num_neurons_to_ablate) in enumerate(\n",
    "#         list(zip(pruner.W, pruner.ablated_filters))\n",
    "#     ):\n",
    "#         # if sparsity is 0%, skip\n",
    "#         if pruner.S[idx] <= 0:\n",
    "#             pruner.backward_masks.append(None)\n",
    "#             continue\n",
    "\n",
    "#         dense_fan_in, _ = calculate_fan_in_and_fan_out(module=w)\n",
    "#         fan_in = get_fan_in_after_ablation(\n",
    "#             weight_tensor=w,\n",
    "#             num_neurons_to_ablate=num_neurons_to_ablate,\n",
    "#             sparsity=pruner.S[idx],\n",
    "#         )\n",
    "#         print(fan_in)\n",
    "#         print(dense_fan_in)\n",
    "#         # Number of connections to drop per filter\n",
    "#         s = dense_fan_in - fan_in\n",
    "#         print(f\"s is {s}\")\n",
    "#         perm = torch.concat(\n",
    "#             [\n",
    "#                 torch.randperm(fan_in).reshape(1, -1)\n",
    "#                 for _ in range(w.shape[0])\n",
    "#             ]\n",
    "#         )\n",
    "#         # Generate random perm of indices to mask per filter / neuron\n",
    "#         perm = perm[\n",
    "#             :, :s\n",
    "#         ]  # Drop s elements from n to achieve desired sparsity\n",
    "#         print(perm)\n",
    "#         print(f\"perm shape: {perm.shape}\")\n",
    "#         mask = torch.concat(\n",
    "#             [torch.ones(dense_fan_in).reshape(1, -1) for _ in range(w.shape[0])]\n",
    "#         )\n",
    "#         print(f\"mask shape: {mask.shape}\")\n",
    "#         for filter_idx in range(mask.shape[0]):  # TODO: vectorize?\n",
    "#             mask[filter_idx][perm[filter_idx]] = 0\n",
    "#         mask = mask.reshape(w.shape).to(device=w.device)\n",
    "#         # Ablate top n neurons according to filter sparsity criterion\n",
    "#         mask[num_neurons_to_ablate:] = False\n",
    "\n",
    "#         if is_dist:\n",
    "#             dist.broadcast(mask, 0)\n",
    "#         mask = mask.bool()\n",
    "#         w *= mask\n",
    "#         pruner.backward_masks.append(mask)\n",
    "#     return pruner\n",
    "\n",
    "# const_fan_pruner = random_sparsify(pruner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 62, 0, 62, 62, 62, 62, 0]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pruner.inital_ablated_filters   # TODO: Make sure this matches below!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 2, 0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def _update_current_filter_ablation(pruner) -> None:\n",
    "    def get_num_ablated_filters(mask) -> int:\n",
    "        if mask is None:\n",
    "            return 0\n",
    "        else:\n",
    "            return torch.sum(\n",
    "                torch.stack([~filter.any() for filter in mask])\n",
    "            ).item()\n",
    "\n",
    "    ablated_filters = [\n",
    "        get_num_ablated_filters(filter) for filter in pruner.backward_masks\n",
    "    ]\n",
    "    return ablated_filters\n",
    "\n",
    "_update_current_filter_ablation(pruner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9199324398812323"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pruner.S[-6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1, 1])\n",
      "tensor(False, device='cuda:0')\n",
      "torch.Size([64, 1, 1])\n",
      "tensor(False, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "pruner.backward_masks[-6]\n",
    "\n",
    "for filter in pruner.backward_masks[-6]:\n",
    "    if  ~filter.any():\n",
    "        print(filter.shape)\n",
    "        print(filter.any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_zero_filters = 0\n",
    "for f in mask:\n",
    "    if f.any():\n",
    "        non_zero_filters+=1\n",
    "non_zero_filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(8, device='cuda:0')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pruner.backward_masks[21][0].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0060, device='cuda:0')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pruner.backward_masks[21].sum() / pruner.backward_masks[21].numel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0060073598943634066"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1-pruner.S[21]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 128, 3, 3])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pruner.backward_masks[21].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.006944444444444444"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "8*128 / pruner.backward_masks[21].numel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "147456"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pruner.backward_masks[21].numel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.006944444444444444"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "8*128 / 147456"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.007568359375"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "18*62 / 147456"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.005997474747474747"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "456/76032"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66\n",
      "885\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from rigl_torch.utils.rigl_utils import calculate_fan_in_and_fan_out\n",
    "import math\n",
    "idx=21\n",
    "weight_tensor = pruner.W[idx]\n",
    "num_neurons_to_ablate = pruner.ablated_filters[idx]\n",
    "sparsity = pruner.S[idx]\n",
    "active_neurons = weight_tensor.shape[0] - num_neurons_to_ablate\n",
    "print(active_neurons)\n",
    "remaining_non_zero_elements = math.floor(weight_tensor.numel() * (1 - sparsity))\n",
    "print(remaining_non_zero_elements)\n",
    "remaining_non_zero_elements // active_neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pruner.ablated_filters[21]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9970987955729167"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1-(6.9*62 / weight_tensor.numel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9939926401056366"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparsity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 128, 3, 3])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.002685546875"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "6*66 / weight_tensor.numel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0060073598943634066"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1-sparsity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_filter_sparsity(mask): \n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0030975449455311315"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(dense_fan_in * (pruner.W[21].shape[0]-62) * (1-pruner.S[21])) / pruner.W[21][:].numel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pruner.W[21][62:].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "456.75158748823856"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(dense_fan_in * (pruner.W[21].shape[0]-62) * (1-pruner.S[21])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_fan_in_after_ablation(\n",
    "    weight_tensor = pruner.W[21],\n",
    "    num_neurons_to_ablate=62,\n",
    "    sparsity=pruner.S[21]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71424"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remaining_els * "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0060, device='cuda:0')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pruner.backward_masks[21].sum() / pruner.backward_masks[21].numel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0060073598943634066"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1-pruner.S[21]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.008680555555555556\n",
      "15\n",
      "0.005208333333333333\n",
      "16\n",
      "0.008680555555555556\n",
      "17\n",
      "0.005208333333333333\n",
      "18\n",
      "0.005208333333333333\n",
      "19\n",
      "0.005208333333333333\n",
      "20\n",
      "0.005208333333333333\n",
      "21\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "for idx, (w,s) in enumerate(list(zip(pruner.W, pruner.S))):\n",
    "    if s is None: \n",
    "        continue\n",
    "    unadjusted_fan_in = w.shape[1]*math.prod(w.shape[2:])\n",
    "    sparse_fan_in = int( (1-s) * unadjusted_fan_in)\n",
    "    out_channels = w.shape[1]\n",
    "    receptive_field_size=9\n",
    "    unadjusted_filter_sparsity = sparse_fan_in / (out_channels * receptive_field_size)\n",
    "    if unadjusted_filter_sparsity < 0.01:\n",
    "        print(unadjusted_filter_sparsity)\n",
    "        print(idx)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pruner.ablated_filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 27])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from rigl_torch.utils.rigl_utils import calculate_fan_in_and_fan_out\n",
    "idx=0\n",
    "\n",
    "w = pruner.W[idx]\n",
    "fan_in, fan_out = calculate_fan_in_and_fan_out(w)\n",
    "s = int(fan_in * pruner.S[idx])\n",
    "perm = torch.concat(\n",
    "    [\n",
    "        torch.randperm(fan_in).reshape(1, -1)\n",
    "        for i in range(w.shape[0])\n",
    "    ]\n",
    ")\n",
    "perm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8043404410996132"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pruner.S[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2222222222222222"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(27-21)/27"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 21])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perm = perm[\n",
    ":, :s\n",
    "]  # Drop s elements from n to achieve desired sparsity\n",
    "perm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "144"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "math.prod(w.shape[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 16, 3, 3])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8043404410996132,\n",
       " 0.9603789393226717,\n",
       " 0.9743196828943242,\n",
       " 0.6698244943555973,\n",
       " 0.9743196828943242,\n",
       " 0.9743196828943242,\n",
       " 0.9743196828943242,\n",
       " 0.9743196828943242,\n",
       " 0.9812900546801505,\n",
       " 0.9877101339565695,\n",
       " 0.8382140022342427,\n",
       " 0.9877101339565695,\n",
       " 0.9877101339565695,\n",
       " 0.9877101339565695,\n",
       " 0.9877101339565695,\n",
       " 0.9909201735947789,\n",
       " 0.9939926401056366,\n",
       " 0.9199324398812323,\n",
       " 0.9939926401056366,\n",
       " 0.9939926401056366,\n",
       " 0.9939926401056366,\n",
       " 0.9939926401056366,\n",
       " 0.6354862417685794]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pruner.S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv1 = model.get_submodule(\"conv1\")\n",
    "conv1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27, 144)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.init._calculate_fan_in_and_fan_out(conv1.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.0"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "144/16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in pruner.backward_masks:\n",
    "    if m is None:\n",
    "        continue\n",
    "    else:\n",
    "        break\n",
    "        print(m.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9603789393226717"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pruner.S[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 128, 3, 3])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pruner.backward_masks[-2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = pruner.backward_masks[20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9939926401056366"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pruner.S[20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 128, 3, 3])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pruner.backward_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 128, 3, 3])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9939926401056366"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pruner.S[20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9940, device='cuda:0')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 - ( m.sum() / m.numel() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_abalation_mask = torch.ones(size=m.shape, dtype=torch.bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 128, 3, 3])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m[:1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9939926401056366"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pruner.S[20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0060073598943634066"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1-pruner.S[20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.006008572149767133\n"
     ]
    }
   ],
   "source": [
    "def get_filter_s(filter) -> float:\n",
    "    return (filter.sum() / filter.numel()).item()\n",
    "\n",
    "filter_sparsities = list(map(get_filter_s, m))\n",
    "avg_filter_s = sum(filter_sparsities)/len(filter_sparsities)\n",
    "if avg_filter_s < 0.1:\n",
    "    print(avg_filter_s)\n",
    "m[0].numel()\n",
    "num_filters = m.numel()\n",
    "# m.shape[0] * m[0].numel()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 0: \n",
      "0.196759263984859\n",
      "0.08629842102527618\n",
      "Layer 1: \n",
      "0.039713542646495625\n",
      "0.013802867382764816\n",
      "Layer 2: \n",
      "0.025716146221384406\n",
      "0.008679855614900589\n",
      "Layer 3: \n",
      "0.33203125\n",
      "0.1387929469347\n",
      "Layer 4: \n",
      "0.025716146228660364\n",
      "0.008266767486929893\n",
      "Layer 5: \n",
      "0.025716146221384406\n",
      "0.009327770210802555\n",
      "Layer 6: \n",
      "0.025716146337799728\n",
      "0.00817213486880064\n",
      "Layer 7: \n",
      "0.02571614623593632\n",
      "0.011185742914676666\n",
      "Layer 8: \n",
      "0.018717448412644444\n",
      "0.00805725622922182\n",
      "Layer 9: \n",
      "0.012315538364418899\n",
      "0.004985100124031305\n",
      "Layer 10: \n",
      "0.162109375\n",
      "0.06678630411624908\n",
      "Layer 11: \n",
      "0.012315538457187358\n",
      "0.004511543083935976\n",
      "Layer 12: \n",
      "0.01231553842080757\n",
      "0.0046781389974057674\n",
      "Layer 13: \n",
      "0.012315538442635443\n",
      "0.005127036478370428\n",
      "Layer 14: \n",
      "0.012315538398979697\n",
      "0.0044474611058831215\n",
      "Layer 15: \n",
      "0.009087456804991234\n",
      "0.003371547209098935\n",
      "Layer 16: \n",
      "0.00600857215204087\n",
      "0.002363148145377636\n",
      "Layer 17: \n",
      "0.080078125\n",
      "0.033391211181879044\n",
      "Layer 18: \n",
      "0.0060085721570430906\n",
      "0.002108385320752859\n",
      "Layer 19: \n",
      "0.0060085721570430906\n",
      "0.002471152227371931\n",
      "Layer 20: \n",
      "0.006008572149767133\n",
      "0.0019806979689747095\n",
      "Layer 21: \n",
      "0.006008572162045311\n",
      "0.0021938891150057316\n",
      "Layer 22: \n",
      "0.36484375\n",
      "0.050771232694387436\n"
     ]
    }
   ],
   "source": [
    "def get_filters_to_prune(mask):\n",
    "    m = mask\n",
    "    kernel_size = m.shape[-2] * m.shape[-1]\n",
    "    in_channels = m.shape[0]\n",
    "    out_channels = m.shape[1]\n",
    "    avg_filter_s = []\n",
    "    for filter in m:\n",
    "        avg_filter_s.append((filter.sum() / filter.numel()).item())\n",
    "    print(sum(avg_filter_s) / len(avg_filter_s))\n",
    "    print(torch.std(torch.tensor(avg_filter_s)).item())\n",
    "        \n",
    "for idx, mask in enumerate(pruner.backward_masks):\n",
    "    # if idx != 20:\n",
    "    #     continue\n",
    "    print(f\"Layer {idx}: \")\n",
    "    if mask is None:\n",
    "        print( \"NONE\")\n",
    "    else:\n",
    "        get_filters_to_prune(mask)\n",
    "        \n",
    "\n",
    "# filter_abalation_mask = torch.ones(shape=mask.shape, dtype=torch.bool)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5/9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = torch.nn.Conv2d(in_channels=3, out_channels=32, kernel_size=(3,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 3, 3, 3])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 128, 3, 3])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/user/condensed-sparsity')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Checkpoint.parent_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/user/condensed-sparsity/artifacts/checkpoints'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg.paths.checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:rigl_torch.utils.checkpoint:Loading checkpoint from /home/user/condensed-sparsity/artifacts/checkpoints/20221009_2d4v4ezc/checkpoint.pt.tar...\n"
     ]
    }
   ],
   "source": [
    "# 99% sparse runs\n",
    "from rigl_torch.utils.checkpoint import Checkpoint\n",
    "const_fan_in_run_id = \"2d4v4ezc\"\n",
    "vanilla_rigl_run_id = \"xhnqnd6c\"\n",
    "\n",
    "const_fan_ckp = Checkpoint.load_last_checkpoint(run_id=const_fan_in_run_id, parent_dir=cfg.paths.checkpoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:rigl_torch.utils.checkpoint:Loading checkpoint from /home/user/condensed-sparsity/artifacts/checkpoints/20221011_xhnqnd6c/checkpoint.pt.tar...\n"
     ]
    }
   ],
   "source": [
    "vanilla_rigl_ckp = Checkpoint.load_last_checkpoint(run_id=vanilla_rigl_run_id, parent_dir=cfg.paths.checkpoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "const_fan_masks =const_fan_ckp.pruner[\"backward_masks\"]\n",
    "vanilla_rigl_masks =vanilla_rigl_ckp.pruner[\"backward_masks\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9957, device='cuda:0')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 - ( vanilla_rigl_masks[35].sum() / vanilla_rigl_masks[35].numel() ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2421875\n",
      "62\n"
     ]
    }
   ],
   "source": [
    "total = 0\n",
    "zeros = 0\n",
    "for filter in vanilla_rigl_masks[35]:\n",
    "    total+=1\n",
    "    if filter.any():\n",
    "        # print(\"Not zero!\")\n",
    "        continue\n",
    "    else:\n",
    "        # print(\"zero\")\n",
    "        zeros+=1\n",
    "print(zeros/total)\n",
    "print(zeros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(9.8672, device='cuda:0')\n",
      "tensor(10.5944, device='cuda:0')\n",
      "46\n"
     ]
    }
   ],
   "source": [
    "non_zero = []\n",
    "max = 0\n",
    "for filter in vanilla_rigl_masks[35]:\n",
    "    non_zero.append(filter.sum())\n",
    "    if max < filter.sum().item():\n",
    "        max = filter.sum().item()\n",
    "non_zero = torch.stack(non_zero).type(torch.float32)\n",
    "print(torch.mean(non_zero))\n",
    "print(torch.std(non_zero))\n",
    "print(max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0043, device='cuda:0')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vanilla_rigl_masks[35].sum() / vanilla_rigl_masks[35].numel() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.390625"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1/256*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00390625"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "9/(256*3*3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9957, device='cuda:0')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 - ( vanilla_rigl_masks[35].sum() / vanilla_rigl_masks[35].numel() ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.9965277777777777"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "46/(256*3*3)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4340277777777778"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "10/(256*3*3)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'fan_in' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [38], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m thres \u001b[39m=\u001b[39m \u001b[39m0.5\u001b[39m\n\u001b[0;32m----> 2\u001b[0m n \u001b[39m=\u001b[39m \u001b[39m0.5\u001b[39m\u001b[39m/\u001b[39m\u001b[39m100\u001b[39m\u001b[39m/\u001b[39mfan_in\u001b[39m*\u001b[39m()\n\u001b[1;32m      3\u001b[0m fan_in\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m\n\u001b[1;32m      4\u001b[0m fan_in\u001b[39m/\u001b[39m((\u001b[39m256\u001b[39m\u001b[39m-\u001b[39mn)\u001b[39m*\u001b[39m\u001b[39m3\u001b[39m\u001b[39m*\u001b[39m\u001b[39m3\u001b[39m)\u001b[39m*\u001b[39m\u001b[39m100\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'fan_in' is not defined"
     ]
    }
   ],
   "source": [
    "thres = 0.5\n",
    "n = 0.5/100/fan_in*()\n",
    "fan_in=10\n",
    "fan_in/((256-n)*3*3)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.10.6 64-bit' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/usr/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "256-10*100/(0.5*9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.10.6 64-bit' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/usr/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "def get_filters_to_prune(mask):\n",
    "    m = mask\n",
    "    kernel_size = m.shape[-2] * m.shape[-1]\n",
    "    in_channels = m.shape[0]\n",
    "    out_channels = m.shape[1]\n",
    "    mask_sparsity = 1 - (mask.sum() / mask.numel()).item()\n",
    "    fan_in = mask[0].sum()\n",
    "    target_filter_sparsity_percent = 0.5\n",
    "    return out_channels - fan_in * 100 / (target_filter_sparsity_percent * kernel_size)\n",
    "    avg_filter_s = []\n",
    "    for filter in m:\n",
    "        avg_filter_s.append((filter.sum() / filter.numel()).item())\n",
    "    print(sum(avg_filter_s) / len(avg_filter_s))\n",
    "    print(torch.std(torch.tensor(avg_filter_s)).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.10.6 64-bit' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/usr/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "fan_in=10\n",
    "n=33.78\n",
    "fan_in/((256-n)*3*3)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.10.6 64-bit' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/usr/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "vanilla_rigl_masks[35].sum() / vanilla_rigl_masks[35].numel()*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.10.6 64-bit' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/usr/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "vanilla_rigl_masks[35].numel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.10.6 64-bit' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/usr/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "vanilla_rigl_masks[35].sum() / ((256-62)*256*3*3) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.10.6 64-bit' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/usr/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "vanilla_rigl_masks[35].sum() / ((256-0)*256*3*3) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.10.6 64-bit' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/usr/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "62*256*3*3 / (256*256*3*3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.10.6 64-bit' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/usr/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "non_zero.type(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.10.6 64-bit' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/usr/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "(non_zero>9).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.10.6 64-bit' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/usr/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "194/256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.10.6 64-bit' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/usr/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "62*256*3*3 / (256*256*3*3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.10.6 64-bit' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/usr/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "vanilla_rigl_masks[35].sum() / ((256-62)*256*3*3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.10.6 64-bit' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/usr/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "vanilla_rigl_masks[35].sum() / (256*256*3*3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.10.6 64-bit' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/usr/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "vanilla_rigl_ckp.pruner[\"S\"][35]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.10.6 64-bit' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/usr/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "1-vanilla_rigl_ckp.pruner[\"S\"][35]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.10.6 64-bit' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/usr/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# Compare this with model weights to close loop on investigating 00 weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.10.6 64-bit' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/usr/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "vanilla_rigl_ckp.pruner.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.10.6 64-bit' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/usr/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "for idx, f in enumerate(vanilla_rigl_masks[35]):\n",
    "    print(1 - (f.sum() / f.numel()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.10.6 64-bit' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/usr/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.10.6 64-bit' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/usr/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "10/(256*9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.10.6 64-bit' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/usr/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "const_fan_masks[35][0].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.10.6 64-bit' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/usr/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "for idx, mask in enumerate(const_fan_masks):\n",
    "    if idx != 35:\n",
    "        continue\n",
    "    print(f\"Layer {idx}: \")\n",
    "    if mask is None:\n",
    "        print( \"NONE\")\n",
    "    else:\n",
    "        get_filters_to_prune(mask)\n",
    "        \n",
    "for idx, mask in enumerate(vanilla_rigl_masks):\n",
    "    if idx != 35:\n",
    "        continue\n",
    "    print(f\"Layer {idx}: \")\n",
    "    if mask is None:\n",
    "        print( \"NONE\")\n",
    "    else:\n",
    "        get_filters_to_prune(mask)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 ('.venv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "816b48dc46e0e4033a4b7ddacb526e2f216437e7413cf9fdf092ed7be3b64e38"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
