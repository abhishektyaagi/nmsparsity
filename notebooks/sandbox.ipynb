{
   "cells": [
      {
         "cell_type": "code",
         "execution_count": 18,
         "metadata": {},
         "outputs": [],
         "source": [
            "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts, CosineAnnealingLR, _LRScheduler\n",
            "from torch.optim import AdamW\n",
            "import math\n",
            "from rigl_torch.datasets import get_dataloaders\n",
            "from rigl_torch.optim import StepLrWithLinearWarmUp\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 19,
         "metadata": {},
         "outputs": [
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  "/tmp/ipykernel_670772/280303579.py:6: UserWarning: \n",
                  "The version_base parameter is not specified.\n",
                  "Please specify a compatability version level, or None.\n",
                  "Will assume defaults for version 1.1\n",
                  "  with hydra.initialize(config_path=\"../configs\"):\n",
                  "INFO:/home/condensed-sparsity/src/rigl_torch/models/model_factory.py:Loading model wide_resnet22/cifar10 using <function get_wide_resnet_22 at 0x7f221a9fc4c0> with args: () and kwargs: {}\n"
               ]
            }
         ],
         "source": [
            "from rigl_torch.datasets import get_dataloaders\n",
            "from omegaconf import DictConfig\n",
            "from rigl_torch.models import ModelFactory\n",
            "import hydra\n",
            "\n",
            "with hydra.initialize(config_path=\"../configs\"):\n",
            "    cfg = hydra.compose(config_name=\"config.yaml\", overrides=[\"dataset=cifar10\", \"model=wide_resnet22\"])\n",
            "cfg\n",
            "\n",
            "net = ModelFactory.load_model(\"wide_resnet22\", \"cifar10\")"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 20,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Files already downloaded and verified\n"
               ]
            }
         ],
         "source": [
            "import torchvision\n",
            "cifar = torchvision.datasets.CIFAR10(root=\"../data/\", download=True)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 21,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "50000"
                  ]
               },
               "execution_count": 21,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "len(cifar)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 22,
         "metadata": {},
         "outputs": [
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  "Traceback (most recent call last):\n",
                  "  File \"<string>\", line 1, in <module>\n",
                  "  File \"/opt/conda/lib/python3.8/multiprocessing/spawn.py\", line 116, in spawn_main\n",
                  "    exitcode = _main(fd, parent_sentinel)\n",
                  "  File \"/opt/conda/lib/python3.8/multiprocessing/spawn.py\", line 126, in _main\n",
                  "    self = reduction.pickle.load(from_parent)\n",
                  "AttributeError: Can't get attribute 'main' on <module '__main__' (built-in)>\n",
                  "Traceback (most recent call last):\n",
                  "  File \"<string>\", line 1, in <module>\n",
                  "  File \"/opt/conda/lib/python3.8/multiprocessing/spawn.py\", line 116, in spawn_main\n",
                  "    exitcode = _main(fd, parent_sentinel)\n",
                  "  File \"/opt/conda/lib/python3.8/multiprocessing/spawn.py\", line 126, in _main\n",
                  "    self = reduction.pickle.load(from_parent)\n",
                  "AttributeError: Can't get attribute 'main' on <module '__main__' (built-in)>\n"
               ]
            },
            {
               "ename": "KeyboardInterrupt",
               "evalue": "",
               "output_type": "error",
               "traceback": [
                  "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                  "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
                  "Cell \u001b[0;32mIn [22], line 24\u001b[0m\n\u001b[1;32m     13\u001b[0m     train_loader \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataLoader(\n\u001b[1;32m     14\u001b[0m         cifar,\n\u001b[1;32m     15\u001b[0m         sampler\u001b[38;5;241m=\u001b[39mtrain_sampler,\n\u001b[1;32m     16\u001b[0m         batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m128\u001b[39m,\n\u001b[1;32m     17\u001b[0m         shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     18\u001b[0m     )\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNum samples in rank \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrank\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(train_loader)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m256\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m) \n\u001b[0;32m---> 24\u001b[0m \u001b[43mmp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mspawn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnprocs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m)\u001b[49m\n",
                  "File \u001b[0;32m~/build/.venv/lib/python3.8/site-packages/torch/multiprocessing/spawn.py:240\u001b[0m, in \u001b[0;36mspawn\u001b[0;34m(fn, args, nprocs, join, daemon, start_method)\u001b[0m\n\u001b[1;32m    236\u001b[0m     msg \u001b[39m=\u001b[39m (\u001b[39m'\u001b[39m\u001b[39mThis method only supports start_method=spawn (got: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m).\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m'\u001b[39m\n\u001b[1;32m    237\u001b[0m            \u001b[39m'\u001b[39m\u001b[39mTo use a different start_method use:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\t\u001b[39;00m\u001b[39m\\t\u001b[39;00m\u001b[39m'\u001b[39m\n\u001b[1;32m    238\u001b[0m            \u001b[39m'\u001b[39m\u001b[39m torch.multiprocessing.start_processes(...)\u001b[39m\u001b[39m'\u001b[39m \u001b[39m%\u001b[39m start_method)\n\u001b[1;32m    239\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(msg)\n\u001b[0;32m--> 240\u001b[0m \u001b[39mreturn\u001b[39;00m start_processes(fn, args, nprocs, join, daemon, start_method\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mspawn\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
                  "File \u001b[0;32m~/build/.venv/lib/python3.8/site-packages/torch/multiprocessing/spawn.py:198\u001b[0m, in \u001b[0;36mstart_processes\u001b[0;34m(fn, args, nprocs, join, daemon, start_method)\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[39mreturn\u001b[39;00m context\n\u001b[1;32m    197\u001b[0m \u001b[39m# Loop on join until it returns True or raises an exception.\u001b[39;00m\n\u001b[0;32m--> 198\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mnot\u001b[39;00m context\u001b[39m.\u001b[39;49mjoin():\n\u001b[1;32m    199\u001b[0m     \u001b[39mpass\u001b[39;00m\n",
                  "File \u001b[0;32m~/build/.venv/lib/python3.8/site-packages/torch/multiprocessing/spawn.py:109\u001b[0m, in \u001b[0;36mProcessContext.join\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    106\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    108\u001b[0m \u001b[39m# Wait for any process to fail or all of them to succeed.\u001b[39;00m\n\u001b[0;32m--> 109\u001b[0m ready \u001b[39m=\u001b[39m multiprocessing\u001b[39m.\u001b[39;49mconnection\u001b[39m.\u001b[39;49mwait(\n\u001b[1;32m    110\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msentinels\u001b[39m.\u001b[39;49mkeys(),\n\u001b[1;32m    111\u001b[0m     timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[1;32m    112\u001b[0m )\n\u001b[1;32m    114\u001b[0m error_index \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    115\u001b[0m \u001b[39mfor\u001b[39;00m sentinel \u001b[39min\u001b[39;00m ready:\n",
                  "File \u001b[0;32m/opt/conda/lib/python3.8/multiprocessing/connection.py:931\u001b[0m, in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    928\u001b[0m     deadline \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mmonotonic() \u001b[39m+\u001b[39m timeout\n\u001b[1;32m    930\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 931\u001b[0m     ready \u001b[39m=\u001b[39m selector\u001b[39m.\u001b[39;49mselect(timeout)\n\u001b[1;32m    932\u001b[0m     \u001b[39mif\u001b[39;00m ready:\n\u001b[1;32m    933\u001b[0m         \u001b[39mreturn\u001b[39;00m [key\u001b[39m.\u001b[39mfileobj \u001b[39mfor\u001b[39;00m (key, events) \u001b[39min\u001b[39;00m ready]\n",
                  "File \u001b[0;32m/opt/conda/lib/python3.8/selectors.py:415\u001b[0m, in \u001b[0;36m_PollLikeSelector.select\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    413\u001b[0m ready \u001b[39m=\u001b[39m []\n\u001b[1;32m    414\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 415\u001b[0m     fd_event_list \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_selector\u001b[39m.\u001b[39;49mpoll(timeout)\n\u001b[1;32m    416\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mInterruptedError\u001b[39;00m:\n\u001b[1;32m    417\u001b[0m     \u001b[39mreturn\u001b[39;00m ready\n",
                  "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
               ]
            }
         ],
         "source": [
            "import torch\n",
            "import torch.nn.functional as F\n",
            "import torch.multiprocessing as mp\n",
            "import torch.distributed as dist\n",
            "from torch.nn.parallel import DistributedDataParallel\n",
            "\n",
            "def main(rank, cfg):\n",
            "    cifar = torchvision.datasets.CIFAR10(root=\"../data/\", download=True)\n",
            "    device = torch.device(f\"cuda:{rank}\")\n",
            "    train_sampler = torch.utils.data.distributed.DistributedSampler(\n",
            "        cifar, drop_last=True\n",
            "    )\n",
            "    train_loader = torch.utils.data.DataLoader(\n",
            "        cifar,\n",
            "        sampler=train_sampler,\n",
            "        batch_size=128,\n",
            "        shuffle=True,\n",
            "    )\n",
            "    print(f\"Num samples in rank {rank}: {len(train_loader)*256}\") \n",
            "\n",
            "    \n",
            "\n",
            "\n",
            "mp.spawn(\n",
            "    main,\n",
            "    args=(cfg,),\n",
            "    nprocs=2,\n",
            ")"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 5,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Files already downloaded and verified\n"
               ]
            }
         ],
         "source": [
            "train, test = get_dataloaders(cfg)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 6,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "32"
                  ]
               },
               "execution_count": 6,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "cfg.training.batch_size"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 7,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "1562"
                  ]
               },
               "execution_count": 7,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "len(train)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 8,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "50000"
                  ]
               },
               "execution_count": 8,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "len(train.dataset)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 9,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "1562.5"
                  ]
               },
               "execution_count": 9,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "len(train.dataset) / cfg.training.batch_size"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 10,
         "metadata": {},
         "outputs": [],
         "source": [
            "for imgs,labels in train:\n",
            "    break"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 11,
         "metadata": {},
         "outputs": [],
         "source": [
            "import torch\n",
            "from rigl_torch.optim import get_lr_scheduler, get_optimizer\n",
            "optim = get_optimizer(cfg, net, None)\n",
            "lr_scheduler = get_lr_scheduler(cfg, optim, None)\n",
            "\n",
            "\n",
            "\n",
            "# adamw1 = AdamW(net.parameters(), lr=0.001)\n",
            "# adamw2 = AdamW(net.parameters(), lr=0.001)\n",
            "# linear_step = torch.optim.lr_scheduler.StepLR(adamw2, step_size=30000, gamma=0.2)\n",
            "# cawr = CosineAnnealingWarmRestarts(optimizer=adamw1, T_0=20, T_mult=2)\n",
            "# ca = CosineAnnealingLR(optimizer=adamw2, T_max=T_max)\n",
            "# adamw3 = AdamW(net.parameters(), lr=0.001)\n",
            "# test= CosineAnnealingWithLinearWarmUp(optimizer=adamw3, T_max=T_max, warm_up_steps=50, lr=0.001)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 12,
         "metadata": {},
         "outputs": [],
         "source": [
            "# lr_scheduler.get_last_lr()"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 13,
         "metadata": {},
         "outputs": [],
         "source": [
            "# lr_scheduler.step_size"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 14,
         "metadata": {},
         "outputs": [
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  "/home/user/build/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:131: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
                  "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n",
                  "INFO:/home/condensed-sparsity/src/rigl_torch/optim/step_lr_with_linear_warm_up.py:Reducing LR to 0.16000000000000003 @ epoch 30\n",
                  "INFO:/home/condensed-sparsity/src/rigl_torch/optim/step_lr_with_linear_warm_up.py:Reducing LR to 0.016000000000000004 @ epoch 70\n",
                  "INFO:/home/condensed-sparsity/src/rigl_torch/optim/step_lr_with_linear_warm_up.py:Reducing LR to 0.0016000000000000005 @ epoch 90\n"
               ]
            }
         ],
         "source": [
            "%matplotlib inline\n",
            "lrs=[]\n",
            "step_lrs=[]\n",
            "# from torch.optim.lr_scheduler import StepLR\n",
            "# step_scheduler = StepLR(optim, step_size=30, gamma=0.1)\n",
            "for epoch in range(0,100):\n",
            "    # lr = [group[\"lr\"] for group in optim.param_groups][0]\n",
            "    lr=lr_scheduler.get_last_lr()[0]\n",
            "    lrs.append(lr)\n",
            "    lr_scheduler.step()\n",
            "    # lr = [group[\"lr\"] for group in optim.param_groups][0]\n",
            "    # step_lrs.append(lr)\n",
            "    # step_scheduler.step()\n",
            "\n",
            "# for x in range(T_max):\n",
            "#     lr1 = cawr.get_last_lr()\n",
            "#     warm_restart_lrs.append(lr1)\n",
            "#     cawr.step()\n",
            "#     lr2 = linear_step.get_last_lr()\n",
            "#     linear_step_lrs.append(lr2)\n",
            "#     linear_step.step()\n",
            "    # combined.append(lr1[0] * lr2[0]*1000)\n",
            "    # lr3 = test.get_last_lr()\n",
            "    # linear_warmup.append(lr3)\n",
            "    # test.step()"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 15,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "[<matplotlib.lines.Line2D at 0x7f21f70572b0>]"
                  ]
               },
               "execution_count": 15,
               "metadata": {},
               "output_type": "execute_result"
            },
            {
               "data": {
                  "image/png": "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",
                  "text/plain": [
                     "<Figure size 432x288 with 1 Axes>"
                  ]
               },
               "metadata": {
                  "needs_background": "light"
               },
               "output_type": "display_data"
            }
         ],
         "source": [
            "import matplotlib.pyplot as plt\n",
            "\n",
            "plt.plot(lrs)\n",
            "# plt.plot(step_lrs)\n",
            "# plt.plot(combined)\n",
            "# plt.plot(linear_warmup)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 16,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "[1.6, 1.6, 0.16000000000000003, 0.16000000000000003]"
                  ]
               },
               "execution_count": 16,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "lrs[28:32]"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 17,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "0.16000000000000003"
                  ]
               },
               "execution_count": 17,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "lrs[31]"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "from rigl_torch.models import get_model\n",
            "from rigl_torch.datasets import get_dataloaders\n",
            "from omegaconf import DictConfig\n",
            "import hydra"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "with hydra.initialize(config_path=\"../configs\"):\n",
            "    cfg = hydra.compose(config_name=\"config.yaml\", overrides=[])\n",
            "cfg"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "def print_image_shape(module, input, output):\n",
            "    print(f\"Module {module._get_name()}\")\n",
            "    print(f\"input shape: {input[0].shape} output shape: {output.shape}\")\n",
            "    return output"
         ]
      }
   ],
   "metadata": {
      "kernelspec": {
         "display_name": "Python 3.8.12 ('.venv')",
         "language": "python",
         "name": "python3"
      },
      "language_info": {
         "codemirror_mode": {
            "name": "ipython",
            "version": 3
         },
         "file_extension": ".py",
         "mimetype": "text/x-python",
         "name": "python",
         "nbconvert_exporter": "python",
         "pygments_lexer": "ipython3",
         "version": "3.8.12"
      },
      "orig_nbformat": 4,
      "vscode": {
         "interpreter": {
            "hash": "816b48dc46e0e4033a4b7ddacb526e2f216437e7413cf9fdf092ed7be3b64e38"
         }
      }
   },
   "nbformat": 4,
   "nbformat_minor": 2
}
