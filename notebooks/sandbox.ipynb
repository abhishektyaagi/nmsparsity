{
   "cells": [
      {
         "cell_type": "code",
         "execution_count": 1,
         "metadata": {},
         "outputs": [],
         "source": [
            "import torch\n",
            "\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 2,
         "metadata": {},
         "outputs": [],
         "source": [
            "import torch\n",
            "from torchvision.models.feature_extraction import create_feature_extractor, get_graph_node_names\n",
            "from rigl_torch.models import ModelFactory\n",
            "\n",
            "class Model(torch.nn.Module):\n",
            "    def __init__(self):\n",
            "        super().__init__()\n",
            "        self.name = \"model\"\n",
            "        self.lin1 = torch.nn.Linear(in_features=10,out_features=100)\n",
            "        self.lin2 = torch.nn.Linear(in_features=100,out_features=1)\n",
            "    \n",
            "    def forward(self, input):\n",
            "        x = self.lin1(input)\n",
            "        x = torch.nn.ReLU(x)\n",
            "        x = self.lin2(x)\n",
            "        return x\n",
            "    \n",
            "    \n",
            "x= torch.Tensor([x for x in range(10)])\n",
            "y=torch.Tensor([100])\n",
            "model = Model()\n",
            "# out = model(x)\n",
            "\n",
            "# opt = torch.optim.SGD(\n",
            "#     params=model.parameters(),\n",
            "#     lr=0.01,\n",
            "#     momentum=0.9,\n",
            "#     weight_decay=0.0005,\n",
            "# )\n",
            "# criterion = torch.nn.MSELoss()\n",
            "# loss = criterion(out, y)\n",
            "# loss.backward()\n",
            "\n",
            "# for p in model.parameters():\n",
            "#     print(p.grad)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 26,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "torch.Size([100, 10])"
                  ]
               },
               "execution_count": 26,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "score_drop = torch.abs(model.lin1.weight)\n",
            "score_drop.shape"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 29,
         "metadata": {},
         "outputs": [],
         "source": [
            "values, idx = torch.topk(\n",
            "    score_drop.flatten(),\n",
            "    k=10,\n",
            "    dim=-1,\n",
            "    largest=True,\n",
            "    sorted=True\n",
            ")"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "drop_mask = "
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 135,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Model(\n",
                  "  (lin1): Linear(in_features=10, out_features=100, bias=True)\n",
                  "  (lin2): Linear(in_features=100, out_features=1, bias=True)\n",
                  ")\n",
                  "Linear(in_features=10, out_features=100, bias=True)\n",
                  "Linear(in_features=100, out_features=1, bias=True)\n"
               ]
            }
         ],
         "source": [
            "for name, p in model.named_modules():\n",
            "    print(p)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 14,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "23"
                  ]
               },
               "execution_count": 14,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "max([1,23])"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 13,
         "metadata": {},
         "outputs": [
            {
               "ename": "RuntimeError",
               "evalue": "max(): Expected reduction dim to be specified for input.numel() == 0. Specify the reduction dim with the 'dim' argument.",
               "output_type": "error",
               "traceback": [
                  "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                  "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
                  "Cell \u001b[0;32mIn [13], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m t \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mTensor([\u001b[39m1\u001b[39m,\u001b[39m2\u001b[39m,\u001b[39m3\u001b[39m])\n\u001b[1;32m      4\u001b[0m m \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mTensor([\u001b[39mTrue\u001b[39;00m, \u001b[39mTrue\u001b[39;00m, \u001b[39mTrue\u001b[39;00m])\n\u001b[0;32m----> 6\u001b[0m torch\u001b[39m.\u001b[39;49mabs(t[m \u001b[39m==\u001b[39;49m \u001b[39mFalse\u001b[39;49;00m])\u001b[39m.\u001b[39;49mmax()\u001b[39m.\u001b[39mitem()\n",
                  "\u001b[0;31mRuntimeError\u001b[0m: max(): Expected reduction dim to be specified for input.numel() == 0. Specify the reduction dim with the 'dim' argument."
               ]
            }
         ],
         "source": [
            "import torch\n",
            "\n",
            "t = torch.Tensor([1,2,3])\n",
            "m = torch.Tensor([True, True, True])\n",
            "\n",
            "torch.abs(t[m == False]).max().item()"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 131,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "model\n"
               ]
            },
            {
               "ename": "AttributeError",
               "evalue": "'Linear' object has no attribute 'name'",
               "output_type": "error",
               "traceback": [
                  "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                  "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
                  "Cell \u001b[0;32mIn [131], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfor\u001b[39;00m m \u001b[39min\u001b[39;00m model\u001b[39m.\u001b[39mmodules():\n\u001b[0;32m----> 2\u001b[0m     \u001b[39mprint\u001b[39m(m\u001b[39m.\u001b[39;49mname)\n",
                  "File \u001b[0;32m~/build/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py:1207\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1205\u001b[0m     \u001b[39mif\u001b[39;00m name \u001b[39min\u001b[39;00m modules:\n\u001b[1;32m   1206\u001b[0m         \u001b[39mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> 1207\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m object has no attribute \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m   1208\u001b[0m     \u001b[39mtype\u001b[39m(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, name))\n",
                  "\u001b[0;31mAttributeError\u001b[0m: 'Linear' object has no attribute 'name'"
               ]
            }
         ],
         "source": [
            "for m in model.modules():\n",
            "    print(m.name)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 129,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "tensor([[inf, inf, inf, inf, inf, inf, inf, inf, inf, inf],\n",
                     "        [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf],\n",
                     "        [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf],\n",
                     "        [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf],\n",
                     "        [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf],\n",
                     "        [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf],\n",
                     "        [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf],\n",
                     "        [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf],\n",
                     "        [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf],\n",
                     "        [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf],\n",
                     "        [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf],\n",
                     "        [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf],\n",
                     "        [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf],\n",
                     "        [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf],\n",
                     "        [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf],\n",
                     "        [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf],\n",
                     "        [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf],\n",
                     "        [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf],\n",
                     "        [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf],\n",
                     "        [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf],\n",
                     "        [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf],\n",
                     "        [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf],\n",
                     "        [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf],\n",
                     "        [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf],\n",
                     "        [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf],\n",
                     "        [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf],\n",
                     "        [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf],\n",
                     "        [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf],\n",
                     "        [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf],\n",
                     "        [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf],\n",
                     "        [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf],\n",
                     "        [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf],\n",
                     "        [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf],\n",
                     "        [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf],\n",
                     "        [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf],\n",
                     "        [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf],\n",
                     "        [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf],\n",
                     "        [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf],\n",
                     "        [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf],\n",
                     "        [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf],\n",
                     "        [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf],\n",
                     "        [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf],\n",
                     "        [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf],\n",
                     "        [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf],\n",
                     "        [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf],\n",
                     "        [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf],\n",
                     "        [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf],\n",
                     "        [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf],\n",
                     "        [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf],\n",
                     "        [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf],\n",
                     "        [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf],\n",
                     "        [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf],\n",
                     "        [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf],\n",
                     "        [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf],\n",
                     "        [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf],\n",
                     "        [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf],\n",
                     "        [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf],\n",
                     "        [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf],\n",
                     "        [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf],\n",
                     "        [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf],\n",
                     "        [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf],\n",
                     "        [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf],\n",
                     "        [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf],\n",
                     "        [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf],\n",
                     "        [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf],\n",
                     "        [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf],\n",
                     "        [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf],\n",
                     "        [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf],\n",
                     "        [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf],\n",
                     "        [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf],\n",
                     "        [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf],\n",
                     "        [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf],\n",
                     "        [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf],\n",
                     "        [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf],\n",
                     "        [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf],\n",
                     "        [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf],\n",
                     "        [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf],\n",
                     "        [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf],\n",
                     "        [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf],\n",
                     "        [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf],\n",
                     "        [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf],\n",
                     "        [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf],\n",
                     "        [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf],\n",
                     "        [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf],\n",
                     "        [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf],\n",
                     "        [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf],\n",
                     "        [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf],\n",
                     "        [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf],\n",
                     "        [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf],\n",
                     "        [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf],\n",
                     "        [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf],\n",
                     "        [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf],\n",
                     "        [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf],\n",
                     "        [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf],\n",
                     "        [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf],\n",
                     "        [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf],\n",
                     "        [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf],\n",
                     "        [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf],\n",
                     "        [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf],\n",
                     "        [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]])"
                  ]
               },
               "execution_count": 129,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "w = model.lin1.weight\n",
            "t = torch.Tensor(size=(w.shape))\n",
            "t[:] = torch.inf\n",
            "t[]"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 114,
         "metadata": {},
         "outputs": [
            {
               "ename": "NameError",
               "evalue": "name 'n_prune' is not defined",
               "output_type": "error",
               "traceback": [
                  "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                  "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
                  "Cell \u001b[0;32mIn [114], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m _, sorted_indices \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtopk(score_drop\u001b[39m.\u001b[39mview(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m), k\u001b[39m=\u001b[39mn_prune)\n\u001b[1;32m      2\u001b[0m new_values_test \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mzeros(size\u001b[39m=\u001b[39m(score_drop\u001b[39m.\u001b[39mflatten()\u001b[39m.\u001b[39mshape), dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mbool)\n\u001b[1;32m      3\u001b[0m new_values_test[sorted_indices] \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
                  "\u001b[0;31mNameError\u001b[0m: name 'n_prune' is not defined"
               ]
            }
         ],
         "source": [
            "n_prune=\n",
            "_, sorted_indices = torch.topk(score_drop.view(-1), k=n_prune)\n",
            "new_values_test = torch.zeros(size=(score_drop.flatten().shape), dtype=torch.bool)\n",
            "new_values_test[sorted_indices] = True"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 113,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "tensor(100)"
                  ]
               },
               "execution_count": 113,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "n_total = score_drop.numel()\n",
            "n_keep = int(n_total * 0.1)\n",
            "w = model.lin1.weight\n",
            "_, sorted_indices = torch.topk(score_drop.view(-1), k=n_total)\n",
            "new_values = torch.where(\n",
            "    torch.arange(n_total, device=w.device) < n_keep,\n",
            "    torch.ones_like(sorted_indices),\n",
            "    torch.zeros_like(sorted_indices),\n",
            ")\n",
            "mask1 = new_values.scatter(0, sorted_indices, new_values)\n",
            "mask1.sum()"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 41,
         "metadata": {},
         "outputs": [],
         "source": [
            "drop_mask = torch.zeros(size=(score_drop.numel(),), dtype=torch.bool)\n",
            "drop_mask[idx] = True"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 79,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "12"
                  ]
               },
               "execution_count": 79,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "from functools import reduce\n",
            "\n",
            "l = [\n",
            "    [1,2,3],\n",
            "    [1,2,3],\n",
            "    [1,2,3],\n",
            "    [1,2,3],\n",
            "]\n",
            "\n",
            "\n",
            "sum([len(sub_list) for sub_list in l])\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 71,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "[1]\n",
                  "None\n",
                  "None\n"
               ]
            }
         ],
         "source": [
            "reduce(lambda x,y: print(x), [[1],[2],[5],[4]])"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 47,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "tensor([481, 537, 619, 992, 443, 605, 262, 214, 170, 483])"
                  ]
               },
               "execution_count": 47,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "idx"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 49,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "tensor([0.3162, 0.3162, 0.3160, 0.3156, 0.3145, 0.3145, 0.3140, 0.3127, 0.3124,\n",
                     "        0.3117], grad_fn=<TopkBackward0>)"
                  ]
               },
               "execution_count": 49,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "drop_mask = drop_mask.reshape(shape=score_drop.shape)\n",
            "values\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 50,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "tensor([0.3162, 0.3162, 0.3160, 0.3156, 0.3145, 0.3145, 0.3140, 0.3127, 0.3124,\n",
                     "        0.3117], grad_fn=<IndexBackward0>)"
                  ]
               },
               "execution_count": 50,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "score_drop.flatten()[idx]"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 6,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "torch.Size([100, 10])"
                  ]
               },
               "execution_count": 6,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "model.lin1.weight.shape"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 8,
         "metadata": {},
         "outputs": [],
         "source": [
            "model.lin1.weight.ablated = True"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 16,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "tensor([-0.0058,  0.1171, -0.0432,  0.1910,  0.1428, -0.0060, -0.1363,  0.1132,\n",
                     "        -0.2438,  0.0087], grad_fn=<SelectBackward0>)"
                  ]
               },
               "execution_count": 16,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "model.lin1.weight[0]"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 23,
         "metadata": {},
         "outputs": [
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  "INFO:/home/user/condensed-sparsity/src/rigl_torch/models/model_factory.py:Loading model wide_resnet22/cifar10 using <function get_wide_resnet_22 at 0x7fe1195e8430> with args: () and kwargs: {}\n"
               ]
            }
         ],
         "source": [
            "wide_res = ModelFactory.load_model(model=\"wide_resnet22\", dataset=\"cifar10\")"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 38,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
                  "Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
                  "Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
                  "Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
                  "Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
                  "Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
                  "Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
                  "Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
                  "Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
                  "Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
                  "Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
                  "Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
                  "Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
                  "Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
                  "Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
                  "Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
                  "Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
                  "Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
                  "Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
                  "Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
                  "Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
                  "Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
                  "Linear(in_features=128, out_features=10, bias=True)\n"
               ]
            }
         ],
         "source": [
            "target_types = [\n",
            "    torch.nn.Conv2d,\n",
            "    torch.nn.Linear\n",
            "]\n",
            "\n",
            "\n",
            "\n",
            "for m in wide_res.modules():\n",
            "    if type(m) in target_types:\n",
            "        print(m.weight)"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 33,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)"
                  ]
               },
               "execution_count": 33,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "wide_res.get_submodule(\"conv1\")"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 31,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "Model(\n",
                     "  (lin1): Linear(in_features=10, out_features=100, bias=True)\n",
                     "  (lin2): Linear(in_features=100, out_features=1, bias=True)\n",
                     ")"
                  ]
               },
               "execution_count": 31,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "model"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 28,
         "metadata": {},
         "outputs": [
            {
               "ename": "AttributeError",
               "evalue": "Model has no attribute `conv1`",
               "output_type": "error",
               "traceback": [
                  "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                  "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
                  "Cell \u001b[0;32mIn [28], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model\u001b[39m.\u001b[39;49mget_submodule(target\u001b[39m=\u001b[39;49mtrain_nodes[\u001b[39m1\u001b[39;49m])\n",
                  "File \u001b[0;32m~/build/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py:456\u001b[0m, in \u001b[0;36mModule.get_submodule\u001b[0;34m(self, target)\u001b[0m\n\u001b[1;32m    453\u001b[0m \u001b[39mfor\u001b[39;00m item \u001b[39min\u001b[39;00m atoms:\n\u001b[1;32m    455\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(mod, item):\n\u001b[0;32m--> 456\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(mod\u001b[39m.\u001b[39m_get_name() \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m has no \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    457\u001b[0m                              \u001b[39m\"\u001b[39m\u001b[39mattribute `\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m item \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m`\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    459\u001b[0m     mod \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(mod, item)\n\u001b[1;32m    461\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(mod, torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mModule):\n",
                  "\u001b[0;31mAttributeError\u001b[0m: Model has no attribute `conv1`"
               ]
            }
         ],
         "source": [
            "model.get_submodule(target=train_nodes[1])"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 25,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "['x',\n",
                     " 'conv1',\n",
                     " 'block1.layer.0.bn1',\n",
                     " 'block1.layer.0.relu1',\n",
                     " 'block1.layer.0.conv1',\n",
                     " 'block1.layer.0.bn2',\n",
                     " 'block1.layer.0.relu2',\n",
                     " 'block1.layer.0.dropout',\n",
                     " 'block1.layer.0.conv2',\n",
                     " 'block1.layer.0.convShortcut',\n",
                     " 'block1.layer.0.add',\n",
                     " 'block1.layer.1.bn1',\n",
                     " 'block1.layer.1.relu1',\n",
                     " 'block1.layer.1.conv1',\n",
                     " 'block1.layer.1.bn2',\n",
                     " 'block1.layer.1.relu2',\n",
                     " 'block1.layer.1.dropout',\n",
                     " 'block1.layer.1.conv2',\n",
                     " 'block1.layer.1.add',\n",
                     " 'block1.layer.2.bn1',\n",
                     " 'block1.layer.2.relu1',\n",
                     " 'block1.layer.2.conv1',\n",
                     " 'block1.layer.2.bn2',\n",
                     " 'block1.layer.2.relu2',\n",
                     " 'block1.layer.2.dropout',\n",
                     " 'block1.layer.2.conv2',\n",
                     " 'block1.layer.2.add',\n",
                     " 'block2.layer.0.bn1',\n",
                     " 'block2.layer.0.relu1',\n",
                     " 'block2.layer.0.conv1',\n",
                     " 'block2.layer.0.bn2',\n",
                     " 'block2.layer.0.relu2',\n",
                     " 'block2.layer.0.dropout',\n",
                     " 'block2.layer.0.conv2',\n",
                     " 'block2.layer.0.convShortcut',\n",
                     " 'block2.layer.0.add',\n",
                     " 'block2.layer.1.bn1',\n",
                     " 'block2.layer.1.relu1',\n",
                     " 'block2.layer.1.conv1',\n",
                     " 'block2.layer.1.bn2',\n",
                     " 'block2.layer.1.relu2',\n",
                     " 'block2.layer.1.dropout',\n",
                     " 'block2.layer.1.conv2',\n",
                     " 'block2.layer.1.add',\n",
                     " 'block2.layer.2.bn1',\n",
                     " 'block2.layer.2.relu1',\n",
                     " 'block2.layer.2.conv1',\n",
                     " 'block2.layer.2.bn2',\n",
                     " 'block2.layer.2.relu2',\n",
                     " 'block2.layer.2.dropout',\n",
                     " 'block2.layer.2.conv2',\n",
                     " 'block2.layer.2.add',\n",
                     " 'block3.layer.0.bn1',\n",
                     " 'block3.layer.0.relu1',\n",
                     " 'block3.layer.0.conv1',\n",
                     " 'block3.layer.0.bn2',\n",
                     " 'block3.layer.0.relu2',\n",
                     " 'block3.layer.0.dropout',\n",
                     " 'block3.layer.0.conv2',\n",
                     " 'block3.layer.0.convShortcut',\n",
                     " 'block3.layer.0.add',\n",
                     " 'block3.layer.1.bn1',\n",
                     " 'block3.layer.1.relu1',\n",
                     " 'block3.layer.1.conv1',\n",
                     " 'block3.layer.1.bn2',\n",
                     " 'block3.layer.1.relu2',\n",
                     " 'block3.layer.1.dropout',\n",
                     " 'block3.layer.1.conv2',\n",
                     " 'block3.layer.1.add',\n",
                     " 'block3.layer.2.bn1',\n",
                     " 'block3.layer.2.relu1',\n",
                     " 'block3.layer.2.conv1',\n",
                     " 'block3.layer.2.bn2',\n",
                     " 'block3.layer.2.relu2',\n",
                     " 'block3.layer.2.dropout',\n",
                     " 'block3.layer.2.conv2',\n",
                     " 'block3.layer.2.add',\n",
                     " 'bn1',\n",
                     " 'relu',\n",
                     " 'avg_pool2d',\n",
                     " 'view',\n",
                     " 'fc',\n",
                     " 'log_softmax']"
                  ]
               },
               "execution_count": 25,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "train_nodes, _ = get_graph_node_names(wide_res)\n",
            "train_nodes"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 16,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "{'input': tensor([0., 1., 2., 3., 4., 5., 6., 7., 8., 9.]),\n",
                     " 'lin1': tensor([-8.8582e-01, -1.9572e-01,  1.1699e+00, -3.4623e-02, -2.6320e+00,\n",
                     "          4.9344e+00, -5.4388e+00,  3.8958e+00,  5.4744e-01,  3.3870e+00,\n",
                     "         -3.5351e+00,  4.2307e+00,  5.2269e+00,  9.9216e-02,  6.3042e-01,\n",
                     "         -5.8878e+00, -5.0083e+00,  2.2750e+00, -1.7004e-02,  2.7141e+00,\n",
                     "         -2.2189e-01,  8.0173e-01,  4.5409e-01,  3.4242e+00, -2.9067e+00,\n",
                     "         -2.2390e+00,  4.2819e-01,  4.9647e+00, -6.4939e-01,  2.4753e+00,\n",
                     "         -3.0932e+00,  1.5543e+00,  3.6289e+00, -2.3433e+00, -1.3665e+00,\n",
                     "          3.0302e+00, -3.7790e+00, -5.2764e+00,  6.2917e-01,  9.1728e-01,\n",
                     "          2.5309e+00,  1.0851e+00, -9.4429e-01, -3.9613e+00,  2.6849e+00,\n",
                     "          7.9153e-01, -7.9573e+00,  4.0984e+00,  2.3593e-03, -2.3005e+00,\n",
                     "         -1.0524e+00,  2.3860e+00, -2.7775e+00, -2.1299e+00,  4.0441e+00,\n",
                     "         -4.5636e+00,  5.1240e-01,  4.3078e+00, -2.8586e+00, -1.4210e+00,\n",
                     "         -6.2731e+00, -1.5812e+00,  1.4324e+00, -2.7698e+00, -3.5402e+00,\n",
                     "         -2.1792e+00, -2.5360e-01,  1.1876e+00,  3.9399e+00,  5.8667e-01,\n",
                     "         -4.9172e-01, -6.8851e-01, -2.1572e-01, -2.1126e+00,  1.8860e+00,\n",
                     "         -4.8369e-01, -1.2571e+00,  3.5463e-01,  1.5206e+00,  3.8061e+00,\n",
                     "          9.8605e-01, -3.7833e+00, -2.3683e+00, -1.9301e-01,  6.9275e-01,\n",
                     "         -3.3874e-01,  7.3349e-01,  4.8968e+00,  3.9761e+00,  8.6049e-02,\n",
                     "         -2.6653e-01, -1.5074e+00,  5.6123e-01,  6.6286e+00,  3.8089e+00,\n",
                     "         -3.2449e+00, -1.8386e+00,  4.9434e+00,  4.9066e+00, -4.0163e+00],\n",
                     "        grad_fn=<AddBackward0>),\n",
                     " 'lin2': tensor([-2.4431], grad_fn=<AddBackward0>)}"
                  ]
               },
               "execution_count": 16,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "features(x)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 15,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "{'training': True,\n",
                     " '_parameters': OrderedDict(),\n",
                     " '_buffers': OrderedDict(),\n",
                     " '_non_persistent_buffers_set': set(),\n",
                     " '_backward_hooks': OrderedDict(),\n",
                     " '_is_full_backward_hook': None,\n",
                     " '_forward_hooks': OrderedDict(),\n",
                     " '_forward_pre_hooks': OrderedDict(),\n",
                     " '_state_dict_hooks': OrderedDict(),\n",
                     " '_load_state_dict_pre_hooks': OrderedDict(),\n",
                     " '_load_state_dict_post_hooks': OrderedDict(),\n",
                     " '_modules': OrderedDict([('lin1',\n",
                     "               Linear(in_features=10, out_features=100, bias=True)),\n",
                     "              ('lin2', Linear(in_features=100, out_features=1, bias=True))]),\n",
                     " 'train_graph': <torch.fx.graph.Graph at 0x7fe22825c1c0>,\n",
                     " 'eval_graph': <torch.fx.graph.Graph at 0x7fe119699fd0>,\n",
                     " '_graph': <torch.fx.graph.Graph at 0x7fe22825c1c0>,\n",
                     " '_code': \"\\n\\n\\ndef forward(self, input):\\n    input_1 = input\\n    lin1 = self.lin1(input_1)\\n    lin2 = self.lin2(lin1)\\n    return {'input': input_1, 'lin1': lin1, 'lin2': lin2}\\n    \",\n",
                     " '_tracer_cls': torchvision.models.feature_extraction.NodePathTracer}"
                  ]
               },
               "execution_count": 15,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "features = create_feature_extractor(model=model, return_nodes=train_nodes)\n",
            "features.__dict__"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 55,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "graph():\n",
                  "    %x : [#users=1] = placeholder[target=x]\n",
                  "    %lin1 : [#users=1] = call_module[target=lin1](args = (%x,), kwargs = {})\n",
                  "    return {'lin1': lin1}\n"
               ]
            }
         ],
         "source": [
            "print(features.graph)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 44,
         "metadata": {},
         "outputs": [
            {
               "ename": "AttributeError",
               "evalue": "'Model' object has no attribute 'features'",
               "output_type": "error",
               "traceback": [
                  "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                  "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
                  "Cell \u001b[0;32mIn [44], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model\u001b[39m.\u001b[39;49mfeatures\n",
                  "File \u001b[0;32m~/build/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py:1207\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1205\u001b[0m     \u001b[39mif\u001b[39;00m name \u001b[39min\u001b[39;00m modules:\n\u001b[1;32m   1206\u001b[0m         \u001b[39mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> 1207\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m object has no attribute \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m   1208\u001b[0m     \u001b[39mtype\u001b[39m(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, name))\n",
                  "\u001b[0;31mAttributeError\u001b[0m: 'Model' object has no attribute 'features'"
               ]
            }
         ],
         "source": [
            "model.features"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 7,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "Parameter containing:\n",
                     "tensor([[-0.2615,  0.3033, -0.1964, -0.1795,  0.0906,  0.2865, -0.0448,  0.1051,\n",
                     "         -0.2138, -0.0536]], requires_grad=True)"
                  ]
               },
               "execution_count": 7,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "w = model.lin1.weight\n",
            "w"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 13,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "tensor([[    0.0000,  -200.5398,  -401.0796,  -601.6193,  -802.1591, -1002.6989,\n",
                     "         -1203.2386, -1403.7784, -1604.3182, -1804.8580]])"
                  ]
               },
               "execution_count": 13,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "w.grad"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": []
      },
      {
         "cell_type": "code",
         "execution_count": 17,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Parameter containing:\n",
                  "tensor([[-0.2615,  0.3033, -0.1964, -0.1795,  0.0906,  0.2865, -0.0448,  0.1051,\n",
                  "         -0.2138, -0.0536]], requires_grad=True)\n",
                  "tensor(-0.0164, grad_fn=<MeanBackward0>)\n",
                  "tensor(0.3033, grad_fn=<MaxBackward1>)\n",
                  "tensor(-0.2615, grad_fn=<MinBackward1>)\n",
                  "tensor(0.2056, grad_fn=<StdBackward0>)\n"
               ]
            }
         ],
         "source": [
            "print(w)\n",
            "print(torch.mean(w))\n",
            "print(torch.max(w))\n",
            "print(torch.min(w))\n",
            "print(torch.std(w))"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 19,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Parameter containing:\n",
                  "tensor([[-0.2615,  2.3087,  3.8144,  5.8367,  8.1122, 10.3135, 11.9876, 14.1429,\n",
                  "         15.8294, 17.9950]], requires_grad=True)\n",
                  "tensor(9.0079, grad_fn=<MeanBackward0>)\n",
                  "tensor(17.9950, grad_fn=<MaxBackward1>)\n",
                  "tensor(-0.2615, grad_fn=<MinBackward1>)\n",
                  "tensor(6.0817, grad_fn=<StdBackward0>)\n"
               ]
            }
         ],
         "source": [
            "print(w)\n",
            "print(torch.mean(w))\n",
            "print(torch.max(w))\n",
            "print(torch.min(w))\n",
            "print(torch.std(w))"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 32,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Parameter containing:\n",
                  "tensor([[-0.1981, -0.0283,  0.1709,  0.1945,  0.2640,  0.1104,  0.1847,  0.3026,\n",
                  "          0.1623,  0.2212]], requires_grad=True)\n"
               ]
            }
         ],
         "source": [
            "for m in model.modules():\n",
            "    if hasattr(m, \"weight\"):\n",
            "        print(m.weight)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 18,
         "metadata": {},
         "outputs": [],
         "source": [
            "opt.step()"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 60,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "Parameter containing:\n",
                     "tensor([[-0.0457,  1.5386,  3.6999,  5.3116,  7.5779,  9.2406, 11.2786, 13.0922,\n",
                     "         15.0026, 16.8836]], requires_grad=True)"
                  ]
               },
               "execution_count": 60,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "w = model.lin1.weight\n",
            "w"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 66,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "defaultdict(dict,\n",
                     "            {Parameter containing:\n",
                     "             tensor([[ 0.0099,  0.2188, -0.0234,  0.1394,  0.2305, -0.2930, -0.0341, -0.0018,\n",
                     "                      -0.1530, -0.2380]], requires_grad=True): {'momentum_buffer': tensor([[ 4.9349e-06,  1.0940e-04, -1.1701e-05,  6.9676e-05,  1.1527e-04,\n",
                     "                       -1.4650e-04, -1.7048e-05, -9.1335e-07, -7.6524e-05, -1.1902e-04]])},\n",
                     "             Parameter containing:\n",
                     "             tensor([0.0272], requires_grad=True): {'momentum_buffer': tensor([1.3598e-05])}})"
                  ]
               },
               "execution_count": 66,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "opt.state"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 1,
         "metadata": {},
         "outputs": [],
         "source": [
            "import torch\n",
            "\n",
            "\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "import torch\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 26,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "hello world\n"
               ]
            }
         ],
         "source": [
            "a = False\n",
            "def dec(fn):\n",
            "    def wrapper(*fn_args):\n",
            "        if a is True:\n",
            "            return 0\n",
            "        return fn(*fn_args)\n",
            "    return wrapper\n",
            "\n",
            "@dec\n",
            "def hello_world():\n",
            "    print('hello world')\n",
            "    \n",
            "    \n",
            "hello_world()\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": []
      },
      {
         "cell_type": "code",
         "execution_count": 15,
         "metadata": {},
         "outputs": [
            {
               "ename": "TypeError",
               "evalue": "bad operand type for unary ~: 'list'",
               "output_type": "error",
               "traceback": [
                  "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                  "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
                  "Cell \u001b[0;32mIn [15], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m arr \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mones(shape\u001b[39m=\u001b[39m(\u001b[39m16\u001b[39m,\u001b[39m3\u001b[39m,\u001b[39m3\u001b[39m,\u001b[39m3\u001b[39m))\n\u001b[1;32m      4\u001b[0m ablated_neurons\u001b[39m=\u001b[39m[\u001b[39m0\u001b[39m,\u001b[39m1\u001b[39m]\n\u001b[0;32m----> 5\u001b[0m arr[\u001b[39m~\u001b[39;49mablated_neurons]\n",
                  "\u001b[0;31mTypeError\u001b[0m: bad operand type for unary ~: 'list'"
               ]
            }
         ],
         "source": [
            "import numpy as np\n",
            "\n",
            "arr = np.ones(shape=(16,3,3,3))\n",
            "ablated_neurons=[0,1]\n",
            "arr[~ablated_neurons]"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 11,
         "metadata": {},
         "outputs": [
            {
               "ename": "TypeError",
               "evalue": "bad operand type for unary ~: 'list'",
               "output_type": "error",
               "traceback": [
                  "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                  "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
                  "Cell \u001b[0;32mIn [11], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m w \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mrand(size\u001b[39m=\u001b[39m(\u001b[39m16\u001b[39m,\u001b[39m3\u001b[39m,\u001b[39m3\u001b[39m,\u001b[39m3\u001b[39m))\n\u001b[1;32m      4\u001b[0m ablated_neurons\u001b[39m=\u001b[39m[\u001b[39m0\u001b[39m,\u001b[39m1\u001b[39m]\n\u001b[0;32m----> 5\u001b[0m w[\u001b[39m~\u001b[39;49m[ablated_neurons]]\u001b[39m.\u001b[39mshape\n",
                  "\u001b[0;31mTypeError\u001b[0m: bad operand type for unary ~: 'list'"
               ]
            }
         ],
         "source": [
            "import torch\n",
            "\n",
            "w = torch.rand(size=(16,3,3,3))\n",
            "ablated_neurons=[0,1]\n",
            "w[~[ablated_neurons]].shape"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 37,
         "metadata": {},
         "outputs": [],
         "source": [
            "import torch\n",
            "\n",
            "\n",
            "logits = torch.rand(size=(64,1000))\n",
            "vals, indx = torch.topk(logits, k=5, dim=1, largest=True)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 2,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "torch.Size([64, 5])"
                  ]
               },
               "execution_count": 2,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "indx.shape"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 3,
         "metadata": {},
         "outputs": [],
         "source": [
            "pred = torch.tensor([[0.9984], [0.9966]])\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 39,
         "metadata": {},
         "outputs": [
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  "/tmp/ipykernel_12615/1533899854.py:6: UserWarning: \n",
                  "The version_base parameter is not specified.\n",
                  "Please specify a compatability version level, or None.\n",
                  "Will assume defaults for version 1.1\n",
                  "  with hydra.initialize(config_path=\"../configs\"):\n"
               ]
            },
            {
               "data": {
                  "text/plain": [
                     "{'dataset': {'name': 'imagenet', 'normalize': False, 'num_classes': 1000, 'train_len': 1281167, 'root': '${oc.env:IMAGE_NET_PATH}', 'use_cc_data_loaders': False}, 'model': {'name': 'resnet50'}, 'experiment': {'comment': 'dense_alloc-${rigl.dense_allocation}_const_fan-${rigl.const_fan_in}_ablation-${rigl.filter_ablation_threshold}_sparse_init-${rigl.use_sparse_initialization}', 'name': '${model.name}_${dataset.name}_${experiment.comment}', 'resume_from_checkpoint': False, 'run_id': None}, 'paths': {'base': '${oc.env:BASE_PATH}', 'data_folder': '${paths.base}/data', 'artifacts': '${paths.base}/artifacts', 'logs': '${paths.base}/logs', 'checkpoints': '${paths.artifacts}/checkpoints'}, 'rigl': {'dense_allocation': 0.01, 'delta': 100, 'grad_accumulation_n': 8, 'alpha': 0.3, 'static_topo': 0, 'const_fan_in': True, 'sparsity_distribution': 'erk', 'erk_power_scale': 1.0, 'use_t_end': True, 'static_ablation': True, 'dynamic_ablation': False, 'filter_ablation_threshold': 0.01, 'use_sparse_initialization': False}, 'training': {'dry_run': False, 'batch_size': 128, 'simulated_batch_size': None, 'test_batch_size': 1000, 'epochs': 250, 'seed': 42, 'log_interval': 1000, 'save_model': True, 'max_steps': 512000, 'optimizer': 'sgd', 'weight_decay': 0.0005, 'momentum': 0.9, 'label_smoothing': 0.0, 'scheduler': 'step_lr', 'lr': 0.1, 'init_lr': 1e-06, 'warm_up_steps': 0, 'gamma': 0.1, 'step_size': [30, 60, 90]}, 'compute': {'no_cuda': False, 'cuda_kwargs': {'num_workers': '${ oc.decode:${oc.env:NUM_WORKERS} }', 'pin_memory': True}, 'distributed': False, 'world_size': 2, 'dist_backend': 'nccl'}, 'wandb': {'project': 'condensed-rigl', 'entity': 'condensed-sparsity', 'start_method': 'thread', 'log_images': False}}"
                  ]
               },
               "execution_count": 39,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "from rigl_torch.datasets import get_dataloaders\n",
            "from omegaconf import DictConfig\n",
            "from rigl_torch.models import ModelFactory\n",
            "import hydra\n",
            "\n",
            "with hydra.initialize(config_path=\"../configs\"):\n",
            "    cfg = hydra.compose(config_name=\"config.yaml\", overrides=[\"dataset=imagenet\", \"model=resnet50\", \"compute.distributed=False\"])\n",
            "cfg\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 6,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "<torch.utils.data.dataloader.DataLoader at 0x7f940ea8f040>"
                  ]
               },
               "execution_count": 6,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "from rigl_torch.datasets import get_dataloaders\n",
            "\n",
            "train,val = get_dataloaders(cfg)\n",
            "train"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 7,
         "metadata": {},
         "outputs": [],
         "source": [
            "for x,y in train:\n",
            "    break"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 8,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "tensor([250, 672, 918, 244, 528, 185, 705, 225, 101, 334, 874, 101, 125, 435,\n",
                     "        521, 277, 443, 956, 611, 971, 332, 796, 868,  34, 300, 998, 247,  39,\n",
                     "          5, 347, 710, 942,  93, 628, 321, 867, 785, 866, 141, 492, 200, 157,\n",
                     "        417, 172,   3, 559, 734, 952, 186, 491, 879, 858,  20,  23,  66,  19,\n",
                     "        462, 930, 189, 326, 849, 994, 214, 432])"
                  ]
               },
               "execution_count": 8,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "y"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "torch.Size([64])"
                  ]
               },
               "execution_count": 43,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "y.shape"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 44,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "torch.Size([64, 5])"
                  ]
               },
               "execution_count": 44,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "indx.shape"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 16,
         "metadata": {},
         "outputs": [],
         "source": [
            "top_5_acc = torch.isin(y,indx)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 30,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "tensor(101)"
                  ]
               },
               "execution_count": 30,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "y[8]"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 31,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "tensor(True)"
                  ]
               },
               "execution_count": 31,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "(indx==101).any()"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 17,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "tensor(14)"
                  ]
               },
               "execution_count": 17,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "top_5_acc.sum()"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 21,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "torch.Size([64, 5])"
                  ]
               },
               "execution_count": 21,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "indx.shape"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 27,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "tensor([False, False, False, False, False, False, False, False,  True, False,\n",
                     "        False,  True, False, False, False, False,  True, False, False, False,\n",
                     "        False,  True,  True, False, False, False, False, False, False, False,\n",
                     "         True, False, False, False, False, False,  True,  True, False, False,\n",
                     "        False, False, False, False, False, False, False, False, False, False,\n",
                     "        False, False, False, False,  True,  True, False, False, False,  True,\n",
                     "        False,  True,  True,  True])"
                  ]
               },
               "execution_count": 27,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "top_5_acc"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 25,
         "metadata": {},
         "outputs": [],
         "source": [
            "for idx, (ii, t) in enumerate(list(zip(indx, y))):\n",
            "    for i in ii:\n",
            "        if i == t:\n",
            "            print(idx)\n",
            "            break"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 34,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "tensor(250)"
                  ]
               },
               "execution_count": 34,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "y[0]"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 40,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "tensor([250, 668, 975, 555, 765])"
                  ]
               },
               "execution_count": 40,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "indx[0]"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 55,
         "metadata": {},
         "outputs": [
            {
               "ename": "RuntimeError",
               "evalue": "shape '[64, 5]' is invalid for input of size 64",
               "output_type": "error",
               "traceback": [
                  "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                  "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
                  "Cell \u001b[0;32mIn [55], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m y\u001b[39m.\u001b[39;49mview_as(indx)\n",
                  "\u001b[0;31mRuntimeError\u001b[0m: shape '[64, 5]' is invalid for input of size 64"
               ]
            }
         ],
         "source": [
            "y.view_as(indx)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 60,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "tensor(1)"
                  ]
               },
               "execution_count": 60,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "(y.reshape(-1,1).expand_as(indx) == indx).any(dim=1)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 5,
         "metadata": {},
         "outputs": [],
         "source": [
            "from rigl_torch.utils.checkpoint import Checkpoint\n",
            "\n",
            "ckp = Checkpoint.load_last_checkpoint(run_id=\"xhnqnd6c\")"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 8,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "dict_keys(['dense_allocation', 'S', 'N', 'hyperparams', 'step', 'rigl_steps', 'backward_masks', '_linear_layers_mask'])"
                  ]
               },
               "execution_count": 8,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "ckp.pruner.keys()"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 71,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "torch.Size([64, 3, 7, 7])"
                  ]
               },
               "execution_count": 71,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "masks = ckp.pruner[\"backward_masks\"]\n",
            "masks[0].shape"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 79,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "54"
                  ]
               },
               "execution_count": 79,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "len(ckp.pruner[\"S\"])"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 78,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "54"
                  ]
               },
               "execution_count": 78,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "len(ckp.pruner[\"backward_masks\"])"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 80,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "[0.9580298609954484,\n",
                     " 0.8452836889704899,\n",
                     " 0.9822803541214066,\n",
                     " 0.9041948997086495,\n",
                     " 0.9041948997086495,\n",
                     " 0.9041948997086495,\n",
                     " 0.9822803541214066,\n",
                     " 0.9041948997086495,\n",
                     " 0.9041948997086495,\n",
                     " 0.9822803541214066,\n",
                     " 0.9041948997086495,\n",
                     " 0.9425764460986625,\n",
                     " 0.9913385313056129,\n",
                     " 0.9522462155380069,\n",
                     " 0.9713626058911724,\n",
                     " 0.9522462155380069,\n",
                     " 0.9913385313056129,\n",
                     " 0.9522462155380069,\n",
                     " 0.9522462155380069,\n",
                     " 0.9913385313056129,\n",
                     " 0.9522462155380069,\n",
                     " 0.9522462155380069,\n",
                     " 0.9913385313056129,\n",
                     " 0.9522462155380069,\n",
                     " 0.9713626058911724,\n",
                     " 0.9957188542140338,\n",
                     " 0.9761602991899241,\n",
                     " 0.9856998986560465,\n",
                     " 0.9761602991899241,\n",
                     " 0.9957188542140338,\n",
                     " 0.9761602991899241,\n",
                     " 0.9761602991899241,\n",
                     " 0.9957188542140338,\n",
                     " 0.9761602991899241,\n",
                     " 0.9761602991899241,\n",
                     " 0.9957188542140338,\n",
                     " 0.9761602991899241,\n",
                     " 0.9761602991899241,\n",
                     " 0.9957188542140338,\n",
                     " 0.9761602991899241,\n",
                     " 0.9761602991899241,\n",
                     " 0.9957188542140338,\n",
                     " 0.9761602991899241,\n",
                     " 0.9856998986560465,\n",
                     " 0.9978718242473238,\n",
                     " 0.9880894474501921,\n",
                     " 0.9928545982556383,\n",
                     " 0.9880894474501921,\n",
                     " 0.9978718242473238,\n",
                     " 0.9880894474501921,\n",
                     " 0.9880894474501921,\n",
                     " 0.9978718242473238,\n",
                     " 0.9880894474501921,\n",
                     " 0.9927449951381855]"
                  ]
               },
               "execution_count": 80,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "ckp.pruner[\"S\"]"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 72,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "<class 'torch.Tensor'>\n",
                  "<class 'torch.Tensor'>\n",
                  "<class 'torch.Tensor'>\n",
                  "<class 'torch.Tensor'>\n",
                  "<class 'torch.Tensor'>\n",
                  "<class 'torch.Tensor'>\n",
                  "<class 'torch.Tensor'>\n",
                  "<class 'torch.Tensor'>\n",
                  "<class 'torch.Tensor'>\n",
                  "<class 'torch.Tensor'>\n",
                  "<class 'torch.Tensor'>\n",
                  "<class 'torch.Tensor'>\n",
                  "<class 'torch.Tensor'>\n",
                  "<class 'torch.Tensor'>\n",
                  "<class 'torch.Tensor'>\n",
                  "<class 'torch.Tensor'>\n",
                  "<class 'torch.Tensor'>\n",
                  "<class 'torch.Tensor'>\n",
                  "<class 'torch.Tensor'>\n",
                  "<class 'torch.Tensor'>\n",
                  "<class 'torch.Tensor'>\n",
                  "<class 'torch.Tensor'>\n",
                  "<class 'torch.Tensor'>\n",
                  "<class 'torch.Tensor'>\n",
                  "<class 'torch.Tensor'>\n",
                  "<class 'torch.Tensor'>\n",
                  "<class 'torch.Tensor'>\n",
                  "<class 'torch.Tensor'>\n",
                  "<class 'torch.Tensor'>\n",
                  "<class 'torch.Tensor'>\n",
                  "<class 'torch.Tensor'>\n",
                  "<class 'torch.Tensor'>\n",
                  "<class 'torch.Tensor'>\n",
                  "<class 'torch.Tensor'>\n",
                  "<class 'torch.Tensor'>\n",
                  "<class 'torch.Tensor'>\n",
                  "<class 'torch.Tensor'>\n",
                  "<class 'torch.Tensor'>\n",
                  "<class 'torch.Tensor'>\n",
                  "<class 'torch.Tensor'>\n",
                  "<class 'torch.Tensor'>\n",
                  "<class 'torch.Tensor'>\n",
                  "<class 'torch.Tensor'>\n",
                  "<class 'torch.Tensor'>\n",
                  "<class 'torch.Tensor'>\n",
                  "<class 'torch.Tensor'>\n",
                  "<class 'torch.Tensor'>\n",
                  "<class 'torch.Tensor'>\n",
                  "<class 'torch.Tensor'>\n",
                  "<class 'torch.Tensor'>\n",
                  "<class 'torch.Tensor'>\n",
                  "<class 'torch.Tensor'>\n",
                  "<class 'torch.Tensor'>\n",
                  "<class 'torch.Tensor'>\n"
               ]
            }
         ],
         "source": [
            "for m in masks:\n",
            "    print(type(m))"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 41,
         "metadata": {},
         "outputs": [],
         "source": [
            "import torch\n",
            "rs_masks=[]\n",
            "for m in masks:\n",
            "    # rs_masks.append(torch.zeros(size=m.shape,dtype=torch.bool))\n",
            "    rs_masks.append(m)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 66,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "tensor(25247830)"
                  ]
               },
               "execution_count": 66,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "# torch.sum(torch.tensor([torch.sum(ep) for ep in explored_params]))"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 67,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "6"
                  ]
               },
               "execution_count": 67,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "sum([1,2,3])"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 63,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "tensor(0.1713, device='cuda:0')"
                  ]
               },
               "execution_count": 63,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "\n",
            "import math\n",
            "backward_masks = masks\n",
            "explored_params = [~b for b in backward_masks]\n",
            "\n",
            "itop_rs = math.sum([ep.sum]\n",
            "itop_rs = math.prod(\n",
            "    [\n",
            "        ep.sum() / ep.numel()``\n",
            "        for ep in explored_params\n",
            "    ]\n",
            ")\n",
            "itop_rs"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 43,
         "metadata": {},
         "outputs": [],
         "source": [
            "for idx, (rs, m) in enumerate(list(zip(rs_masks, masks))):\n",
            "    break\n",
            "    rs_masks[0] = rs((m==False))"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 55,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "tensor([True, True, True])"
                  ]
               },
               "execution_count": 55,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "t1 = torch.tensor([0,1,1],dtype=torch.bool)\n",
            "t2 = torch.tensor([1,1,0],dtype=torch.bool)\n",
            "t1+=t2\n",
            "t1"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 50,
         "metadata": {},
         "outputs": [
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  "/tmp/ipykernel_14266/3909545341.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
                  "  torch.tensor(data=(m+~m)).all()\n"
               ]
            },
            {
               "data": {
                  "text/plain": [
                     "tensor(True, device='cuda:0')"
                  ]
               },
               "execution_count": 50,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "torch.tensor(data=(m+~m)).all()"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 70,
         "metadata": {},
         "outputs": [],
         "source": [
            "for m in masks:\n",
            "    if m is None:\n",
            "        print(\"found none\")"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 3,
         "metadata": {},
         "outputs": [],
         "source": [
            " = import numpy as np\n",
            "step = 0\n",
            "alpha = 0.3\n",
            "T_end=256000\n",
            "\n",
            "ps=[]\n",
            "for step in range(T_end):\n",
            "    ps.append(alpha / 2 * (1 + np.cos((step * np.pi) / T_end)))"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 4,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "[<matplotlib.lines.Line2D at 0x7f3524802430>]"
                  ]
               },
               "execution_count": 4,
               "metadata": {},
               "output_type": "execute_result"
            },
            {
               "data": {
                  "image/png": "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",
                  "text/plain": [
                     "<Figure size 432x288 with 1 Axes>"
                  ]
               },
               "metadata": {
                  "needs_background": "light"
               },
               "output_type": "display_data"
            }
         ],
         "source": [
            "import matplotlib.pyplot as plt\n",
            "\n",
            "plt.plot(ps)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 26,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "[<matplotlib.lines.Line2D at 0x7f8ae530a970>]"
                  ]
               },
               "execution_count": 26,
               "metadata": {},
               "output_type": "execute_result"
            },
            {
               "data": {
                  "image/png": "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",
                  "text/plain": [
                     "<Figure size 432x288 with 1 Axes>"
                  ]
               },
               "metadata": {
                  "needs_background": "light"
               },
               "output_type": "display_data"
            }
         ],
         "source": [
            "from dataclasses import dataclass\n",
            "import torch``\n",
            "\n",
            "@dataclass(init=True)\n",
            "class Flags():\n",
            "    base_learning_rate: float\n",
            "    train_batch_size:int\n",
            "\n",
            "global FLAGS\n",
            "FLAGS = Flags(base_learning_rate=0.1, train_batch_size=512)\n",
            "\n",
            "global LR_SCHEDULE\n",
            "LR_SCHEDULE = [(1.0, 0), (0.1, 30), (0.01, 70), (0.001, 90), (.0001, 120)]\n",
            "\n",
            "def lr_schedule(current_epoch):\n",
            "    \"\"\"Computes learning rate schedule.\"\"\"\n",
            "    scaled_lr = FLAGS.base_learning_rate * (FLAGS.train_batch_size / 256.0)\n",
            "    decay_rate = (\n",
            "            scaled_lr * LR_SCHEDULE[0][0] * current_epoch / LR_SCHEDULE[0][1]\n",
            "        ) \n",
            "    # print(decay_rate)\n",
            "    for mult, start_epoch in LR_SCHEDULE:\n",
            "        decay_rate = torch.where(current_epoch < start_epoch, decay_rate, scaled_lr * mult)\n",
            "    return decay_rate\n",
            "\n",
            "\n",
            "epochs = torch.arange(1,101)\n",
            "lrs = []\n",
            "\n",
            "for e in epochs:\n",
            "    lrs.append(lr_schedule(e).item())\n",
            "\n",
            "import matplotlib.pyplot as plt\n",
            "plt.plot(lrs)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": []
      },
      {
         "cell_type": "code",
         "execution_count": 25,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "tensor([inf])\n",
                  "tensor([1.6000])\n"
               ]
            }
         ],
         "source": [
            "current_epoch=torch.tensor([1], dtype=torch.int8)\n",
            "scaled_lr = FLAGS.base_learning_rate * (FLAGS.train_batch_size / 256.0)\n",
            "decay_rate = (\n",
            "        scaled_lr * LR_SCHEDULE[0][0] * current_epoch / LR_SCHEDULE[0][1]\n",
            "    ) \n",
            "print(decay_rate)\n",
            "for mult, start_epoch in LR_SCHEDULE:\n",
            "        decay_rate = torch.where(current_epoch < start_epoch, decay_rate, scaled_lr * mult)\n",
            "print(decay_rate)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 18,
         "metadata": {},
         "outputs": [],
         "source": [
            "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts, CosineAnnealingLR, _LRScheduler\n",
            "from torch.optim import AdamW\n",
            "import math\n",
            "from rigl_torch.datasets import get_dataloaders\n",
            "from rigl_torch.optim import StepLrWithLinearWarmUp\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 1,
         "metadata": {},
         "outputs": [
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  "INFO:/home/condensed-sparsity/src/rigl_torch/models/model_factory.py:Registering mnist for mnist dataset to ModelFactory...\n",
                  "INFO:/home/condensed-sparsity/src/rigl_torch/models/model_factory.py:Registering resnet18 for cifar10 dataset to ModelFactory...\n",
                  "INFO:/home/condensed-sparsity/src/rigl_torch/models/model_factory.py:Registering wide_resnet22 for cifar10 dataset to ModelFactory...\n",
                  "INFO:/home/condensed-sparsity/src/rigl_torch/models/model_factory.py:Registering cond_net for mnist dataset to ModelFactory...\n",
                  "INFO:/home/condensed-sparsity/src/rigl_torch/models/model_factory.py:Registering wide_resnet22 for imagenet dataset to ModelFactory...\n",
                  "INFO:/home/condensed-sparsity/src/rigl_torch/models/model_factory.py:Registering resnet18 for imagenet dataset to ModelFactory...\n",
                  "INFO:/home/condensed-sparsity/src/rigl_torch/models/model_factory.py:Registering resnet50 for imagenet dataset to ModelFactory...\n",
                  "/tmp/ipykernel_153204/82332062.py:6: UserWarning: \n",
                  "The version_base parameter is not specified.\n",
                  "Please specify a compatability version level, or None.\n",
                  "Will assume defaults for version 1.1\n",
                  "  with hydra.initialize(config_path=\"../configs\"):\n",
                  "INFO:/home/condensed-sparsity/src/rigl_torch/models/model_factory.py:Loading model wide_resnet22/cifar10 using <function get_wide_resnet_22 at 0x7f699b4e5040> with args: () and kwargs: {}\n"
               ]
            }
         ],
         "source": [
            "from rigl_torch.datasets import get_dataloaders\n",
            "from omegaconf import DictConfig\n",
            "from rigl_torch.models import ModelFactory\n",
            "import hydra\n",
            "\n",
            "with hydra.initialize(config_path=\"../configs\"):\n",
            "    cfg = hydra.compose(config_name=\"config.yaml\", overrides=[\"dataset=cifar10\", \"model=wide_resnet22\", \"compute.distributed=False\"])\n",
            "cfg\n",
            "\n",
            "net = ModelFactory.load_model(\"wide_resnet22\", \"cifar10\")"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 4,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Files already downloaded and verified\n"
               ]
            }
         ],
         "source": [
            "import torchvision\n",
            "cifar = torchvision.datasets.CIFAR10(root=\"../data/\", download=True)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 21,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "50000"
                  ]
               },
               "execution_count": 21,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "len(cifar)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 22,
         "metadata": {},
         "outputs": [
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  "Traceback (most recent call last):\n",
                  "  File \"<string>\", line 1, in <module>\n",
                  "  File \"/opt/conda/lib/python3.8/multiprocessing/spawn.py\", line 116, in spawn_main\n",
                  "    exitcode = _main(fd, parent_sentinel)\n",
                  "  File \"/opt/conda/lib/python3.8/multiprocessing/spawn.py\", line 126, in _main\n",
                  "    self = reduction.pickle.load(from_parent)\n",
                  "AttributeError: Can't get attribute 'main' on <module '__main__' (built-in)>\n",
                  "Traceback (most recent call last):\n",
                  "  File \"<string>\", line 1, in <module>\n",
                  "  File \"/opt/conda/lib/python3.8/multiprocessing/spawn.py\", line 116, in spawn_main\n",
                  "    exitcode = _main(fd, parent_sentinel)\n",
                  "  File \"/opt/conda/lib/python3.8/multiprocessing/spawn.py\", line 126, in _main\n",
                  "    self = reduction.pickle.load(from_parent)\n",
                  "AttributeError: Can't get attribute 'main' on <module '__main__' (built-in)>\n"
               ]
            },
            {
               "ename": "KeyboardInterrupt",
               "evalue": "",
               "output_type": "error",
               "traceback": [
                  "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                  "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
                  "Cell \u001b[0;32mIn [22], line 24\u001b[0m\n\u001b[1;32m     13\u001b[0m     train_loader \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataLoader(\n\u001b[1;32m     14\u001b[0m         cifar,\n\u001b[1;32m     15\u001b[0m         sampler\u001b[38;5;241m=\u001b[39mtrain_sampler,\n\u001b[1;32m     16\u001b[0m         batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m128\u001b[39m,\n\u001b[1;32m     17\u001b[0m         shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     18\u001b[0m     )\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNum samples in rank \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrank\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(train_loader)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m256\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m) \n\u001b[0;32m---> 24\u001b[0m \u001b[43mmp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mspawn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnprocs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m)\u001b[49m\n",
                  "File \u001b[0;32m~/build/.venv/lib/python3.8/site-packages/torch/multiprocessing/spawn.py:240\u001b[0m, in \u001b[0;36mspawn\u001b[0;34m(fn, args, nprocs, join, daemon, start_method)\u001b[0m\n\u001b[1;32m    236\u001b[0m     msg \u001b[39m=\u001b[39m (\u001b[39m'\u001b[39m\u001b[39mThis method only supports start_method=spawn (got: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m).\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m'\u001b[39m\n\u001b[1;32m    237\u001b[0m            \u001b[39m'\u001b[39m\u001b[39mTo use a different start_method use:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\t\u001b[39;00m\u001b[39m\\t\u001b[39;00m\u001b[39m'\u001b[39m\n\u001b[1;32m    238\u001b[0m            \u001b[39m'\u001b[39m\u001b[39m torch.multiprocessing.start_processes(...)\u001b[39m\u001b[39m'\u001b[39m \u001b[39m%\u001b[39m start_method)\n\u001b[1;32m    239\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(msg)\n\u001b[0;32m--> 240\u001b[0m \u001b[39mreturn\u001b[39;00m start_processes(fn, args, nprocs, join, daemon, start_method\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mspawn\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
                  "File \u001b[0;32m~/build/.venv/lib/python3.8/site-packages/torch/multiprocessing/spawn.py:198\u001b[0m, in \u001b[0;36mstart_processes\u001b[0;34m(fn, args, nprocs, join, daemon, start_method)\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[39mreturn\u001b[39;00m context\n\u001b[1;32m    197\u001b[0m \u001b[39m# Loop on join until it returns True or raises an exception.\u001b[39;00m\n\u001b[0;32m--> 198\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mnot\u001b[39;00m context\u001b[39m.\u001b[39;49mjoin():\n\u001b[1;32m    199\u001b[0m     \u001b[39mpass\u001b[39;00m\n",
                  "File \u001b[0;32m~/build/.venv/lib/python3.8/site-packages/torch/multiprocessing/spawn.py:109\u001b[0m, in \u001b[0;36mProcessContext.join\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    106\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    108\u001b[0m \u001b[39m# Wait for any process to fail or all of them to succeed.\u001b[39;00m\n\u001b[0;32m--> 109\u001b[0m ready \u001b[39m=\u001b[39m multiprocessing\u001b[39m.\u001b[39;49mconnection\u001b[39m.\u001b[39;49mwait(\n\u001b[1;32m    110\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msentinels\u001b[39m.\u001b[39;49mkeys(),\n\u001b[1;32m    111\u001b[0m     timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[1;32m    112\u001b[0m )\n\u001b[1;32m    114\u001b[0m error_index \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    115\u001b[0m \u001b[39mfor\u001b[39;00m sentinel \u001b[39min\u001b[39;00m ready:\n",
                  "File \u001b[0;32m/opt/conda/lib/python3.8/multiprocessing/connection.py:931\u001b[0m, in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    928\u001b[0m     deadline \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mmonotonic() \u001b[39m+\u001b[39m timeout\n\u001b[1;32m    930\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 931\u001b[0m     ready \u001b[39m=\u001b[39m selector\u001b[39m.\u001b[39;49mselect(timeout)\n\u001b[1;32m    932\u001b[0m     \u001b[39mif\u001b[39;00m ready:\n\u001b[1;32m    933\u001b[0m         \u001b[39mreturn\u001b[39;00m [key\u001b[39m.\u001b[39mfileobj \u001b[39mfor\u001b[39;00m (key, events) \u001b[39min\u001b[39;00m ready]\n",
                  "File \u001b[0;32m/opt/conda/lib/python3.8/selectors.py:415\u001b[0m, in \u001b[0;36m_PollLikeSelector.select\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    413\u001b[0m ready \u001b[39m=\u001b[39m []\n\u001b[1;32m    414\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 415\u001b[0m     fd_event_list \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_selector\u001b[39m.\u001b[39;49mpoll(timeout)\n\u001b[1;32m    416\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mInterruptedError\u001b[39;00m:\n\u001b[1;32m    417\u001b[0m     \u001b[39mreturn\u001b[39;00m ready\n",
                  "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
               ]
            }
         ],
         "source": [
            "import torch\n",
            "import torch.nn.functional as F\n",
            "import torch.multiprocessing as mp\n",
            "import torch.distributed as dist\n",
            "from torch.nn.parallel import DistributedDataParallel\n",
            "\n",
            "def main(rank, cfg):\n",
            "    cifar = torchvision.datasets.CIFAR10(root=\"../data/\", download=True)\n",
            "    device = torch.device(f\"cuda:{rank}\")\n",
            "    train_sampler = torch.utils.data.distributed.DistributedSampler(\n",
            "        cifar, drop_last=True\n",
            "    )\n",
            "    train_loader = torch.utils.data.DataLoader(\n",
            "        cifar,\n",
            "        sampler=train_sampler,\n",
            "        batch_size=128,\n",
            "        shuffle=True,\n",
            "    )\n",
            "    print(f\"Num samples in rank {rank}: {len(train_loader)*256}\") \n",
            "\n",
            "    \n",
            "\n",
            "\n",
            "mp.spawn(\n",
            "    main,\n",
            "    args=(cfg,),\n",
            "    nprocs=2,\n",
            ")"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 5,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Files already downloaded and verified\n"
               ]
            }
         ],
         "source": [
            "train, test = get_dataloaders(cfg)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 6,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "32"
                  ]
               },
               "execution_count": 6,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "cfg.training.batch_size"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 7,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "1562"
                  ]
               },
               "execution_count": 7,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "len(train)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 8,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "50000"
                  ]
               },
               "execution_count": 8,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "len(train.dataset)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 9,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "1562.5"
                  ]
               },
               "execution_count": 9,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "len(train.dataset) / cfg.training.batch_size"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 10,
         "metadata": {},
         "outputs": [],
         "source": [
            "for imgs,labels in train:\n",
            "    break"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 2,
         "metadata": {},
         "outputs": [],
         "source": [
            "import torch\n",
            "from rigl_torch.optim import get_lr_scheduler, get_optimizer\n",
            "optim = get_optimizer(cfg, net, None)\n",
            "lr_scheduler = get_lr_scheduler(cfg, optim, None)\n",
            "\n",
            "\n",
            "\n",
            "# adamw1 = AdamW(net.parameters(), lr=0.001)\n",
            "# adamw2 = AdamW(net.parameters(), lr=0.001)\n",
            "# linear_step = torch.optim.lr_scheduler.StepLR(adamw2, step_size=30000, gamma=0.2)\n",
            "# cawr = CosineAnnealingWarmRestarts(optimizer=adamw1, T_0=20, T_mult=2)\n",
            "# ca = CosineAnnealingLR(optimizer=adamw2, T_max=T_max)\n",
            "# adamw3 = AdamW(net.parameters(), lr=0.001)\n",
            "# test= CosineAnnealingWithLinearWarmUp(optimizer=adamw3, T_max=T_max, warm_up_steps=50, lr=0.001)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 12,
         "metadata": {},
         "outputs": [],
         "source": [
            "# lr_scheduler.get_last_lr()"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 13,
         "metadata": {},
         "outputs": [],
         "source": [
            "# lr_scheduler.step_size"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 3,
         "metadata": {},
         "outputs": [
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  "/home/user/build/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:131: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
                  "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n",
                  "INFO:/home/condensed-sparsity/src/rigl_torch/optim/step_lr_with_linear_warm_up.py:Reducing LR to 0.020000000000000004 @ epoch 30\n",
                  "INFO:/home/condensed-sparsity/src/rigl_torch/optim/step_lr_with_linear_warm_up.py:Reducing LR to 0.0020000000000000005 @ epoch 70\n",
                  "INFO:/home/condensed-sparsity/src/rigl_torch/optim/step_lr_with_linear_warm_up.py:Reducing LR to 0.00020000000000000006 @ epoch 90\n"
               ]
            }
         ],
         "source": [
            "%matplotlib inline\n",
            "lrs=[]\n",
            "step_lrs=[]\n",
            "# from torch.optim.lr_scheduler import StepLR\n",
            "# step_scheduler = StepLR(optim, step_size=30, gamma=0.1)\n",
            "for epoch in range(0,100):\n",
            "    # lr = [group[\"lr\"] for group in optim.param_groups][0]\n",
            "    lr=lr_scheduler.get_last_lr()[0]\n",
            "    lrs.append(lr)\n",
            "    lr_scheduler.step()\n",
            "    # lr = [group[\"lr\"] for group in optim.param_groups][0]\n",
            "    # step_lrs.append(lr)\n",
            "    # step_scheduler.step()\n",
            "\n",
            "# for x in range(T_max):\n",
            "#     lr1 = cawr.get_last_lr()\n",
            "#     warm_restart_lrs.append(lr1)\n",
            "#     cawr.step()\n",
            "#     lr2 = linear_step.get_last_lr()\n",
            "#     linear_step_lrs.append(lr2)\n",
            "#     linear_step.step()\n",
            "    # combined.append(lr1[0] * lr2[0]*1000)\n",
            "    # lr3 = test.get_last_lr()\n",
            "    # linear_warmup.append(lr3)\n",
            "    # test.step()"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 5,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "[1e-06, 0.050000750000000004, 0.1000005, 0.15000025, 0.2, 0.2]"
                  ]
               },
               "execution_count": 5,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "lrs[0:6]"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 4,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "[<matplotlib.lines.Line2D at 0x7f69998ce9a0>]"
                  ]
               },
               "execution_count": 4,
               "metadata": {},
               "output_type": "execute_result"
            },
            {
               "data": {
                  "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD4CAYAAADlwTGnAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAAfwklEQVR4nO3df5DcdZ3n8eeruycJPxJ+joBJMHGJeFFXXIeItSu7C+oG9QhVBxoKBbcouS2ldve83VsoS7zLYtVye7Wc1lEeWUF+rAhs1GVK4+ZQcO/XghmQIwSMDIEliSgjvybATDI9874/+tNJ00yYnulvT893vq9HVVe6P98f8/na+H3358f3/VFEYGZmxVPqdgXMzKw7HADMzArKAcDMrKAcAMzMCsoBwMysoCrdrsB0HH/88bFixYpuV8PMLFceeOCBX0dEb3N5rgLAihUrGBgY6HY1zMxyRdK/TFbuLiAzs4JyADAzKygHADOzgnIAMDMrKAcAM7OCaikASForaYekQUlXTLL985IelfSwpB9JekvDtkskPZ5elzSUv1fStnTOr0pSNpdkZmatmDIASCoD1wHnAKuBCyWtbtrtp0BfRPwmsAn4z+nYY4EvAe8D1gBfknRMOuZrwGeAVem1tu2rMTOzlrXyHMAaYDAidgJIuh1YBzxa3yEi7m3Y/z7gk+n9HwB3R8Tz6di7gbWSfgwsiYj7UvktwHnAD9q5mKw89/I+vnn/01THJ7pdlVw59cQlfPQ3T+p2NcysRa0EgKXArobPu6n9oj+USzl4I5/s2KXptXuS8teRdBlwGcDJJ5/cQnXb9/1tz/A3d/88/f1Z+ZO5FwFHLqw4AJjlSKZPAkv6JNAH/G5W54yIjcBGgL6+vllZvebFV8cAGPzyOVTKHidvxTX/+DNu+N9PdrsaZjYNrdzd9gDLGz4vS2WvIemDwBeAcyNi3xTH7knv3/Cc3TI8MsbhC8q++U9DpSR3mZnlTCt3uK3AKkkrJS0A1gP9jTtIeg9wPbWb/7MNm7YAH5Z0TBr8/TCwJSKeAYYlnZFm/1wM3JXB9WRieHSMJYt6ul2NXCmXxETAxISXGDXLiym7gCKiKulyajfzMnBjRGyXtAEYiIh+4K+BI4G/T7M5n46IcyPieUl/SS2IAGyoDwgDnwVuAg6jNmYwJwaAAYZHqiw5LFd58rquJ7WWqhPBgpIHTszyoKW7XERsBjY3lV3V8P6Db3DsjcCNk5QPAO9suaazyC2A6Sunm/64WwBmueFO7kkMj46x5DAHgOmopABQnfA4gFleOABMYnikypJF7gKajgMBYNwtALO8cACYhFsA01duGAMws3xwAGgSEQyPeAxgunrcBWSWOw4ATV7ZP85E4FlA01R2F5BZ7jgANBkeqT0F7BbA9PS4C8gsdxwAmuwdrQJ4DGCaDk4DdReQWV44ADQZHnULYCZ6yvUxALcAzPLCAaDJgS4gjwFMS7mUuoA8BmCWGw4ATdwCmJmDD4I5AJjlhQNAk+GR2hjAYj8INi2VeheQM4Ka5YYDQJN6F9BitwCmpewWgFnuOAA0GR4d47CeMgsq/p9mOg5MA/UYgFlu+C7XxKmgZ6bsJ4HNcscBoIlTQc9MT5oF5HTQZvnhANDEieBmpt4CGHMXkFlutBQAJK2VtEPSoKQrJtl+pqQHJVUlnd9Q/vuSHmp4jUo6L227SdKTDdtOy+qi2uFU0DNTnwXkFoBZfkx5p5NUBq4DPgTsBrZK6o+IRxt2exr4NPBnjcdGxL3Aaek8xwKDwP9o2OXPI2JTG/XP3PDoGG/tPaLb1cgdLwhjlj+t/NRdAwxGxE4ASbcD64ADASAinkrb3uj//ecDP4iIV2dc21ngVNAzU/GTwGa500oX0FJgV8Pn3alsutYD32oq+7KkhyVdK2nhZAdJukzSgKSBoaGhGfzZ1kUEe0c9C2gmDjwI5haAWW7MyiCwpJOAdwFbGoqvBN4OnA4cC/zFZMdGxMaI6IuIvt7e3o7Wc2RsnOpEuAUwA04FYZY/rQSAPcDyhs/LUtl0fBz4bkSM1Qsi4pmo2Qd8g1pXU1fV00B4FtD0HUwH7QBglhetBICtwCpJKyUtoNaV0z/Nv3MhTd0/qVWAJAHnAY9M85yZcyK4maukJ4E9DdQsP6YMABFRBS6n1n3zGHBnRGyXtEHSuQCSTpe0G7gAuF7S9vrxklZQa0H8U9OpvylpG7ANOB64OoPraYtTQc9cxQvCmOVOS3e6iNgMbG4qu6rh/VZqXUOTHfsUkwwaR8RZ06nobHALYObqg8BuAZjlh58EbuBU0DNXcSoIs9xxAGhwoAXgQeBpK5eE5PUAzPLEAaDBwbUA3AKYiUpJngZqliMOAA2GR6ss6imxsFLudlVyqVySu4DMcsQBoIHTQLSnp1TyILBZjjgANHAq6PaUy/I0ULMccQBo4FTQ7amUSoy5C8gsNxwAGrgF0J5KSYy7C8gsNxwAGuwdrXoMoA1lzwIyyxUHgAbDI2NOA9GGnrKcDtosRxwAkojwgvBtcgvALF8cAJLRsQnGxsNjAG3oKZf8JLBZjjgAJE4E1z4/CGaWLw4AiVNBt69S9oNgZnniAJDUWwCL3QKYsYpbAGa54gCQHFgO0g+CzVhtENhjAGZ50VIAkLRW0g5Jg5KumGT7mZIelFSVdH7TtnFJD6VXf0P5Skn3p3PekZab7Bqngm5fT1lU3QVklhtTBgBJZeA64BxgNXChpNVNuz0NfBq4bZJTjETEael1bkP5NcC1EXEK8AJw6Qzqn5kDYwDuApqxcqnkaaBmOdJKC2ANMBgROyNiP3A7sK5xh4h4KiIeBlpq/6eF4M8CNqWim6ktDN81w6NeDaxdPe4CMsuVVgLAUmBXw+fdTLLG7xtYJGlA0n2SzktlxwEvpgXn3/Ccki5Lxw8MDQ1N489Oz/DIGAsrJRb1eC2AmSqX3AVkliez8XP3LRGxR9JbgXskbQNeavXgiNgIbATo6+vr2N3FieDa11N2F5BZnrTSAtgDLG/4vCyVtSQi9qR/dwI/Bt4DPAccLakegKZ1zk4YHnUq6Hb5QTCzfGklAGwFVqVZOwuA9UD/FMcAIOkYSQvT++OB3wYejYgA7gXqM4YuAe6abuWzVEsE5xZAOyoeAzDLlSkDQOqnvxzYAjwG3BkR2yVtkHQugKTTJe0GLgCul7Q9Hf6vgAFJ/4/aDf+vIuLRtO0vgM9LGqQ2JnBDlhc2XcNOBd22iqeBmuVKS30eEbEZ2NxUdlXD+63UunGaj/u/wLsOcc6d1GYYzQl7R8Y4+djDu12NXPM0ULN88ZPASS0VtMcA2lF7EMxdQGZ54QBAWgtgpOoxgDZ5PQCzfHEAAPZVJ9g/PuGHwNpU8XMAZrniAIDTQGSlUi55GqhZjjgA4ERwWfE0ULN8cQAAXnIq6ExUSiUmAibcCjDLBQcA3ALISqUsAA8Em+WEAwAeA8hKpVQPAO4GMssDBwAOpoL2esDtKZfcAjDLEwcAYO+oWwBZONAC8FRQs1xwAKC2HvACrwXQtkq59p+Tu4DM8sEBgHoaCP/6b1e9BeBnAczywQGAeipo9/+360ALwF1AZrngAIBTQWel4kFgs1xxAMCLwWTlwCwgZwQ1y4WWAoCktZJ2SBqUdMUk28+U9KCkqqTzG8pPk/TPkrZLeljSJxq23STpSUkPpddpmVzRDDgVdDZ6/CCYWa5MedeTVAauAz4E7Aa2SupvWNkL4Gng08CfNR3+KnBxRDwu6c3AA5K2RMSLafufR8SmNq+hbcMjVRa7C6ht5ZLHAMzypJWfvWuAwbSCF5JuB9YBBwJARDyVtr2m7R8RP294/wtJzwK9wIvtVjxLw6MeBM7CwVQQ7gIyy4NWuoCWArsaPu9OZdMiaQ2wAHiiofjLqWvo2vri8ZMcd5mkAUkDQ0ND0/2zUxodG2d/dcKDwBnwNFCzfJmVQWBJJwG3An8YEfWfh1cCbwdOB46ltkj860TExojoi4i+3t7ezOvmRHDZqaQuoDF3AZnlQisBYA+wvOHzslTWEklLgO8DX4iI++rlEfFM1OwDvkGXFogfdirozNS7gNwCMMuHVgLAVmCVpJWSFgDrgf5WTp72/y5wS/Ngb2oVIEnAecAj06h3ZtwCyE59GuiYxwDMcmHKABARVeByYAvwGHBnRGyXtEHSuQCSTpe0G7gAuF7S9nT4x4EzgU9PMt3zm5K2AduA44Grs7ywVjkVdHZ6UhfQuLuAzHKhpX6PiNgMbG4qu6rh/VZqXUPNx/0d8HeHOOdZ06pph+xNqaCP8iygtjkdtFm+FP5J4GGngs5Mj6eBmuWKA0B9ENhjAG0rexqoWa44AIyOsaBcYmGl8P9TtK2n7GmgZnlS+LtePRV0bTKSteNgC8BdQGZ54ADgVNCZqT8J7BaAWT44AIyMsdgPgWWiviCMxwDM8sEBYNRrAWTF00DN8sUBYMTrAWflwDRQLwhjlgsOAKNVp4LOiFsAZvniAOAWQGYqXhDGLFcKHQBGx8bZV53wGEBGyiUheRqoWV4UOgDU8wA5FXR2KiUx5i4gs1woeABwKuisVUolTwM1y4lCB4DhAy0AB4CsVEryGIBZThQ7ANTXAvAsoMxUynI2ULOcKHYAcCrozJVLJU8DNcuJlgKApLWSdkgalHTFJNvPlPSgpKqk85u2XSLp8fS6pKH8vZK2pXN+VV3IxuZU0NmrdQG5BWCWB1MGAEll4DrgHGA1cKGk1U27PQ18Grit6dhjgS8B76O26PuXJB2TNn8N+AywKr3WzvgqZsgtgOzVuoDcAjDLg1ZaAGuAwYjYGRH7gduBdY07RMRTEfEw0PzT7w+AuyPi+Yh4AbgbWJsWhF8SEfdFRAC3UFsYflYNj4zRUxaLegrdE5YpDwKb5Ucrd76lwK6Gz7tTWSsOdezS9H7Kc0q6TNKApIGhoaEW/2xrhkfHWLyox2sBZKhS9jRQs7yY8z99I2JjRPRFRF9vb2+m5x4eqfohsIxVSp4FZJYXrQSAPcDyhs/LUlkrDnXsnvR+JufMjFNBZ6/sLiCz3GglAGwFVklaKWkBsB7ob/H8W4APSzomDf5+GNgSEc8Aw5LOSLN/LgbumkH92+JEcNmrlD0N1CwvpgwAEVEFLqd2M38MuDMitkvaIOlcAEmnS9oNXABcL2l7OvZ54C+pBZGtwIZUBvBZ4OvAIPAE8INMr6wFTgWdPXcBmeVHS3e/iNgMbG4qu6rh/VZe26XTuN+NwI2TlA8A75xOZbPmFkD2PAvILD/m/CBwJ3kMIHt+DsAsPwobAPZVxxkdm/AsoIxVnArCLDcKGwAOrAXgFkCmKiV5QRiznHAA8BhApjwN1Cw/ChsAnAq6M3o8DdQsN4obAJwIriPKzgZqlhvFDQBOBd0RngVklh/FDQCpBbDYs4Ay5ecAzPKjuAFgxF1AneBUEGb5UdwAMDpGuSQOX1DudlXmFU8DNcuP4gaAlAraawFky9NAzfKjuAHAaSA6wtNAzfKjuAHAieA6ouxsoGa5UdwA4FTQHdFT8jRQs7wobgBwC6AjyqUSEXhdYLMcKG4AGHUA6IRKuTao7m4gs7mvpQAgaa2kHZIGJV0xyfaFku5I2++XtCKVXyTpoYbXhKTT0rYfp3PWt70pywubyvCIu4A6oVKqBQC3AMzmvikDgKQycB1wDrAauFDS6qbdLgVeiIhTgGuBawAi4psRcVpEnAZ8CngyIh5qOO6i+vaIeLbtq2nR/uoEI2PjbgF0QDkFgDFPBTWb81ppAawBBiNiZ0TsB24H1jXtsw64Ob3fBJyt10+wvzAd23V764ngPA00cz3l2n9SbgGYzX2tBIClwK6Gz7tT2aT7pEXkXwKOa9rnE8C3msq+kbp/vjhJwABA0mWSBiQNDA0NtVDdqQ0fWAzGXUBZq7cAnBHUbO6blUFgSe8DXo2IRxqKL4qIdwEfSK9PTXZsRGyMiL6I6Ovt7c2kPvU8QIsXugWQtZ4Dg8BuAZjNda0EgD3A8obPy1LZpPtIqgBHAc81bF9P06//iNiT/t0L3Eatq2lWeDnIzimX3AVklhetBICtwCpJKyUtoHYz72/apx+4JL0/H7gnIgJAUgn4OA39/5Iqko5P73uAjwGPMEsOLAbjLqDMVQ4MArsLyGyum/IOGBFVSZcDW4AycGNEbJe0ARiIiH7gBuBWSYPA89SCRN2ZwK6I2NlQthDYkm7+ZeCHwN9mckUtcCrozqk/B+AWgNnc19JP4IjYDGxuKruq4f0ocMEhjv0xcEZT2SvAe6dZ18wMexZQx1Q8DdQsNwr5JPDwSJWS4AivBZC5iscAzHKjmAEgpYL2WgDZK6cuoDGngjCb84oZAJwIrmOcCsIsP4oZAJwKumPqXUBeFcxs7itmAHALoGOcDdQsP4oZAJwKumPqXUB+Eths7itmAHAq6I5xF5BZfhQzALgF0DEHHwRzF5DZXFe4ADA2PsGr+8f9EFiH+EEws/woXACoJ4JbvMhdQJ1Q9jRQs9woXABwHqDOqi8I40Fgs7mveAHAeYA6ygvCmOVH8QLASFoLwF1AHVHxgjBmuVG8AOAWQEcdnAbqFoDZXFe4AOAF4TvLLQCz/GgpAEhaK2mHpEFJV0yyfaGkO9L2+yWtSOUrJI2khd8fkvTfG455r6Rt6ZivHmpR+Ky5C6iz/CSwWX5MGQAklYHrgHOA1cCFklY37XYp8EJEnAJcC1zTsO2JiDgtvf6oofxrwGeAVem1duaX0brh0bG0FoADQCd4GqhZfrTSAlgDDEbEzojYT21t33VN+6wDbk7vNwFnv9EvekknAUsi4r60dvAtwHnTrfxMDI+MsXhRD6WS1wLohB6ngjDLjVYCwFJgV8Pn3als0n0iogq8BByXtq2U9FNJ/yTpAw37757inABIukzSgKSBoaGhFqr7xoZHq34IrINKJSE5G6hZHnR6EPgZ4OSIeA/weeA2SUumc4KI2BgRfRHR19vb23aFhkfGOMoDwB3VUyp5DMAsB1oJAHuA5Q2fl6WySfeRVAGOAp6LiH0R8RxARDwAPAG8Le2/bIpzdoQTwXVeuSRPAzXLgVYCwFZglaSVkhYA64H+pn36gUvS+/OBeyIiJPWmQWQkvZXaYO/OiHgGGJZ0RhoruBi4K4PrmZJTQXdepSS3AMxyYMo7YURUJV0ObAHKwI0RsV3SBmAgIvqBG4BbJQ0Cz1MLEgBnAhskjQETwB9FxPNp22eBm4DDgB+kV8cNj9YGga1zKmV5ENgsB1r6KRwRm4HNTWVXNbwfBS6Y5LhvA98+xDkHgHdOp7JZ8HKQnVf2GIBZLhTqSeDq+ASv7B93F1CH9ZTlBWHMcqBQAaC+FoBbAJ1VGwR2C8BsritUAHAiuNnRU3YXkFkeFCoAHGwBuAuok8ol+UEwsxwoVAA4sBqYWwAdVXEXkFkuFCsAjHo5yNlQKfs5ALM8KFYAqKeC9iygjvI0ULN8KFYA8CDwrOgpeRqoWR4UKwCMjCHBkV4LoKPKJTHmMQCzOa9YAWC0yuKFFa8F0GGVsrwgjFkOFCsAjIy5+2cWVEolZwM1y4FiBQCngp4VzgZqlg/FCgAjXg1sNrgLyCwfihUARt0FNBsqpRJj7gIym/MKFQD2jlbdBTQL3AIwy4dCBYDaILC7gDrN00DN8qGlACBpraQdkgYlXTHJ9oWS7kjb75e0IpV/SNIDkralf89qOObH6ZwPpdebMruqSYxPBHv3uQUwGyoltwDM8mDKn8NpTd/rgA8Bu4Gtkvoj4tGG3S4FXoiIUyStB64BPgH8GvjXEfELSe+ktqzk0objLkorg3Xcy/VMoB4D6LhKueRsoGY50EoLYA0wGBE7I2I/cDuwrmmfdcDN6f0m4GxJioifRsQvUvl24DBJC7Oo+HQdTATnLqBO8zRQs3xoJQAsBXY1fN7Na3/Fv2afiKgCLwHHNe3zb4AHI2JfQ9k3UvfPFyVN+niupMskDUgaGBoaaqG6k3vJqaBnTaVUYtxjAGZz3qwMAkt6B7VuoX/bUHxRRLwL+EB6fWqyYyNiY0T0RURfb2/vjOvgVNCzp1IWY+4CMpvzWgkAe4DlDZ+XpbJJ95FUAY4CnkuflwHfBS6OiCfqB0TEnvTvXuA2al1NHeNU0LPHg8Bm+dBKANgKrJK0UtICYD3Q37RPP3BJen8+cE9EhKSjge8DV0TE/6nvLKki6fj0vgf4GPBIW1cyBbcAZk8lTQONcBAwm8um/DkcEVVJl1ObwVMGboyI7ZI2AAMR0Q/cANwqaRB4nlqQALgcOAW4StJVqezDwCvAlnTzLwM/BP42w+t6HS8HOXvKpdrviiu/s43JR3Ys797x5qP45Blv6XY1rE0t9YdExGZgc1PZVQ3vR4ELJjnuauDqQ5z2va1Xs33Do1UkWLzQXUCd9u7lR3HSUYu452fPdrsq1gGv7h9n0wO7+XjfchZUCvUs6bxTmLvh3tExjvRaALPi9059E/985dndroZ1yD/8dA9/esdDPPXcK7zthMXdro61oTDhe3jETwGbZaF+09/xy71drom1qzgBYHTMqaDNMvAbbzqCckkOAPNAcQKAVwMzy8TCSpmVxx/Bjl85AORdcQKAU0GbZebUExbzcweA3CtOAHAqaLPMvO2ExTz9/Ku8ur/a7apYG4oTALwesFlmTj1xMRHw+K9e7nZVrA2FCAATE8HL+6oeAzDLyKknpplA7gbKtUIEgL37qkQ4FbRZVk4+9nAWVkr83DOBcq0QAcBpIMyyVS6JVScc6RZAzhUjADgRnFnmTj1hiZ8FyLlCBIC9o04FbZa1U088kmf37uOFV/Z3uyo2Q4UIAAe6gNwCMMtMPSWEnwfIr2IEgNQCOMpjAGaZqc8EcgDIr2IEgNQCcC4gs+ycuGQRSxZV+JnHAXKrGAEgDQIf6bUAzDIjiVNPdEqIPGvpjihpLfAVaqt3fT0i/qpp+0LgFmqLvDwHfCIinkrbrgQuBcaBP46ILa2cM0vDI1WOXFihUi5EvDObNW87YTF3DuziI1/5X92uSseVS2LdaW/m4vevmDcL4UwZACSVgeuADwG7ga2S+iPi0YbdLgVeiIhTJK0HrgE+IWk1teUh3wG8GfihpLelY6Y6Z2ZqaSD8698sax/vW86vX97H+ES3a9J5z72yj6u//xi3/eRpvvjR1bz/N46b1b+/oFzKfEGrVu6Ka4DBiNgJIOl2YB3QeLNeB/zH9H4T8N8kKZXfHhH7gCfTmsFr0n5TnTMzTgVt1hnvXn4013+qr9vVmBURwb07nuXq7z3GH960ddb//g8//7uc8qYjMz1nKwFgKbCr4fNu4H2H2ictIv8ScFwqv6/p2KXp/VTnBEDSZcBlACeffHIL1X29dy8/mrf2Zvs/nJkViyTOevsJ/M4pvdz10B6GXt43q3//uCMWZH7OOd8vEhEbgY0AfX19MZNzfO73T8m0TmZWXAsqJS7oW97tamSilZGMPUDj1S5LZZPuI6kCHEVtMPhQx7ZyTjMz66BWAsBWYJWklZIWUBvU7W/apx+4JL0/H7gnIiKVr5e0UNJKYBXwkxbPaWZmHTRlF1Dq078c2EJtyuaNEbFd0gZgICL6gRuAW9Mg7/PUbuik/e6kNrhbBT4XEeMAk50z+8szM7NDUe2Hej709fXFwMBAt6thZpYrkh6IiNdN15ofTzOYmdm0OQCYmRWUA4CZWUE5AJiZFVSuBoElDQH/MsPDjwd+nWF18qKI113Ea4ZiXrevuTVviYje5sJcBYB2SBqYbBR8vividRfxmqGY1+1rbo+7gMzMCsoBwMysoIoUADZ2uwJdUsTrLuI1QzGv29fchsKMAZiZ2WsVqQVgZmYNHADMzAqqEAFA0lpJOyQNSrqi2/XpBEnLJd0r6VFJ2yX9SSo/VtLdkh5P/x7T7bpmTVJZ0k8lfS99Xinp/vR935FSjs8rko6WtEnSzyQ9Jun98/27lvTv0n/bj0j6lqRF8/G7lnSjpGclPdJQNul3q5qvput/WNJvTedvzfsA0LCo/TnAauDCtFj9fFMF/n1ErAbOAD6XrvMK4EcRsQr4Ufo83/wJ8FjD52uAayPiFOAF4NKu1KqzvgL8Y0S8HXg3teuft9+1pKXAHwN9EfFOamnk1zM/v+ubgLVNZYf6bs+hts7KKmpL535tOn9o3gcAGha1j4j9QH0B+nklIp6JiAfT+73UbghLqV3rzWm3m4HzulLBDpG0DPgo8PX0WcBZwKa0y3y85qOAM6mtw0FE7I+IF5nn3zW19UsOS6sOHg48wzz8riPif1JbV6XRob7bdcAtUXMfcLSkk1r9W0UIAJMtar/0EPvOC5JWAO8B7gdOiIhn0qZfAid0q14d8l+B/wBMpM/HAS9GRDV9no/f90pgCPhG6vr6uqQjmMffdUTsAf4L8DS1G/9LwAPM/++67lDfbVv3tyIEgEKRdCTwbeBPI2K4cVtapnPezPuV9DHg2Yh4oNt1mWUV4LeAr0XEe4BXaOrumYff9THUfu2uBN4MHMHru0kKIcvvtggBoDAL0EvqoXbz/2ZEfCcV/6reJEz/Ptut+nXAbwPnSnqKWtfeWdT6xo9O3QQwP7/v3cDuiLg/fd5ELSDM5+/6g8CTETEUEWPAd6h9//P9u6471Hfb1v2tCAGgEAvQp77vG4DHIuJvGjb1A5ek95cAd8123TolIq6MiGURsYLa93pPRFwE3Aucn3abV9cMEBG/BHZJOjUVnU1t3e15+11T6/o5Q9Lh6b/1+jXP6++6waG+237g4jQb6AzgpYauoqlFxLx/AR8Bfg48AXyh2/Xp0DX+DrVm4cPAQ+n1EWp94j8CHgd+CBzb7bp26Pp/D/heev9W4CfAIPD3wMJu168D13saMJC+738Ajpnv3zXwn4CfAY8AtwIL5+N3DXyL2jjHGLXW3qWH+m4BUZvl+ASwjdosqZb/llNBmJkVVBG6gMzMbBIOAGZmBeUAYGZWUA4AZmYF5QBgZlZQDgBmZgXlAGBmVlD/H0/GuG3dDPUOAAAAAElFTkSuQmCC",
                  "text/plain": [
                     "<Figure size 432x288 with 1 Axes>"
                  ]
               },
               "metadata": {
                  "needs_background": "light"
               },
               "output_type": "display_data"
            }
         ],
         "source": [
            "import matplotlib.pyplot as plt\n",
            "\n",
            "plt.plot(lrs)\n",
            "# plt.plot(step_lrs)\n",
            "# plt.plot(combined)\n",
            "# plt.plot(linear_warmup)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 16,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "[1.6, 1.6, 0.16000000000000003, 0.16000000000000003]"
                  ]
               },
               "execution_count": 16,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "lrs[28:32]"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 17,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "0.16000000000000003"
                  ]
               },
               "execution_count": 17,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "lrs[31]"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "from rigl_torch.models import get_model\n",
            "from rigl_torch.datasets import get_dataloaders\n",
            "from omegaconf import DictConfig\n",
            "import hydra"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "with hydra.initialize(config_path=\"../configs\"):\n",
            "    cfg = hydra.compose(config_name=\"config.yaml\", overrides=[])\n",
            "cfg"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "def print_image_shape(module, input, output):\n",
            "    print(f\"Module {module._get_name()}\")\n",
            "    print(f\"input shape: {input[0].shape} output shape: {output.shape}\")\n",
            "    return output"
         ]
      }
   ],
   "metadata": {
      "kernelspec": {
         "display_name": "Python 3.8.12 ('.venv')",
         "language": "python",
         "name": "python3"
      },
      "language_info": {
         "codemirror_mode": {
            "name": "ipython",
            "version": 3
         },
         "file_extension": ".py",
         "mimetype": "text/x-python",
         "name": "python",
         "nbconvert_exporter": "python",
         "pygments_lexer": "ipython3",
         "version": "3.8.12"
      },
      "orig_nbformat": 4,
      "vscode": {
         "interpreter": {
            "hash": "816b48dc46e0e4033a4b7ddacb526e2f216437e7413cf9fdf092ed7be3b64e38"
         }
      }
   },
   "nbformat": 4,
   "nbformat_minor": 2
}
