{
   "cells": [
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts, CosineAnnealingLR, _LRScheduler\n",
            "from torch.optim import AdamW\n",
            "import math\n",
            "from rigl_torch.datasets import get_dataloaders\n",
            "\n",
            "\n",
            "net = ModelFactory.load_model(\"wide_resnet22\", \"cifar10\")"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  "/tmp/ipykernel_171789/4275460388.py:6: UserWarning: \n",
                  "The version_base parameter is not specified.\n",
                  "Please specify a compatability version level, or None.\n",
                  "Will assume defaults for version 1.1\n",
                  "  with hydra.initialize(config_path=\"../configs\"):\n"
               ]
            },
            {
               "data": {
                  "text/plain": [
                     "{'dataset': {'name': 'cifar10', 'normalize': False, 'num_classes': 10, 'classes': ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']}, 'model': {'name': 'wide_resnet22'}, 'experiment': {'comment': None, 'name': '${model.name}_${dataset.name}_${experiment.comment}_0.1LR'}, 'paths': {'data_folder': '/home/condensed-sparsity/data', 'artifacts': '/home/condensed-sparsity/artifacts', 'logs': '/home/condensed-sparsity/logs'}, 'rigl': {'dense_allocation': 0.1, 'delta': 100, 'grad_accumulation_n': 1, 'alpha': 0.3, 'static_topo': 0, 'const_fan_in': False, 'sparsity_distribution': 'erk', 'erk_power_scale': 1.0}, 'training': {'batch_size': 128, 'test_batch_size': 10, 'epochs': 250, 'lr': 0.1, 'init_lr': 1e-06, 'warm_up_steps': 5, 'gamma': 0.2, 'dry_run': False, 'seed': 1, 'log_interval': 10, 'save_model': True, 'weight_decay': 0, 'momentum': 0.9, 'optimizer': 'adadelta'}, 'compute': {'no_cuda': False, 'cuda_kwargs': {'num_workers': 1, 'pin_memory': True, 'shuffle': True}}, 'wandb': {'project': 'condensed-rigl', 'entity': 'condensed-sparsity', 'start_method': 'thread'}}"
                  ]
               },
               "execution_count": 1,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "from rigl_torch.datasets import get_dataloaders\n",
            "from omegaconf import DictConfig\n",
            "from rigl_torch.models import ModelFactory\n",
            "import hydra\n",
            "\n",
            "with hydra.initialize(config_path=\"../configs\"):\n",
            "    cfg = hydra.compose(config_name=\"config.yaml\", overrides=[])\n",
            "cfg"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 5,
         "metadata": {},
         "outputs": [],
         "source": [
            "import torchvision\n",
            "cifar = torchvision.datasets.CIFAR10(root=\"../data/\")"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 7,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "50000"
                  ]
               },
               "execution_count": 7,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "len(cifar)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 2,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Files already downloaded and verified\n"
               ]
            }
         ],
         "source": [
            "train, test = get_dataloaders(cfg)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "50048"
                  ]
               },
               "execution_count": 9,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "128*391"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "len(train)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "for x in train:\n",
            "    break"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "x[0].shape"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "import torch\n",
            "T_max= int(250*50000/128)\n",
            "adamw1 = AdamW(net.parameters(), lr=0.001)\n",
            "adamw2 = AdamW(net.parameters(), lr=0.001)\n",
            "linear_step = torch.optim.lr_scheduler.StepLR(adamw2, step_size=30000, gamma=0.2)\n",
            "cawr = CosineAnnealingWarmRestarts(optimizer=adamw1, T_0=20, T_mult=2)\n",
            "# ca = CosineAnnealingLR(optimizer=adamw2, T_max=T_max)\n",
            "# adamw3 = AdamW(net.parameters(), lr=0.001)\n",
            "# test= CosineAnnealingWithLinearWarmUp(optimizer=adamw3, T_max=T_max, warm_up_steps=50, lr=0.001)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "linear_step.get_last_lr()"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "%matplotlib inline\n",
            "warm_restart_lrs = []\n",
            "linear_step_lrs = []\n",
            "combined =[]\n",
            "linear_warmup = []\n",
            "for x in range(T_max):\n",
            "    lr1 = cawr.get_last_lr()\n",
            "    warm_restart_lrs.append(lr1)\n",
            "    cawr.step()\n",
            "    lr2 = linear_step.get_last_lr()\n",
            "    linear_step_lrs.append(lr2)\n",
            "    linear_step.step()\n",
            "    # combined.append(lr1[0] * lr2[0]*1000)\n",
            "    # lr3 = test.get_last_lr()\n",
            "    # linear_warmup.append(lr3)\n",
            "    # test.step()"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "import matplotlib.pyplot as plt\n",
            "\n",
            "plt.plot(warm_restart_lrs)\n",
            "plt.plot(linear_step_lrs)\n",
            "# plt.plot(combined)\n",
            "# plt.plot(linear_warmup)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "from rigl_torch.models import get_model\n",
            "from rigl_torch.datasets import get_dataloaders\n",
            "from omegaconf import DictConfig\n",
            "import hydra"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "with hydra.initialize(config_path=\"../configs\"):\n",
            "    cfg = hydra.compose(config_name=\"config.yaml\", overrides=[])\n",
            "cfg"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "def print_image_shape(module, input, output):\n",
            "    print(f\"Module {module._get_name()}\")\n",
            "    print(f\"input shape: {input[0].shape} output shape: {output.shape}\")\n",
            "    return output"
         ]
      }
   ],
   "metadata": {
      "interpreter": {
         "hash": "3048c034334543d4ee86da410acdb4bca653f21fb3aaa9f7e0605787389cbd5e"
      },
      "kernelspec": {
         "display_name": "Python 3.8.10 ('.venv': venv)",
         "language": "python",
         "name": "python3"
      },
      "language_info": {
         "codemirror_mode": {
            "name": "ipython",
            "version": 3
         },
         "file_extension": ".py",
         "mimetype": "text/x-python",
         "name": "python",
         "nbconvert_exporter": "python",
         "pygments_lexer": "ipython3",
         "version": "3.8.10"
      },
      "orig_nbformat": 4
   },
   "nbformat": 4,
   "nbformat_minor": 2
}
