{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.multiprocessing as mp\n",
    "import torch.distributed as dist\n",
    "from torch.nn.parallel import DistributedDataParallel\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import pytorch_lightning as pl\n",
    "import random\n",
    "import dotenv\n",
    "import omegaconf\n",
    "import hydra\n",
    "import logging\n",
    "from typing import List\n",
    "\n",
    "import wandb\n",
    "from datetime import date\n",
    "import dotenv\n",
    "import os\n",
    "import pathlib\n",
    "from typing import Dict, Any\n",
    "from copy import deepcopy\n",
    "\n",
    "from rigl_torch.models import ModelFactory\n",
    "from rigl_torch.rigl_scheduler import RigLScheduler\n",
    "from rigl_torch.rigl_constant_fan import RigLConstFanScheduler\n",
    "from rigl_torch.datasets import get_dataloaders\n",
    "from rigl_torch.optim import (\n",
    "    get_optimizer,\n",
    "    get_lr_scheduler,\n",
    ")\n",
    "from rigl_torch.utils.checkpoint import Checkpoint\n",
    "from rigl_torch.utils.rigl_utils import get_T_end, get_fan_in_after_ablation, get_conv_idx_from_flat_idx\n",
    "from hydra import initialize, compose\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resnet50\n"
     ]
    }
   ],
   "source": [
    "with initialize(\"../configs\", version_base=\"1.2.0\"):\n",
    "    cfg = compose(\n",
    "        \"config.yaml\",\n",
    "        overrides=[\n",
    "            \"dataset=imagenet\",\n",
    "            # # \"compute.distributed=False\",\n",
    "            \"model=resnet50\",\n",
    "            # # \"model=skinny_resnet18\",\n",
    "            # \"rigl.dense_allocation=0.01\",\n",
    "            # \"rigl.delta=2\",\n",
    "            # \"rigl.grad_accumulation_n=1\"\n",
    "            ])\n",
    "dotenv.load_dotenv(\"../.env\")\n",
    "os.environ[\"IMAGE_NET_PATH\"]\n",
    "print(cfg.model.name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'no_cuda': False, 'cuda_kwargs': {'num_workers': '${ oc.decode:${oc.env:NUM_WORKERS} }', 'pin_memory': True}, 'distributed': False, 'world_size': 4, 'dist_backend': 'nccl'}\n",
      "loading to device rank: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:/home/user/condensed-sparsity/src/rigl_torch/models/model_factory.py:Loading model resnet50/imagenet using <function get_imagenet_resnet50 at 0x7ff7b4257ac0> with args: () and kwargs: {'diet': [17, 16, 17, 14, 16, 33, 31, 31, 32, 30, 65, 63, 63, 65, 63, 122, 124, 124, 114, 125, 0]}\n"
     ]
    }
   ],
   "source": [
    "rank=0\n",
    "checkpoint=None\n",
    "if checkpoint is not None:\n",
    "    run_id = checkpoint.run_id\n",
    "    optimizer_state = checkpoint.optimizer\n",
    "    scheduler_state = checkpoint.scheduler\n",
    "    pruner_state = checkpoint.pruner\n",
    "    model_state = checkpoint.model\n",
    "    cfg = checkpoint.cfg\n",
    "else:\n",
    "    run_id, optimizer_state, scheduler_state, pruner_state, model_state = (\n",
    "        None,\n",
    "        None,\n",
    "        None,\n",
    "        None,\n",
    "        None,\n",
    "    )\n",
    "\n",
    "if \"diet\" not in cfg.rigl:\n",
    "    with omegaconf.open_dict(cfg):\n",
    "        cfg.rigl.diet = None\n",
    "if \"keep_first_layer_dense\" not in cfg.rigl:\n",
    "    with omegaconf.open_dict(cfg):\n",
    "        cfg.rigl.keep_first_layer_dense = False\n",
    "print(cfg.compute)\n",
    "cfg.compute.distributed=False\n",
    "    \n",
    "pl.seed_everything(cfg.training.seed)\n",
    "use_cuda = not cfg.compute.no_cuda and torch.cuda.is_available()\n",
    "if not use_cuda:\n",
    "    raise SystemError(\"GPU has stopped responding...waiting to die!\")\n",
    "    logger.warning(\n",
    "        \"Using CPU! Verify cfg.compute.no_cuda and \"\n",
    "        \"torch.cuda.is_available() are properly set if this is unexpected\"\n",
    "    )\n",
    "\n",
    "if cfg.compute.distributed and use_cuda:\n",
    "    device = torch.device(f\"cuda:{rank}\")\n",
    "else:\n",
    "    print(f\"loading to device rank: {rank}\")\n",
    "    device = torch.device(f\"cuda:{rank}\")\n",
    "if not use_cuda:\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "train_loader, test_loader = get_dataloaders(cfg)\n",
    "\n",
    "model = ModelFactory.load_model(\n",
    "    model=cfg.model.name, dataset=cfg.dataset.name, diet=cfg.rigl.diet\n",
    ")\n",
    "model.to(device)\n",
    "if cfg.compute.distributed:\n",
    "    model = DistributedDataParallel(model, device_ids=[rank])\n",
    "if model_state is not None:\n",
    "    try:\n",
    "        model.load_state_dict(model_state)\n",
    "    except RuntimeError:\n",
    "        model_state = checkpoint.get_single_process_model_state_from_distributed_state()\n",
    "        model.load_state_dict(model_state)\n",
    "        \n",
    "optimizer = get_optimizer(cfg, model, state_dict=optimizer_state)\n",
    "scheduler = get_lr_scheduler(cfg, optimizer, state_dict=scheduler_state)\n",
    "pruner = None\n",
    "if cfg.rigl.dense_allocation is not None:\n",
    "    if cfg.rigl.dense_allocation is not None:\n",
    "        if cfg.model.name == \"skinny_resnet18\":\n",
    "            dense_allocation = (\n",
    "                cfg.rigl.dense_allocation * cfg.model.sparsity_scale_factor\n",
    "            )\n",
    "            print(\n",
    "                f\"Scaling {cfg.rigl.dense_allocation} by \"\n",
    "                f\"{cfg.model.sparsity_scale_factor:.2f} for SkinnyResNet18 \"\n",
    "                f\"New Dense Alloc == {dense_allocation:.6f}\"\n",
    "            )\n",
    "        else:\n",
    "            dense_allocation = cfg.rigl.dense_allocation\n",
    "        T_end = get_T_end(cfg, [0 for _ in range(0,1251)])\n",
    "        if cfg.rigl.const_fan_in:\n",
    "            rigl_scheduler = RigLConstFanScheduler\n",
    "        else:\n",
    "            rigl_scheduler = RigLScheduler\n",
    "        pruner = rigl_scheduler(\n",
    "            model,\n",
    "            optimizer,\n",
    "            dense_allocation=cfg.rigl.dense_allocation,\n",
    "            alpha=cfg.rigl.alpha,\n",
    "            delta=cfg.rigl.delta,\n",
    "            static_topo=cfg.rigl.static_topo,\n",
    "            T_end=T_end,\n",
    "            ignore_linear_layers=cfg.rigl.ignore_linear_layers,\n",
    "            grad_accumulation_n=cfg.rigl.grad_accumulation_n,\n",
    "            sparsity_distribution=cfg.rigl.sparsity_distribution,\n",
    "            erk_power_scale=cfg.rigl.erk_power_scale,\n",
    "            state_dict=pruner_state,\n",
    "            filter_ablation_threshold=cfg.rigl.filter_ablation_threshold,\n",
    "            static_ablation=cfg.rigl.static_ablation,\n",
    "            dynamic_ablation=cfg.rigl.dynamic_ablation,\n",
    "            min_salient_weights_per_neuron=cfg.rigl.min_salient_weights_per_neuron,  # noqa\n",
    "            use_sparse_init=cfg.rigl.use_sparse_initialization,\n",
    "            init_method_str=cfg.rigl.init_method_str,\n",
    "            use_sparse_const_fan_in_for_ablation=cfg.rigl.use_sparse_const_fan_in_for_ablation,  # noqa\n",
    "            initialize_grown_weights=cfg.rigl.initialize_grown_weights,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "for data, target in train_loader:\n",
    "    print(data.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rigl_torch.utils.sparse_ops import SparseModelFactory\n",
    "\n",
    "dense_model = model\n",
    "sparse_model = SparseModelFactory().get_sparse_model(model.to(\"cpu\"), input_shape=data.to(\"cpu\").shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.benchmark import Timer\n",
    "data = data.to(\"cpu\")\n",
    "dense_model = dense_model.to(\"cpu\")\n",
    "dense_timer = Timer(\n",
    "    stmt='model(input)',\n",
    "    label=\"dense\",\n",
    "    globals={\"model\": dense_model,\n",
    "             \"input\": data},\n",
    "    num_threads=8,\n",
    ")\n",
    "\n",
    "dense_result = dense_timer.timeit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.benchmark import Timer\n",
    "sparse_timer = Timer(\n",
    "    stmt='model(input)',\n",
    "    label=\"dense\",\n",
    "    globals={\"model\": sparse_model,\n",
    "             \"input\": data},\n",
    "    num_threads=8,\n",
    ")\n",
    "\n",
    "sparse_result = sparse_timer.timeit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.benchmark.utils.common.Measurement object at 0x7ff7c48e59f0>\n",
      "dense\n",
      "  11.10 s\n",
      "  1 measurement, 1 runs , 8 threads\n"
     ]
    }
   ],
   "source": [
    "print(dense_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.benchmark.utils.common.Measurement object at 0x7ff786ae7f70>\n",
      "dense\n",
      "  10.10 s\n",
      "  1 measurement, 1 runs , 8 threads\n"
     ]
    }
   ],
   "source": [
    "print(sparse_result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
