{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.multiprocessing as mp\n",
    "import torch.distributed as dist\n",
    "from torch.nn.parallel import DistributedDataParallel\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import pytorch_lightning as pl\n",
    "import random\n",
    "import dotenv\n",
    "import omegaconf\n",
    "import hydra\n",
    "import logging\n",
    "from typing import List\n",
    "\n",
    "import wandb\n",
    "from datetime import date\n",
    "import dotenv\n",
    "import os\n",
    "import pathlib\n",
    "from typing import Dict, Any\n",
    "from copy import deepcopy\n",
    "\n",
    "from rigl_torch.models import ModelFactory\n",
    "from rigl_torch.rigl_scheduler import RigLScheduler\n",
    "from rigl_torch.rigl_constant_fan import RigLConstFanScheduler\n",
    "from rigl_torch.datasets import get_dataloaders\n",
    "from rigl_torch.optim import (\n",
    "    get_optimizer,\n",
    "    get_lr_scheduler,\n",
    ")\n",
    "from rigl_torch.utils.checkpoint import Checkpoint\n",
    "from rigl_torch.utils.rigl_utils import get_T_end, get_fan_in_after_ablation, get_conv_idx_from_flat_idx\n",
    "from hydra import initialize, compose\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resnet50\n"
     ]
    }
   ],
   "source": [
    "with initialize(\"../configs\", version_base=\"1.2.0\"):\n",
    "    cfg = compose(\n",
    "        \"config.yaml\",\n",
    "        overrides=[\n",
    "            \"dataset=imagenet\",\n",
    "            # # \"compute.distributed=False\",\n",
    "            \"model=resnet50\",\n",
    "            # # \"model=skinny_resnet18\",\n",
    "            # \"rigl.dense_allocation=0.01\",\n",
    "            # \"rigl.delta=2\",\n",
    "            # \"rigl.grad_accumulation_n=1\"\n",
    "            ])\n",
    "dotenv.load_dotenv(\"../.env\")\n",
    "os.environ[\"IMAGE_NET_PATH\"]\n",
    "print(cfg.model.name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'no_cuda': False, 'cuda_kwargs': {'num_workers': '${ oc.decode:${oc.env:NUM_WORKERS} }', 'pin_memory': True}, 'distributed': False, 'world_size': 4, 'dist_backend': 'nccl'}\n",
      "loading to device rank: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:/home/user/condensed-sparsity/src/rigl_torch/models/model_factory.py:Loading model resnet50/imagenet using <function get_imagenet_resnet50 at 0x7ff7b4257ac0> with args: () and kwargs: {'diet': [17, 16, 17, 14, 16, 33, 31, 31, 32, 30, 65, 63, 63, 65, 63, 122, 124, 124, 114, 125, 0]}\n"
     ]
    }
   ],
   "source": [
    "rank=0\n",
    "checkpoint=None\n",
    "if checkpoint is not None:\n",
    "    run_id = checkpoint.run_id\n",
    "    optimizer_state = checkpoint.optimizer\n",
    "    scheduler_state = checkpoint.scheduler\n",
    "    pruner_state = checkpoint.pruner\n",
    "    model_state = checkpoint.model\n",
    "    cfg = checkpoint.cfg\n",
    "else:\n",
    "    run_id, optimizer_state, scheduler_state, pruner_state, model_state = (\n",
    "        None,\n",
    "        None,\n",
    "        None,\n",
    "        None,\n",
    "        None,\n",
    "    )\n",
    "\n",
    "if \"diet\" not in cfg.rigl:\n",
    "    with omegaconf.open_dict(cfg):\n",
    "        cfg.rigl.diet = None\n",
    "if \"keep_first_layer_dense\" not in cfg.rigl:\n",
    "    with omegaconf.open_dict(cfg):\n",
    "        cfg.rigl.keep_first_layer_dense = False\n",
    "print(cfg.compute)\n",
    "cfg.compute.distributed=False\n",
    "    \n",
    "pl.seed_everything(cfg.training.seed)\n",
    "use_cuda = not cfg.compute.no_cuda and torch.cuda.is_available()\n",
    "if not use_cuda:\n",
    "    raise SystemError(\"GPU has stopped responding...waiting to die!\")\n",
    "    logger.warning(\n",
    "        \"Using CPU! Verify cfg.compute.no_cuda and \"\n",
    "        \"torch.cuda.is_available() are properly set if this is unexpected\"\n",
    "    )\n",
    "\n",
    "if cfg.compute.distributed and use_cuda:\n",
    "    device = torch.device(f\"cuda:{rank}\")\n",
    "else:\n",
    "    print(f\"loading to device rank: {rank}\")\n",
    "    device = torch.device(f\"cuda:{rank}\")\n",
    "if not use_cuda:\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "train_loader, test_loader = get_dataloaders(cfg)\n",
    "\n",
    "model = ModelFactory.load_model(\n",
    "    model=cfg.model.name, dataset=cfg.dataset.name, diet=cfg.rigl.diet\n",
    ")\n",
    "model.to(device)\n",
    "if cfg.compute.distributed:\n",
    "    model = DistributedDataParallel(model, device_ids=[rank])\n",
    "if model_state is not None:\n",
    "    try:\n",
    "        model.load_state_dict(model_state)\n",
    "    except RuntimeError:\n",
    "        model_state = checkpoint.get_single_process_model_state_from_distributed_state()\n",
    "        model.load_state_dict(model_state)\n",
    "        \n",
    "optimizer = get_optimizer(cfg, model, state_dict=optimizer_state)\n",
    "scheduler = get_lr_scheduler(cfg, optimizer, state_dict=scheduler_state)\n",
    "pruner = None\n",
    "if cfg.rigl.dense_allocation is not None:\n",
    "    if cfg.rigl.dense_allocation is not None:\n",
    "        if cfg.model.name == \"skinny_resnet18\":\n",
    "            dense_allocation = (\n",
    "                cfg.rigl.dense_allocation * cfg.model.sparsity_scale_factor\n",
    "            )\n",
    "            print(\n",
    "                f\"Scaling {cfg.rigl.dense_allocation} by \"\n",
    "                f\"{cfg.model.sparsity_scale_factor:.2f} for SkinnyResNet18 \"\n",
    "                f\"New Dense Alloc == {dense_allocation:.6f}\"\n",
    "            )\n",
    "        else:\n",
    "            dense_allocation = cfg.rigl.dense_allocation\n",
    "        T_end = get_T_end(cfg, [0 for _ in range(0,1251)])\n",
    "        if cfg.rigl.const_fan_in:\n",
    "            rigl_scheduler = RigLConstFanScheduler\n",
    "        else:\n",
    "            rigl_scheduler = RigLScheduler\n",
    "        pruner = rigl_scheduler(\n",
    "            model,\n",
    "            optimizer,\n",
    "            dense_allocation=cfg.rigl.dense_allocation,\n",
    "            alpha=cfg.rigl.alpha,\n",
    "            delta=cfg.rigl.delta,\n",
    "            static_topo=cfg.rigl.static_topo,\n",
    "            T_end=T_end,\n",
    "            ignore_linear_layers=cfg.rigl.ignore_linear_layers,\n",
    "            grad_accumulation_n=cfg.rigl.grad_accumulation_n,\n",
    "            sparsity_distribution=cfg.rigl.sparsity_distribution,\n",
    "            erk_power_scale=cfg.rigl.erk_power_scale,\n",
    "            state_dict=pruner_state,\n",
    "            filter_ablation_threshold=cfg.rigl.filter_ablation_threshold,\n",
    "            static_ablation=cfg.rigl.static_ablation,\n",
    "            dynamic_ablation=cfg.rigl.dynamic_ablation,\n",
    "            min_salient_weights_per_neuron=cfg.rigl.min_salient_weights_per_neuron,  # noqa\n",
    "            use_sparse_init=cfg.rigl.use_sparse_initialization,\n",
    "            init_method_str=cfg.rigl.init_method_str,\n",
    "            use_sparse_const_fan_in_for_ablation=cfg.rigl.use_sparse_const_fan_in_for_ablation,  # noqa\n",
    "            initialize_grown_weights=cfg.rigl.initialize_grown_weights,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "for data, target in train_loader:\n",
    "    print(data.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rigl_torch.utils.sparse_ops import SparseModelFactory\n",
    "\n",
    "dense_model = model\n",
    "sparse_model = SparseModelFactory().get_sparse_model(model.to(\"cpu\"), input_shape=data.to(\"cpu\").shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.benchmark import Timer\n",
    "data = data.to(\"cpu\")\n",
    "dense_model = dense_model.to(\"cpu\")\n",
    "dense_timer = Timer(\n",
    "    stmt='model(input)',\n",
    "    label=\"dense\",\n",
    "    globals={\"model\": dense_model,\n",
    "             \"input\": data},\n",
    "    num_threads=8,\n",
    ")\n",
    "\n",
    "dense_result = dense_timer.timeit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.benchmark import Timer\n",
    "sparse_timer = Timer(\n",
    "    stmt='model(input)',\n",
    "    label=\"dense\",\n",
    "    globals={\"model\": sparse_model,\n",
    "             \"input\": data},\n",
    "    num_threads=8,\n",
    ")\n",
    "\n",
    "sparse_result = sparse_timer.timeit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.benchmark.utils.common.Measurement object at 0x7ff7b3ff7100>\n",
      "dense\n",
      "  9.68 s\n",
      "  1 measurement, 1 runs , 8 threads\n"
     ]
    }
   ],
   "source": [
    "print(dense_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.benchmark.utils.common.Measurement object at 0x7ff786ae7f70>\n",
      "dense\n",
      "  10.10 s\n",
      "  1 measurement, 1 runs , 8 threads\n"
     ]
    }
   ],
   "source": [
    "print(sparse_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "module Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False) took 0.11940121650695801 fwd and 0.8622603416442871 bwd\n",
      "module SparseConv2d([64, 3, 7, 7], sp=0.96, nnz=384, s=2, p=3, voo=False) took 0.3096311092376709 fwd and 1.401214838027954 bwd\n",
      "module SparseConv2d([64, 3, 7, 7], sp=0.96, nnz=384, s=2, p=3, voo=True) took 0.29630565643310547 fwd and 0.8625237941741943 bwd\n",
      "going with Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False) with full time of 0.9816615581512451\n",
      "keeping the module conv1 dense...\n",
      "module Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False) took 0.03121495246887207 fwd and 0.10735845565795898 bwd\n",
      "module SparseConv2d([64, 64, 1, 1], sp=0.86, nnz=576, s=1, p=0, voo=False) took 0.09251952171325684 fwd and 0.39707136154174805 bwd\n",
      "module SparseConv2d([64, 64, 1, 1], sp=0.86, nnz=576, s=1, p=0, voo=True) took 0.0315093994140625 fwd and 0.07506585121154785 bwd\n",
      "going with SparseConv2d([64, 64, 1, 1], sp=0.86, nnz=576, s=1, p=0, voo=True) with full time of 0.10657525062561035\n",
      "module layer1.0.conv1 replaced with SparseConv2d([64, 64, 1, 1], sp=0.86, nnz=576, s=1, p=0, voo=True)\n",
      "module Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) took 0.10468339920043945 fwd and 0.2530035972595215 bwd\n",
      "module SparseConv2d([64, 64, 3, 3], sp=0.98, nnz=640, s=1, p=1, voo=False) took 0.10110616683959961 fwd and 0.3958704471588135 bwd\n",
      "module SparseConv2d([64, 64, 3, 3], sp=0.98, nnz=640, s=1, p=1, voo=True) took 0.036988019943237305 fwd and 0.09065008163452148 bwd\n",
      "going with SparseConv2d([64, 64, 3, 3], sp=0.98, nnz=640, s=1, p=1, voo=True) with full time of 0.1276381015777588\n",
      "module layer1.0.conv2 replaced with SparseConv2d([64, 64, 3, 3], sp=0.98, nnz=640, s=1, p=1, voo=True)\n",
      "module Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False) took 0.10229802131652832 fwd and 0.8748898506164551 bwd\n",
      "module SparseConv2d([256, 64, 1, 1], sp=0.91, nnz=1536, s=1, p=0, voo=False) took 0.23076653480529785 fwd and 1.3759586811065674 bwd\n",
      "module SparseConv2d([256, 64, 1, 1], sp=0.91, nnz=1536, s=1, p=0, voo=True) took 0.1356525421142578 fwd and 0.6110999584197998 bwd\n",
      "going with SparseConv2d([256, 64, 1, 1], sp=0.91, nnz=1536, s=1, p=0, voo=True) with full time of 0.7467525005340576\n",
      "module layer1.0.conv3 replaced with SparseConv2d([256, 64, 1, 1], sp=0.91, nnz=1536, s=1, p=0, voo=True)\n",
      "module Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False) took 0.08806633949279785 fwd and 0.8515908718109131 bwd\n",
      "module SparseConv2d([256, 64, 1, 1], sp=0.91, nnz=1536, s=1, p=0, voo=False) took 0.23014068603515625 fwd and 1.3015170097351074 bwd\n",
      "module SparseConv2d([256, 64, 1, 1], sp=0.91, nnz=1536, s=1, p=0, voo=True) took 0.15416264533996582 fwd and 0.47394895553588867 bwd\n",
      "going with SparseConv2d([256, 64, 1, 1], sp=0.91, nnz=1536, s=1, p=0, voo=True) with full time of 0.6281116008758545\n",
      "module layer1.0.downsample.0 replaced with SparseConv2d([256, 64, 1, 1], sp=0.91, nnz=1536, s=1, p=0, voo=True)\n",
      "module Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False) took 0.19149565696716309 fwd and 0.4714174270629883 bwd\n",
      "module SparseConv2d([64, 256, 1, 1], sp=0.91, nnz=1536, s=1, p=0, voo=False) took 0.3221321105957031 fwd and 0.9631571769714355 bwd\n",
      "module SparseConv2d([64, 256, 1, 1], sp=0.91, nnz=1536, s=1, p=0, voo=True) took 0.08741617202758789 fwd and 0.21476984024047852 bwd\n",
      "going with SparseConv2d([64, 256, 1, 1], sp=0.91, nnz=1536, s=1, p=0, voo=True) with full time of 0.3021860122680664\n",
      "module layer1.1.conv1 replaced with SparseConv2d([64, 256, 1, 1], sp=0.91, nnz=1536, s=1, p=0, voo=True)\n",
      "module Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) took 0.10244035720825195 fwd and 0.18179583549499512 bwd\n",
      "module SparseConv2d([64, 64, 3, 3], sp=0.98, nnz=640, s=1, p=1, voo=False) took 0.0932321548461914 fwd and 0.40331053733825684 bwd\n",
      "module SparseConv2d([64, 64, 3, 3], sp=0.98, nnz=640, s=1, p=1, voo=True) took 0.03739500045776367 fwd and 0.09081697463989258 bwd\n",
      "going with SparseConv2d([64, 64, 3, 3], sp=0.98, nnz=640, s=1, p=1, voo=True) with full time of 0.12821197509765625\n",
      "module layer1.1.conv2 replaced with SparseConv2d([64, 64, 3, 3], sp=0.98, nnz=640, s=1, p=1, voo=True)\n",
      "module Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False) took 0.0879976749420166 fwd and 0.798912763595581 bwd\n",
      "module SparseConv2d([256, 64, 1, 1], sp=0.91, nnz=1536, s=1, p=0, voo=False) took 0.2249889373779297 fwd and 1.4543509483337402 bwd\n",
      "module SparseConv2d([256, 64, 1, 1], sp=0.91, nnz=1536, s=1, p=0, voo=True) took 0.1723318099975586 fwd and 0.5625960826873779 bwd\n",
      "going with SparseConv2d([256, 64, 1, 1], sp=0.91, nnz=1536, s=1, p=0, voo=True) with full time of 0.7349278926849365\n",
      "module layer1.1.conv3 replaced with SparseConv2d([256, 64, 1, 1], sp=0.91, nnz=1536, s=1, p=0, voo=True)\n",
      "module Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False) took 0.14776182174682617 fwd and 0.4784708023071289 bwd\n",
      "module SparseConv2d([64, 256, 1, 1], sp=0.91, nnz=1536, s=1, p=0, voo=False) took 0.32297539710998535 fwd and 0.9757754802703857 bwd\n",
      "module SparseConv2d([64, 256, 1, 1], sp=0.91, nnz=1536, s=1, p=0, voo=True) took 0.08616209030151367 fwd and 0.21652936935424805 bwd\n",
      "going with SparseConv2d([64, 256, 1, 1], sp=0.91, nnz=1536, s=1, p=0, voo=True) with full time of 0.3026914596557617\n",
      "module layer1.2.conv1 replaced with SparseConv2d([64, 256, 1, 1], sp=0.91, nnz=1536, s=1, p=0, voo=True)\n",
      "module Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) took 0.10372662544250488 fwd and 0.25025153160095215 bwd\n",
      "module SparseConv2d([64, 64, 3, 3], sp=0.98, nnz=640, s=1, p=1, voo=False) took 0.10239458084106445 fwd and 0.39719080924987793 bwd\n",
      "module SparseConv2d([64, 64, 3, 3], sp=0.98, nnz=640, s=1, p=1, voo=True) took 0.03767704963684082 fwd and 0.09157514572143555 bwd\n",
      "going with SparseConv2d([64, 64, 3, 3], sp=0.98, nnz=640, s=1, p=1, voo=True) with full time of 0.12925219535827637\n",
      "module layer1.2.conv2 replaced with SparseConv2d([64, 64, 3, 3], sp=0.98, nnz=640, s=1, p=1, voo=True)\n",
      "module Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False) took 0.08934926986694336 fwd and 0.8823773860931396 bwd\n",
      "module SparseConv2d([256, 64, 1, 1], sp=0.91, nnz=1536, s=1, p=0, voo=False) took 0.29512548446655273 fwd and 1.4519932270050049 bwd\n",
      "module SparseConv2d([256, 64, 1, 1], sp=0.91, nnz=1536, s=1, p=0, voo=True) took 0.16781854629516602 fwd and 0.605736494064331 bwd\n",
      "going with SparseConv2d([256, 64, 1, 1], sp=0.91, nnz=1536, s=1, p=0, voo=True) with full time of 0.7735550403594971\n",
      "module layer1.2.conv3 replaced with SparseConv2d([256, 64, 1, 1], sp=0.91, nnz=1536, s=1, p=0, voo=True)\n",
      "module Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False) took 0.23789238929748535 fwd and 0.772209644317627 bwd\n",
      "module SparseConv2d([128, 256, 1, 1], sp=0.95, nnz=1792, s=1, p=0, voo=False) took 0.3600490093231201 fwd and 1.4285223484039307 bwd\n",
      "module SparseConv2d([128, 256, 1, 1], sp=0.95, nnz=1792, s=1, p=0, voo=True) took 0.10713839530944824 fwd and 0.4039914608001709 bwd\n",
      "going with SparseConv2d([128, 256, 1, 1], sp=0.95, nnz=1792, s=1, p=0, voo=True) with full time of 0.5111298561096191\n",
      "module layer2.0.conv1 replaced with SparseConv2d([128, 256, 1, 1], sp=0.95, nnz=1792, s=1, p=0, voo=True)\n",
      "module Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) took 0.11569452285766602 fwd and 0.2630290985107422 bwd\n",
      "module SparseConv2d([128, 128, 3, 3], sp=0.99, nnz=1152, s=2, p=1, voo=False) took 0.08077001571655273 fwd and 0.40673375129699707 bwd\n",
      "module SparseConv2d([128, 128, 3, 3], sp=0.99, nnz=1152, s=2, p=1, voo=True) took 0.12467455863952637 fwd and 0.12874960899353027 bwd\n",
      "going with SparseConv2d([128, 128, 3, 3], sp=0.99, nnz=1152, s=2, p=1, voo=True) with full time of 0.25342416763305664\n",
      "module layer2.0.conv2 replaced with SparseConv2d([128, 128, 3, 3], sp=0.99, nnz=1152, s=2, p=1, voo=True)\n",
      "module Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False) took 0.06712126731872559 fwd and 0.36334967613220215 bwd\n",
      "module SparseConv2d([512, 128, 1, 1], sp=0.95, nnz=3072, s=1, p=0, voo=False) took 0.10094213485717773 fwd and 0.5543005466461182 bwd\n",
      "module SparseConv2d([512, 128, 1, 1], sp=0.95, nnz=3072, s=1, p=0, voo=True) took 0.08672523498535156 fwd and 0.2978839874267578 bwd\n",
      "going with SparseConv2d([512, 128, 1, 1], sp=0.95, nnz=3072, s=1, p=0, voo=True) with full time of 0.3846092224121094\n",
      "module layer2.0.conv3 replaced with SparseConv2d([512, 128, 1, 1], sp=0.95, nnz=3072, s=1, p=0, voo=True)\n",
      "module Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) took 0.24553751945495605 fwd and 0.8967916965484619 bwd\n",
      "module SparseConv2d([512, 256, 1, 1], sp=0.97, nnz=3584, s=2, p=0, voo=False) took 0.22691893577575684 fwd and 1.3064279556274414 bwd\n",
      "module SparseConv2d([512, 256, 1, 1], sp=0.97, nnz=3584, s=2, p=0, voo=True) took 0.32175230979919434 fwd and 0.6704380512237549 bwd\n",
      "going with SparseConv2d([512, 256, 1, 1], sp=0.97, nnz=3584, s=2, p=0, voo=True) with full time of 0.9921903610229492\n",
      "module layer2.0.downsample.0 replaced with SparseConv2d([512, 256, 1, 1], sp=0.97, nnz=3584, s=2, p=0, voo=True)\n",
      "module Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False) took 0.1267528533935547 fwd and 0.2835111618041992 bwd\n",
      "module SparseConv2d([128, 512, 1, 1], sp=0.95, nnz=3072, s=1, p=0, voo=False) took 0.15250372886657715 fwd and 0.4524567127227783 bwd\n",
      "module SparseConv2d([128, 512, 1, 1], sp=0.95, nnz=3072, s=1, p=0, voo=True) took 0.06124591827392578 fwd and 0.14603757858276367 bwd\n",
      "going with SparseConv2d([128, 512, 1, 1], sp=0.95, nnz=3072, s=1, p=0, voo=True) with full time of 0.20728349685668945\n",
      "module layer2.1.conv1 replaced with SparseConv2d([128, 512, 1, 1], sp=0.95, nnz=3072, s=1, p=0, voo=True)\n",
      "module Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) took 0.07169723510742188 fwd and 0.20519208908081055 bwd\n",
      "module SparseConv2d([128, 128, 3, 3], sp=0.99, nnz=1152, s=1, p=1, voo=False) took 0.03870582580566406 fwd and 0.1776437759399414 bwd\n",
      "module SparseConv2d([128, 128, 3, 3], sp=0.99, nnz=1152, s=1, p=1, voo=True) took 0.020960092544555664 fwd and 0.050063371658325195 bwd\n",
      "going with SparseConv2d([128, 128, 3, 3], sp=0.99, nnz=1152, s=1, p=1, voo=True) with full time of 0.07102346420288086\n",
      "module layer2.1.conv2 replaced with SparseConv2d([128, 128, 3, 3], sp=0.99, nnz=1152, s=1, p=1, voo=True)\n",
      "module Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False) took 0.05911540985107422 fwd and 0.4850602149963379 bwd\n",
      "module SparseConv2d([512, 128, 1, 1], sp=0.95, nnz=3072, s=1, p=0, voo=False) took 0.09612560272216797 fwd and 0.6000678539276123 bwd\n",
      "module SparseConv2d([512, 128, 1, 1], sp=0.95, nnz=3072, s=1, p=0, voo=True) took 0.10371589660644531 fwd and 0.3026762008666992 bwd\n",
      "going with SparseConv2d([512, 128, 1, 1], sp=0.95, nnz=3072, s=1, p=0, voo=True) with full time of 0.40639209747314453\n",
      "module layer2.1.conv3 replaced with SparseConv2d([512, 128, 1, 1], sp=0.95, nnz=3072, s=1, p=0, voo=True)\n",
      "module Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False) took 0.09067487716674805 fwd and 0.27449774742126465 bwd\n",
      "module SparseConv2d([128, 512, 1, 1], sp=0.95, nnz=3072, s=1, p=0, voo=False) took 0.1512279510498047 fwd and 0.4374995231628418 bwd\n",
      "module SparseConv2d([128, 512, 1, 1], sp=0.95, nnz=3072, s=1, p=0, voo=True) took 0.059828758239746094 fwd and 0.1376044750213623 bwd\n",
      "going with SparseConv2d([128, 512, 1, 1], sp=0.95, nnz=3072, s=1, p=0, voo=True) with full time of 0.1974332332611084\n",
      "module layer2.2.conv1 replaced with SparseConv2d([128, 512, 1, 1], sp=0.95, nnz=3072, s=1, p=0, voo=True)\n",
      "module Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) took 0.08928799629211426 fwd and 0.21308565139770508 bwd\n",
      "module SparseConv2d([128, 128, 3, 3], sp=0.99, nnz=1152, s=1, p=1, voo=False) took 0.04084444046020508 fwd and 0.1782362461090088 bwd\n",
      "module SparseConv2d([128, 128, 3, 3], sp=0.99, nnz=1152, s=1, p=1, voo=True) took 0.020992755889892578 fwd and 0.049408912658691406 bwd\n",
      "going with SparseConv2d([128, 128, 3, 3], sp=0.99, nnz=1152, s=1, p=1, voo=True) with full time of 0.07040166854858398\n",
      "module layer2.2.conv2 replaced with SparseConv2d([128, 128, 3, 3], sp=0.99, nnz=1152, s=1, p=1, voo=True)\n",
      "module Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False) took 0.07153701782226562 fwd and 0.42609667778015137 bwd\n",
      "module SparseConv2d([512, 128, 1, 1], sp=0.95, nnz=3072, s=1, p=0, voo=False) took 0.12329792976379395 fwd and 0.7304887771606445 bwd\n",
      "module SparseConv2d([512, 128, 1, 1], sp=0.95, nnz=3072, s=1, p=0, voo=True) took 0.10550165176391602 fwd and 0.3226194381713867 bwd\n",
      "going with SparseConv2d([512, 128, 1, 1], sp=0.95, nnz=3072, s=1, p=0, voo=True) with full time of 0.42812108993530273\n",
      "module layer2.2.conv3 replaced with SparseConv2d([512, 128, 1, 1], sp=0.95, nnz=3072, s=1, p=0, voo=True)\n",
      "module Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False) took 0.09715127944946289 fwd and 0.22395801544189453 bwd\n",
      "module SparseConv2d([128, 512, 1, 1], sp=0.95, nnz=3072, s=1, p=0, voo=False) took 0.14512205123901367 fwd and 0.4041144847869873 bwd\n",
      "module SparseConv2d([128, 512, 1, 1], sp=0.95, nnz=3072, s=1, p=0, voo=True) took 0.05909299850463867 fwd and 0.13632869720458984 bwd\n",
      "going with SparseConv2d([128, 512, 1, 1], sp=0.95, nnz=3072, s=1, p=0, voo=True) with full time of 0.19542169570922852\n",
      "module layer2.3.conv1 replaced with SparseConv2d([128, 512, 1, 1], sp=0.95, nnz=3072, s=1, p=0, voo=True)\n",
      "module Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) took 0.06780266761779785 fwd and 0.2098865509033203 bwd\n",
      "module SparseConv2d([128, 128, 3, 3], sp=0.99, nnz=1152, s=1, p=1, voo=False) took 0.04094362258911133 fwd and 0.17464518547058105 bwd\n",
      "module SparseConv2d([128, 128, 3, 3], sp=0.99, nnz=1152, s=1, p=1, voo=True) took 0.021377086639404297 fwd and 0.050512075424194336 bwd\n",
      "going with SparseConv2d([128, 128, 3, 3], sp=0.99, nnz=1152, s=1, p=1, voo=True) with full time of 0.07188916206359863\n",
      "module layer2.3.conv2 replaced with SparseConv2d([128, 128, 3, 3], sp=0.99, nnz=1152, s=1, p=1, voo=True)\n",
      "module Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False) took 0.0621798038482666 fwd and 0.41335439682006836 bwd\n",
      "module SparseConv2d([512, 128, 1, 1], sp=0.95, nnz=3072, s=1, p=0, voo=False) took 0.10044431686401367 fwd and 0.6149296760559082 bwd\n",
      "module SparseConv2d([512, 128, 1, 1], sp=0.95, nnz=3072, s=1, p=0, voo=True) took 0.10403704643249512 fwd and 0.32999467849731445 bwd\n",
      "going with SparseConv2d([512, 128, 1, 1], sp=0.95, nnz=3072, s=1, p=0, voo=True) with full time of 0.43403172492980957\n",
      "module layer2.3.conv3 replaced with SparseConv2d([512, 128, 1, 1], sp=0.95, nnz=3072, s=1, p=0, voo=True)\n",
      "module Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False) took 0.1907181739807129 fwd and 0.40402913093566895 bwd\n",
      "module SparseConv2d([256, 512, 1, 1], sp=0.97, nnz=3584, s=1, p=0, voo=False) took 0.16325950622558594 fwd and 0.5451016426086426 bwd\n",
      "module SparseConv2d([256, 512, 1, 1], sp=0.97, nnz=3584, s=1, p=0, voo=True) took 0.07722330093383789 fwd and 0.19501209259033203 bwd\n",
      "going with SparseConv2d([256, 512, 1, 1], sp=0.97, nnz=3584, s=1, p=0, voo=True) with full time of 0.2722353935241699\n",
      "module layer3.0.conv1 replaced with SparseConv2d([256, 512, 1, 1], sp=0.97, nnz=3584, s=1, p=0, voo=True)\n",
      "module Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) took 0.11355233192443848 fwd and 0.23691797256469727 bwd\n",
      "module SparseConv2d([256, 256, 3, 3], sp=1.00, nnz=2304, s=2, p=1, voo=False) took 0.039130449295043945 fwd and 0.18439149856567383 bwd\n",
      "module SparseConv2d([256, 256, 3, 3], sp=1.00, nnz=2304, s=2, p=1, voo=True) took 0.07130622863769531 fwd and 0.08426666259765625 bwd\n",
      "going with SparseConv2d([256, 256, 3, 3], sp=1.00, nnz=2304, s=2, p=1, voo=True) with full time of 0.15557289123535156\n",
      "module layer3.0.conv2 replaced with SparseConv2d([256, 256, 3, 3], sp=1.00, nnz=2304, s=2, p=1, voo=True)\n",
      "module Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False) took 0.05565285682678223 fwd and 0.14949297904968262 bwd\n",
      "module SparseConv2d([1024, 256, 1, 1], sp=0.98, nnz=6144, s=1, p=0, voo=False) took 0.04176807403564453 fwd and 0.2486858367919922 bwd\n",
      "module SparseConv2d([1024, 256, 1, 1], sp=0.98, nnz=6144, s=1, p=0, voo=True) took 0.07595562934875488 fwd and 0.19830584526062012 bwd\n",
      "going with Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False) with full time of 0.20514583587646484\n",
      "keeping the module layer3.0.conv3 dense...\n",
      "module Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False) took 0.12899041175842285 fwd and 0.5200247764587402 bwd\n",
      "module SparseConv2d([1024, 512, 1, 1], sp=0.99, nnz=7168, s=2, p=0, voo=False) took 0.1141364574432373 fwd and 0.5429873466491699 bwd\n",
      "module SparseConv2d([1024, 512, 1, 1], sp=0.99, nnz=7168, s=2, p=0, voo=True) took 0.1493818759918213 fwd and 0.47925472259521484 bwd\n",
      "going with SparseConv2d([1024, 512, 1, 1], sp=0.99, nnz=7168, s=2, p=0, voo=True) with full time of 0.6286365985870361\n",
      "module layer3.0.downsample.0 replaced with SparseConv2d([1024, 512, 1, 1], sp=0.99, nnz=7168, s=2, p=0, voo=True)\n",
      "module Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False) took 0.052681684494018555 fwd and 0.09323358535766602 bwd\n",
      "module SparseConv2d([256, 1024, 1, 1], sp=0.98, nnz=6144, s=1, p=0, voo=False) took 0.04001975059509277 fwd and 0.14434528350830078 bwd\n",
      "module SparseConv2d([256, 1024, 1, 1], sp=0.98, nnz=6144, s=1, p=0, voo=True) took 0.059186458587646484 fwd and 0.10366678237915039 bwd\n",
      "going with Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False) with full time of 0.14591526985168457\n",
      "keeping the module layer3.1.conv1 dense...\n",
      "module Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) took 0.0675961971282959 fwd and 0.14489221572875977 bwd\n",
      "module SparseConv2d([256, 256, 3, 3], sp=1.00, nnz=2304, s=1, p=1, voo=False) took 0.01575469970703125 fwd and 0.08951616287231445 bwd\n",
      "module SparseConv2d([256, 256, 3, 3], sp=1.00, nnz=2304, s=1, p=1, voo=True) took 0.022816896438598633 fwd and 0.042847394943237305 bwd\n",
      "going with SparseConv2d([256, 256, 3, 3], sp=1.00, nnz=2304, s=1, p=1, voo=True) with full time of 0.06566429138183594\n",
      "module layer3.1.conv2 replaced with SparseConv2d([256, 256, 3, 3], sp=1.00, nnz=2304, s=1, p=1, voo=True)\n",
      "module Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False) took 0.05503535270690918 fwd and 0.28839802742004395 bwd\n",
      "module SparseConv2d([1024, 256, 1, 1], sp=0.98, nnz=6144, s=1, p=0, voo=False) took 0.042675018310546875 fwd and 0.3568718433380127 bwd\n",
      "module SparseConv2d([1024, 256, 1, 1], sp=0.98, nnz=6144, s=1, p=0, voo=True) took 0.08623337745666504 fwd and 0.2210240364074707 bwd\n",
      "going with SparseConv2d([1024, 256, 1, 1], sp=0.98, nnz=6144, s=1, p=0, voo=True) with full time of 0.30725741386413574\n",
      "module layer3.1.conv3 replaced with SparseConv2d([1024, 256, 1, 1], sp=0.98, nnz=6144, s=1, p=0, voo=True)\n",
      "module Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False) took 0.05265498161315918 fwd and 0.09784221649169922 bwd\n",
      "module SparseConv2d([256, 1024, 1, 1], sp=0.98, nnz=6144, s=1, p=0, voo=False) took 0.04095029830932617 fwd and 0.14801931381225586 bwd\n",
      "module SparseConv2d([256, 1024, 1, 1], sp=0.98, nnz=6144, s=1, p=0, voo=True) took 0.07132244110107422 fwd and 0.11611080169677734 bwd\n",
      "going with Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False) with full time of 0.1504971981048584\n",
      "keeping the module layer3.2.conv1 dense...\n",
      "module Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) took 0.06257867813110352 fwd and 0.18468809127807617 bwd\n",
      "module SparseConv2d([256, 256, 3, 3], sp=1.00, nnz=2304, s=1, p=1, voo=False) took 0.01695704460144043 fwd and 0.07887887954711914 bwd\n",
      "module SparseConv2d([256, 256, 3, 3], sp=1.00, nnz=2304, s=1, p=1, voo=True) took 0.0229184627532959 fwd and 0.04502105712890625 bwd\n",
      "going with SparseConv2d([256, 256, 3, 3], sp=1.00, nnz=2304, s=1, p=1, voo=True) with full time of 0.06793951988220215\n",
      "module layer3.2.conv2 replaced with SparseConv2d([256, 256, 3, 3], sp=1.00, nnz=2304, s=1, p=1, voo=True)\n",
      "module Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False) took 0.055281639099121094 fwd and 0.2433300018310547 bwd\n",
      "module SparseConv2d([1024, 256, 1, 1], sp=0.98, nnz=6144, s=1, p=0, voo=False) took 0.03607511520385742 fwd and 0.30652546882629395 bwd\n",
      "module SparseConv2d([1024, 256, 1, 1], sp=0.98, nnz=6144, s=1, p=0, voo=True) took 0.0844416618347168 fwd and 0.22636866569519043 bwd\n",
      "going with Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False) with full time of 0.2986116409301758\n",
      "keeping the module layer3.2.conv3 dense...\n",
      "module Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False) took 0.05385470390319824 fwd and 0.12578225135803223 bwd\n",
      "module SparseConv2d([256, 1024, 1, 1], sp=0.98, nnz=6144, s=1, p=0, voo=False) took 0.06267523765563965 fwd and 0.15389490127563477 bwd\n",
      "module SparseConv2d([256, 1024, 1, 1], sp=0.98, nnz=6144, s=1, p=0, voo=True) took 0.08205461502075195 fwd and 0.12725448608398438 bwd\n",
      "going with Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False) with full time of 0.17963695526123047\n",
      "keeping the module layer3.3.conv1 dense...\n",
      "module Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) took 0.0864267349243164 fwd and 0.19103455543518066 bwd\n",
      "module SparseConv2d([256, 256, 3, 3], sp=1.00, nnz=2304, s=1, p=1, voo=False) took 0.018237590789794922 fwd and 0.08133959770202637 bwd\n",
      "module SparseConv2d([256, 256, 3, 3], sp=1.00, nnz=2304, s=1, p=1, voo=True) took 0.02355670928955078 fwd and 0.0442805290222168 bwd\n",
      "going with SparseConv2d([256, 256, 3, 3], sp=1.00, nnz=2304, s=1, p=1, voo=True) with full time of 0.06783723831176758\n",
      "module layer3.3.conv2 replaced with SparseConv2d([256, 256, 3, 3], sp=1.00, nnz=2304, s=1, p=1, voo=True)\n",
      "module Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False) took 0.05031418800354004 fwd and 0.27219271659851074 bwd\n",
      "module SparseConv2d([1024, 256, 1, 1], sp=0.98, nnz=6144, s=1, p=0, voo=False) took 0.039438724517822266 fwd and 0.3364126682281494 bwd\n",
      "module SparseConv2d([1024, 256, 1, 1], sp=0.98, nnz=6144, s=1, p=0, voo=True) took 0.08568429946899414 fwd and 0.2135331630706787 bwd\n",
      "going with SparseConv2d([1024, 256, 1, 1], sp=0.98, nnz=6144, s=1, p=0, voo=True) with full time of 0.29921746253967285\n",
      "module layer3.3.conv3 replaced with SparseConv2d([1024, 256, 1, 1], sp=0.98, nnz=6144, s=1, p=0, voo=True)\n",
      "module Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False) took 0.05668449401855469 fwd and 0.12339639663696289 bwd\n",
      "module SparseConv2d([256, 1024, 1, 1], sp=0.98, nnz=6144, s=1, p=0, voo=False) took 0.05105948448181152 fwd and 0.20624136924743652 bwd\n",
      "module SparseConv2d([256, 1024, 1, 1], sp=0.98, nnz=6144, s=1, p=0, voo=True) took 0.07695531845092773 fwd and 0.12330889701843262 bwd\n",
      "going with Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False) with full time of 0.18008089065551758\n",
      "keeping the module layer3.4.conv1 dense...\n",
      "module Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) took 0.0861208438873291 fwd and 0.17670035362243652 bwd\n",
      "module SparseConv2d([256, 256, 3, 3], sp=1.00, nnz=2304, s=1, p=1, voo=False) took 0.016627073287963867 fwd and 0.07856893539428711 bwd\n",
      "module SparseConv2d([256, 256, 3, 3], sp=1.00, nnz=2304, s=1, p=1, voo=True) took 0.022717952728271484 fwd and 0.0437617301940918 bwd\n",
      "going with SparseConv2d([256, 256, 3, 3], sp=1.00, nnz=2304, s=1, p=1, voo=True) with full time of 0.06647968292236328\n",
      "module layer3.4.conv2 replaced with SparseConv2d([256, 256, 3, 3], sp=1.00, nnz=2304, s=1, p=1, voo=True)\n",
      "module Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False) took 0.04894590377807617 fwd and 0.27138566970825195 bwd\n",
      "module SparseConv2d([1024, 256, 1, 1], sp=0.98, nnz=6144, s=1, p=0, voo=False) took 0.039922237396240234 fwd and 0.3526623249053955 bwd\n",
      "module SparseConv2d([1024, 256, 1, 1], sp=0.98, nnz=6144, s=1, p=0, voo=True) took 0.0863041877746582 fwd and 0.21660780906677246 bwd\n",
      "going with SparseConv2d([1024, 256, 1, 1], sp=0.98, nnz=6144, s=1, p=0, voo=True) with full time of 0.30291199684143066\n",
      "module layer3.4.conv3 replaced with SparseConv2d([1024, 256, 1, 1], sp=0.98, nnz=6144, s=1, p=0, voo=True)\n",
      "module Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False) took 0.05195260047912598 fwd and 0.12244296073913574 bwd\n",
      "module SparseConv2d([256, 1024, 1, 1], sp=0.98, nnz=6144, s=1, p=0, voo=False) took 0.06592607498168945 fwd and 0.20081448554992676 bwd\n",
      "module SparseConv2d([256, 1024, 1, 1], sp=0.98, nnz=6144, s=1, p=0, voo=True) took 0.07736444473266602 fwd and 0.12480521202087402 bwd\n",
      "going with Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False) with full time of 0.17439556121826172\n",
      "keeping the module layer3.5.conv1 dense...\n",
      "module Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) took 0.08341765403747559 fwd and 0.18668270111083984 bwd\n",
      "module SparseConv2d([256, 256, 3, 3], sp=1.00, nnz=2304, s=1, p=1, voo=False) took 0.014799833297729492 fwd and 0.07429695129394531 bwd\n",
      "module SparseConv2d([256, 256, 3, 3], sp=1.00, nnz=2304, s=1, p=1, voo=True) took 0.022713184356689453 fwd and 0.04390907287597656 bwd\n",
      "going with SparseConv2d([256, 256, 3, 3], sp=1.00, nnz=2304, s=1, p=1, voo=True) with full time of 0.06662225723266602\n",
      "module layer3.5.conv2 replaced with SparseConv2d([256, 256, 3, 3], sp=1.00, nnz=2304, s=1, p=1, voo=True)\n",
      "module Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False) took 0.04920697212219238 fwd and 0.2847919464111328 bwd\n",
      "module SparseConv2d([1024, 256, 1, 1], sp=0.98, nnz=6144, s=1, p=0, voo=False) took 0.03344464302062988 fwd and 0.2942488193511963 bwd\n",
      "module SparseConv2d([1024, 256, 1, 1], sp=0.98, nnz=6144, s=1, p=0, voo=True) took 0.06612491607666016 fwd and 0.20522475242614746 bwd\n",
      "going with SparseConv2d([1024, 256, 1, 1], sp=0.98, nnz=6144, s=1, p=0, voo=True) with full time of 0.2713496685028076\n",
      "module layer3.5.conv3 replaced with SparseConv2d([1024, 256, 1, 1], sp=0.98, nnz=6144, s=1, p=0, voo=True)\n",
      "module Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False) took 0.10464715957641602 fwd and 0.25977063179016113 bwd\n",
      "module SparseConv2d([512, 1024, 1, 1], sp=0.99, nnz=7168, s=1, p=0, voo=False) took 0.07282495498657227 fwd and 0.2692101001739502 bwd\n",
      "module SparseConv2d([512, 1024, 1, 1], sp=0.99, nnz=7168, s=1, p=0, voo=True) took 0.11587071418762207 fwd and 0.21869444847106934 bwd\n",
      "going with SparseConv2d([512, 1024, 1, 1], sp=0.99, nnz=7168, s=1, p=0, voo=True) with full time of 0.3345651626586914\n",
      "module layer4.0.conv1 replaced with SparseConv2d([512, 1024, 1, 1], sp=0.99, nnz=7168, s=1, p=0, voo=True)\n",
      "module Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) took 0.133012056350708 fwd and 0.24077963829040527 bwd\n",
      "module SparseConv2d([512, 512, 3, 3], sp=1.00, nnz=4608, s=2, p=1, voo=False) took 0.017261981964111328 fwd and 0.05905032157897949 bwd\n",
      "module SparseConv2d([512, 512, 3, 3], sp=1.00, nnz=4608, s=2, p=1, voo=True) took 0.014735937118530273 fwd and 0.07627701759338379 bwd\n",
      "going with SparseConv2d([512, 512, 3, 3], sp=1.00, nnz=4608, s=2, p=1, voo=False) with full time of 0.07631230354309082\n",
      "module layer4.0.conv2 replaced with SparseConv2d([512, 512, 3, 3], sp=1.00, nnz=4608, s=2, p=1, voo=False)\n",
      "module Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False) took 0.04342293739318848 fwd and 0.12405967712402344 bwd\n",
      "module SparseConv2d([2048, 512, 1, 1], sp=0.99, nnz=12288, s=1, p=0, voo=False) took 0.020048856735229492 fwd and 0.12172245979309082 bwd\n",
      "module SparseConv2d([2048, 512, 1, 1], sp=0.99, nnz=12288, s=1, p=0, voo=True) took 0.1694951057434082 fwd and 0.3264293670654297 bwd\n",
      "going with SparseConv2d([2048, 512, 1, 1], sp=0.99, nnz=12288, s=1, p=0, voo=False) with full time of 0.1417713165283203\n",
      "module layer4.0.conv3 replaced with SparseConv2d([2048, 512, 1, 1], sp=0.99, nnz=12288, s=1, p=0, voo=False)\n",
      "module Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False) took 0.12346100807189941 fwd and 0.32200050354003906 bwd\n",
      "module SparseConv2d([2048, 1024, 1, 1], sp=0.99, nnz=14336, s=2, p=0, voo=False) took 0.06729960441589355 fwd and 0.2735414505004883 bwd\n",
      "module SparseConv2d([2048, 1024, 1, 1], sp=0.99, nnz=14336, s=2, p=0, voo=True) took 0.07916569709777832 fwd and 0.6754019260406494 bwd\n",
      "going with SparseConv2d([2048, 1024, 1, 1], sp=0.99, nnz=14336, s=2, p=0, voo=False) with full time of 0.34084105491638184\n",
      "module layer4.0.downsample.0 replaced with SparseConv2d([2048, 1024, 1, 1], sp=0.99, nnz=14336, s=2, p=0, voo=False)\n",
      "module Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False) took 0.042427778244018555 fwd and 0.07893896102905273 bwd\n",
      "module SparseConv2d([512, 2048, 1, 1], sp=0.99, nnz=12288, s=1, p=0, voo=False) took 0.022661685943603516 fwd and 0.0731821060180664 bwd\n",
      "module SparseConv2d([512, 2048, 1, 1], sp=0.99, nnz=12288, s=1, p=0, voo=True) took 0.13031911849975586 fwd and 0.27845335006713867 bwd\n",
      "going with SparseConv2d([512, 2048, 1, 1], sp=0.99, nnz=12288, s=1, p=0, voo=False) with full time of 0.09584379196166992\n",
      "module layer4.1.conv1 replaced with SparseConv2d([512, 2048, 1, 1], sp=0.99, nnz=12288, s=1, p=0, voo=False)\n",
      "module Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) took 0.08701562881469727 fwd and 0.20094084739685059 bwd\n",
      "module SparseConv2d([512, 512, 3, 3], sp=1.00, nnz=4608, s=1, p=1, voo=False) took 0.0075795650482177734 fwd and 0.0348210334777832 bwd\n",
      "module SparseConv2d([512, 512, 3, 3], sp=1.00, nnz=4608, s=1, p=1, voo=True) took 0.044886112213134766 fwd and 0.07336807250976562 bwd\n",
      "going with SparseConv2d([512, 512, 3, 3], sp=1.00, nnz=4608, s=1, p=1, voo=False) with full time of 0.04240059852600098\n",
      "module layer4.1.conv2 replaced with SparseConv2d([512, 512, 3, 3], sp=1.00, nnz=4608, s=1, p=1, voo=False)\n",
      "module Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False) took 0.04909920692443848 fwd and 0.11614108085632324 bwd\n",
      "module SparseConv2d([2048, 512, 1, 1], sp=0.99, nnz=12288, s=1, p=0, voo=False) took 0.018381357192993164 fwd and 0.11469531059265137 bwd\n",
      "module SparseConv2d([2048, 512, 1, 1], sp=0.99, nnz=12288, s=1, p=0, voo=True) took 0.16556525230407715 fwd and 0.28099966049194336 bwd\n",
      "going with SparseConv2d([2048, 512, 1, 1], sp=0.99, nnz=12288, s=1, p=0, voo=False) with full time of 0.13307666778564453\n",
      "module layer4.1.conv3 replaced with SparseConv2d([2048, 512, 1, 1], sp=0.99, nnz=12288, s=1, p=0, voo=False)\n",
      "module Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False) took 0.05920839309692383 fwd and 0.10248923301696777 bwd\n",
      "module SparseConv2d([512, 2048, 1, 1], sp=0.99, nnz=12288, s=1, p=0, voo=False) took 0.026504039764404297 fwd and 0.09976577758789062 bwd\n",
      "module SparseConv2d([512, 2048, 1, 1], sp=0.99, nnz=12288, s=1, p=0, voo=True) took 0.17533016204833984 fwd and 0.3433558940887451 bwd\n",
      "going with SparseConv2d([512, 2048, 1, 1], sp=0.99, nnz=12288, s=1, p=0, voo=False) with full time of 0.12626981735229492\n",
      "module layer4.2.conv1 replaced with SparseConv2d([512, 2048, 1, 1], sp=0.99, nnz=12288, s=1, p=0, voo=False)\n",
      "module Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) took 0.09086060523986816 fwd and 0.20243310928344727 bwd\n",
      "module SparseConv2d([512, 512, 3, 3], sp=1.00, nnz=4608, s=1, p=1, voo=False) took 0.009920835494995117 fwd and 0.0331728458404541 bwd\n",
      "module SparseConv2d([512, 512, 3, 3], sp=1.00, nnz=4608, s=1, p=1, voo=True) took 0.045706987380981445 fwd and 0.07412576675415039 bwd\n",
      "going with SparseConv2d([512, 512, 3, 3], sp=1.00, nnz=4608, s=1, p=1, voo=False) with full time of 0.04309368133544922\n",
      "module layer4.2.conv2 replaced with SparseConv2d([512, 512, 3, 3], sp=1.00, nnz=4608, s=1, p=1, voo=False)\n",
      "module Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False) took 0.04907822608947754 fwd and 0.11639404296875 bwd\n",
      "module SparseConv2d([2048, 512, 1, 1], sp=0.99, nnz=12288, s=1, p=0, voo=False) took 0.018368244171142578 fwd and 0.11538529396057129 bwd\n",
      "module SparseConv2d([2048, 512, 1, 1], sp=0.99, nnz=12288, s=1, p=0, voo=True) took 0.13840842247009277 fwd and 0.2936549186706543 bwd\n",
      "going with SparseConv2d([2048, 512, 1, 1], sp=0.99, nnz=12288, s=1, p=0, voo=False) with full time of 0.13375353813171387\n",
      "module layer4.2.conv3 replaced with SparseConv2d([2048, 512, 1, 1], sp=0.99, nnz=12288, s=1, p=0, voo=False)\n",
      "module Linear(in_features=2048, out_features=1000, bias=True) took 0.004445552825927734 fwd and 0.0042133331298828125 bwd\n",
      "module SparseLinear([1000, 2048], sp=0.99, nnz=14000) took 0.0007669925689697266 fwd and 0.002374887466430664 bwd\n",
      "going with SparseLinear([1000, 2048], sp=0.99, nnz=14000) with full time of 0.0031418800354003906\n",
      "module fc replaced with SparseLinear([1000, 2048], sp=0.99, nnz=14000)\n"
     ]
    }
   ],
   "source": [
    "from sparseprop.utils import swap_modules_with_sparse\n",
    "\n",
    "partially_sparse_model = swap_modules_with_sparse(model.to(\"cpu\"), data.shape, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): SparseConv2d([64, 64, 1, 1], sp=0.86, nnz=576, s=1, p=0, voo=True)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): SparseConv2d([64, 64, 3, 3], sp=0.98, nnz=640, s=1, p=1, voo=True)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): SparseConv2d([256, 64, 1, 1], sp=0.91, nnz=1536, s=1, p=0, voo=True)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): SparseConv2d([256, 64, 1, 1], sp=0.91, nnz=1536, s=1, p=0, voo=True)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): SparseConv2d([64, 256, 1, 1], sp=0.91, nnz=1536, s=1, p=0, voo=True)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): SparseConv2d([64, 64, 3, 3], sp=0.98, nnz=640, s=1, p=1, voo=True)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): SparseConv2d([256, 64, 1, 1], sp=0.91, nnz=1536, s=1, p=0, voo=True)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): SparseConv2d([64, 256, 1, 1], sp=0.91, nnz=1536, s=1, p=0, voo=True)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): SparseConv2d([64, 64, 3, 3], sp=0.98, nnz=640, s=1, p=1, voo=True)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): SparseConv2d([256, 64, 1, 1], sp=0.91, nnz=1536, s=1, p=0, voo=True)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): SparseConv2d([128, 256, 1, 1], sp=0.95, nnz=1792, s=1, p=0, voo=True)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): SparseConv2d([128, 128, 3, 3], sp=0.99, nnz=1152, s=2, p=1, voo=True)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): SparseConv2d([512, 128, 1, 1], sp=0.95, nnz=3072, s=1, p=0, voo=True)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): SparseConv2d([512, 256, 1, 1], sp=0.97, nnz=3584, s=2, p=0, voo=True)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): SparseConv2d([128, 512, 1, 1], sp=0.95, nnz=3072, s=1, p=0, voo=True)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): SparseConv2d([128, 128, 3, 3], sp=0.99, nnz=1152, s=1, p=1, voo=True)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): SparseConv2d([512, 128, 1, 1], sp=0.95, nnz=3072, s=1, p=0, voo=True)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): SparseConv2d([128, 512, 1, 1], sp=0.95, nnz=3072, s=1, p=0, voo=True)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): SparseConv2d([128, 128, 3, 3], sp=0.99, nnz=1152, s=1, p=1, voo=True)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): SparseConv2d([512, 128, 1, 1], sp=0.95, nnz=3072, s=1, p=0, voo=True)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): SparseConv2d([128, 512, 1, 1], sp=0.95, nnz=3072, s=1, p=0, voo=True)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): SparseConv2d([128, 128, 3, 3], sp=0.99, nnz=1152, s=1, p=1, voo=True)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): SparseConv2d([512, 128, 1, 1], sp=0.95, nnz=3072, s=1, p=0, voo=True)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): SparseConv2d([256, 512, 1, 1], sp=0.97, nnz=3584, s=1, p=0, voo=True)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): SparseConv2d([256, 256, 3, 3], sp=1.00, nnz=2304, s=2, p=1, voo=True)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): SparseConv2d([1024, 512, 1, 1], sp=0.99, nnz=7168, s=2, p=0, voo=True)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): SparseConv2d([256, 256, 3, 3], sp=1.00, nnz=2304, s=1, p=1, voo=True)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): SparseConv2d([1024, 256, 1, 1], sp=0.98, nnz=6144, s=1, p=0, voo=True)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): SparseConv2d([256, 256, 3, 3], sp=1.00, nnz=2304, s=1, p=1, voo=True)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): SparseConv2d([256, 256, 3, 3], sp=1.00, nnz=2304, s=1, p=1, voo=True)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): SparseConv2d([1024, 256, 1, 1], sp=0.98, nnz=6144, s=1, p=0, voo=True)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): SparseConv2d([256, 256, 3, 3], sp=1.00, nnz=2304, s=1, p=1, voo=True)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): SparseConv2d([1024, 256, 1, 1], sp=0.98, nnz=6144, s=1, p=0, voo=True)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): SparseConv2d([256, 256, 3, 3], sp=1.00, nnz=2304, s=1, p=1, voo=True)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): SparseConv2d([1024, 256, 1, 1], sp=0.98, nnz=6144, s=1, p=0, voo=True)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): SparseConv2d([512, 1024, 1, 1], sp=0.99, nnz=7168, s=1, p=0, voo=True)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): SparseConv2d([512, 512, 3, 3], sp=1.00, nnz=4608, s=2, p=1, voo=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): SparseConv2d([2048, 512, 1, 1], sp=0.99, nnz=12288, s=1, p=0, voo=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): SparseConv2d([2048, 1024, 1, 1], sp=0.99, nnz=14336, s=2, p=0, voo=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): SparseConv2d([512, 2048, 1, 1], sp=0.99, nnz=12288, s=1, p=0, voo=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): SparseConv2d([512, 512, 3, 3], sp=1.00, nnz=4608, s=1, p=1, voo=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): SparseConv2d([2048, 512, 1, 1], sp=0.99, nnz=12288, s=1, p=0, voo=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): SparseConv2d([512, 2048, 1, 1], sp=0.99, nnz=12288, s=1, p=0, voo=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): SparseConv2d([512, 512, 3, 3], sp=1.00, nnz=4608, s=1, p=1, voo=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): SparseConv2d([2048, 512, 1, 1], sp=0.99, nnz=12288, s=1, p=0, voo=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): SparseLinear([1000, 2048], sp=0.99, nnz=14000)\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "partially_sparse_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.benchmark import Timer\n",
    "partially_sparse_timer = Timer(\n",
    "    stmt='model(input)',\n",
    "    label=\"dense\",\n",
    "    globals={\"model\": partially_sparse_model,\n",
    "             \"input\": data},\n",
    "    num_threads=8,\n",
    ")\n",
    "\n",
    "partially_sparse_result = partially_sparse_timer.timeit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.benchmark.utils.common.Measurement object at 0x7ff7c49800a0>\n",
      "dense\n",
      "  8.61 s\n",
      "  1 measurement, 1 runs , 8 threads\n"
     ]
    }
   ],
   "source": [
    "print(partially_sparse_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
